[
  {
    "Id": "44785585",
    "PostTypeId": "1",
    "AcceptedAnswerId": "44785784",
    "CreationDate": "2017-06-27T16:36:53.480",
    "Score": "992",
    "ViewCount": "1023912",
    "Body": "<p>I recently started using Docker and never realized that I should use <code>docker-compose down</code> instead of <code>ctrl-c</code> or <code>docker-compose stop</code> to get rid of my experiments. I now have a large number of unneeded docker images locally. </p>  <p>Is there a flag I can run to delete all the local docker images &amp; containers?</p>  <p>Something like <code>docker rmi --all --force</code> --all flag does not exist but I am looking for something with similar idea. </p> ",
    "OwnerUserId": "2335820",
    "LastEditorUserId": "12744",
    "LastEditDate": "2023-03-08T10:14:15.883",
    "LastActivityDate": "2023-10-13T08:03:37.670",
    "Title": "How can I delete all local Docker images?",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "25",
    "CommentCount": "6",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "34324277",
    "PostTypeId": "1",
    "AcceptedAnswerId": "47643816",
    "CreationDate": "2015-12-16T23:43:51.877",
    "Score": "98",
    "ViewCount": "60220",
    "Body": "<p>Docker 1.9 allows to pass arguments to a dockerfile. See link: <a href='https://docs.docker.com/engine/reference/builder/#arg' rel='noreferrer'>https://docs.docker.com/engine/reference/builder/#arg</a></p>  <p>How can i pass the same arugments within ENTRYPOINT Instruction??  </p>  <p>My dockerfile has  </p>  <blockquote>   <p>ARG $Version=3.1<br>   ENTRYPOINT /tmp/folder-$Version/sample.sh start  </p> </blockquote>  <p>I am getting an error while creating container with above dockerfile. Please suggest what is the correct way to specify the argument within ENTRYPOINT instruction??</p> ",
    "OwnerUserId": "5632400",
    "LastActivityDate": "2022-02-25T14:27:13.980",
    "Title": "How to pass ARG value to ENTRYPOINT?",
    "Tags": "<docker><dockerfile><docker-compose><docker-registry>",
    "AnswerCount": "5",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "43408493",
    "PostTypeId": "1",
    "CreationDate": "2017-04-14T09:05:36.800",
    "Score": "98",
    "ViewCount": "61234",
    "Body": "<p>When do we use a <code>docker service create</code> command and when do we use a <code>docker run</code> command?</p> ",
    "OwnerUserId": "7863706",
    "LastEditorUserId": "4922375",
    "LastEditDate": "2018-12-22T23:36:09.900",
    "LastActivityDate": "2023-07-19T16:39:51.067",
    "Title": "What is the difference between Docker Service and Docker Container?",
    "Tags": "<docker><docker-compose><dockerfile>",
    "AnswerCount": "6",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "31149501",
    "PostTypeId": "1",
    "AcceptedAnswerId": "35691865",
    "CreationDate": "2015-06-30T22:16:13.497",
    "Score": "97",
    "ViewCount": "139661",
    "Body": "<p>Is there a way I can reach my docker containers using names instead of ip addresses?</p>  <p>I've heard of pipework and I've seen some dns and hostname type options for docker, but I still am unable to piece everything together.</p>  <p>Thank you for your time.</p>  <p>I'm not sure if this is helpful, but this is what I've done so far:</p>  <ul> <li>installed docker container host using docker-machine and the vmwarevsphere driver</li> <li>started up all the services with docker-compose</li> <li>I can reach all of the services from any other machine on the network using IP and port</li> </ul>  <p>I've added a DNS alias entry to my private network DNS server and it matches the machine name that's used by docker-machine.  But the machine always picks up a different IP address when it boots and connects to the network.</p>  <p>I'm just lost as to where to tackle this:</p>  <ul> <li>network DNS server</li> <li>docker-machine hostname</li> <li>docker container hostname</li> <li>probably some combination of all of them</li> </ul>  <p>I'm probably looking for something similar to this question:</p>  <p><a href='https://stackoverflow.com/questions/27342382/how-can-let-docker-use-my-network-router-to-assign-dhcp-ip-to-containers-easily'>How can let docker use my network router to assign dhcp ip to containers easily instead of pipework?</a></p>  <p>Any general direction will be awesome...thanks again!</p> ",
    "OwnerUserId": "1207596",
    "LastEditorUserId": "-1",
    "LastEditDate": "2017-05-23T12:02:00.800",
    "LastActivityDate": "2022-10-23T10:41:42.040",
    "Title": "How to reach docker containers by name instead of IP address?",
    "Tags": "<dns><docker><hostname><docker-compose><docker-machine>",
    "AnswerCount": "7",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "47615495",
    "PostTypeId": "1",
    "AcceptedAnswerId": "47622441",
    "CreationDate": "2017-12-03T05:15:01.137",
    "Score": "97",
    "ViewCount": "120508",
    "Body": "<p>I am currently trying out this tutorial for <code>node express</code> with <code>mongodb</code> <a href='https://medium.com/@sunnykay/docker-development-workflow-node-express-mongo-4bb3b1f7eb1e' rel='noreferrer'>https://medium.com/@sunnykay/docker-development-workflow-node-express-mongo-4bb3b1f7eb1e</a></p> <p>the first part works fine where to build the <code>docker-compose.yml</code> it works totally fine building it locally so I tried to tag it and push into my <code>dockerhub</code> to learn and try more.</p> <p>this is originally what's in the <code>yml</code> file followed by the tutorial</p> <pre><code>version: &quot;2&quot; services:   web:     build: .     volumes:       - ./:/app     ports:       - &quot;3000:3000&quot; </code></pre> <p>this works like a charm when I use <code>docker-compose build</code> and <code>docker-compose up</code></p> <p>so I tried to push it to my dockerhub and I also tag it as <code>node-test</code></p> <p>I then changed the <code>yml</code> file into</p> <pre><code>version: &quot;2&quot; services:   web:     image: &quot;et4891/node-test&quot;     volumes:       - ./:/app     ports:       - &quot;3000:3000&quot; </code></pre> <p>then I removed all images I have previously to make sure this also works...but when I run <code>docker-compose build</code>  I see this message <code>error: web uses an image, skipping</code> and nothing happens.</p> <p>I tried googling the error but nothing much I can find.</p> <p>Can someone please give me a hand?</p> ",
    "OwnerUserId": "1850712",
    "LastEditorUserId": "11107541",
    "LastEditDate": "2022-12-18T23:17:00.127",
    "LastActivityDate": "2023-04-21T13:15:26.410",
    "Title": "Docker: Uses an image, skipping (docker-compose)",
    "Tags": "<node.js><mongodb><docker><docker-compose>",
    "AnswerCount": "5",
    "CommentCount": "4",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "30063907",
    "PostTypeId": "1",
    "AcceptedAnswerId": "30064175",
    "CreationDate": "2015-05-05T21:53:37.160",
    "Score": "969",
    "ViewCount": "1093335",
    "Body": "<p>I want to do something like this where I can run multiple commands in the following code:</p> <pre class='lang-yaml prettyprint-override'><code>db:   image: postgres web:   build: .   command: python manage.py migrate   command: python manage.py runserver 0.0.0.0:8000   volumes:     - .:/code   ports:     - &quot;8000:8000&quot;   links:     - db </code></pre> <p>How could I execute multiple commands?</p> ",
    "OwnerUserId": "2587797",
    "LastEditorUserId": "11107541",
    "LastEditDate": "2022-12-27T00:59:12.397",
    "LastActivityDate": "2023-02-26T11:27:07.617",
    "Title": "Docker Compose - How to execute multiple commands?",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "21",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "35560894",
    "PostTypeId": "1",
    "AcceptedAnswerId": "35562189",
    "CreationDate": "2016-02-22T18:15:08.793",
    "Score": "96",
    "ViewCount": "39210",
    "Body": "<p>I have a Dockerfile where an <code>ARG</code> is used in the <code>CMD</code> instruction:</p>  <pre><code>ARG MASTER_NAME CMD spark-submit --deploy-mode client --master ${MASTER_URL} </code></pre>  <p>The arg is passed via docker-compose:</p>  <pre><code>  spark:     build:       context: spark       args:         - MASTER_URL=spark://master:7077 </code></pre>  <p>However, the <code>ARG</code> does not seem to get expanded for <code>CMD</code>. After I <code>docker-compose up</code>.</p>  <p>Here's what inspect shows:</p>  <pre><code>docker inspect  -f '{{.Name}} {{.Config.Cmd}}' $(docker ps -a -q) /spark {[/bin/sh -c spark-submit --deploy-mode client --master ${MASTER_URL}]} </code></pre> ",
    "OwnerUserId": "1086117",
    "LastEditorUserId": "745868",
    "LastEditDate": "2018-12-28T00:10:46.477",
    "LastActivityDate": "2018-12-28T00:10:46.477",
    "Title": "Is Docker ARG allowed within CMD instruction",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "52429984",
    "PostTypeId": "1",
    "AcceptedAnswerId": "52430444",
    "CreationDate": "2018-09-20T17:01:32.607",
    "Score": "96",
    "ViewCount": "83524",
    "Body": "<p><strong>TL;DR :</strong> How can I pass env variable when building the image with <code>docker-compose</code> and have <code>docker run image command</code> recognize them ?</p>  <p>I have this Dockerfile :</p>  <pre><code>FROM mhart/alpine-node:10 ADD . /app WORKDIR /app RUN apk --no-cache add --virtual builds-deps build-base python &amp;&amp;\\     yarn global add nodemon &amp;&amp;\\     yarn &amp;&amp;\\     apk del builds-deps build-base python </code></pre>  <p>and this docker-compose.yml :</p>  <pre><code>version: '3.3' services:    api:     build:       context: .       dockerfile: Dockerfile-preprod     image: registry.git.louis-girones.fr:4567/make-your-night/back:preprod     environment:       - NODE_ENV=development     env_file:       - .env     volumes:       - .:/app     ports:       - '${PORT_PREPROD}:${PORT_PREPROD}'     command: sh -c 'mkdir -p dist &amp;&amp; touch ./dist/app.js &amp;&amp; yarn run start'    mongo:     image: mongo:4.0     ports:       - '${MONGO_PREPROD}'     command: mongod     volumes:       - ./data:/data/db    elasticsearch:     image: docker.elastic.co/elasticsearch/elasticsearch:6.1.1     volumes:       - ./esdata:/usr/share/elasticsearch/data     environment:       - bootstrap.memory_lock=true       - 'ES_JAVA_OPTS=-Xms512m -Xmx512m'       - discovery.type=single-node     ports:       - '9300:9300'       - '9200:9200'  volumes:   esdata: </code></pre>  <p>With this .env file (which is in the root folder, like docker-compose.yml and Dockerfile) :</p>  <pre><code>#!/usr/bin/env bash  NODE_ENV=development PORT=9000 SECRET_SESSION=superSecr3t APP_NAME=Night Vision API_VERSION=/api/v0/ DEFAULT_TZ=Europe/Paris ASSETS_URI=http://localhost:9000/public/img/ BCRYPT_WORKFACTOR=1 ES_PORT=9200 ES_LOG_LEVEL=trace </code></pre>  <p>And this code in the node server startup :</p>  <pre><code>// Export the config object based on the NODE_ENV // ============================================== const config: IConfig = commonConfig  if (commonConfig.env === 'development') {     _.merge(config, developmentConfig) } else if (commonConfig.env === 'test') {     _.merge(config, testConfig) } else if (commonConfig.env === 'preproduction') {     _.merge(config, preproductionConfig) } else if (commonConfig.env === 'production') {     _.merge(config, productionConfig) } else {     throw new Error('Please set an environment') } </code></pre>  <p>When I run the <code>docker-compose build</code> command, everything is fine, but for instance If I try <code>docker run myimage yarn run test</code> the Error 'Please set an environment' is thrown. </p>  <p>I would expect that </p>  <pre><code>env_file:   - .env </code></pre>  <p>makes the env variables of this file accessible in my image but that is not the case, that's why I tried to add </p>  <pre><code> environment:   - NODE_ENV=development </code></pre>  <p>But still no success, I have also tried to pass my env variable as command line argument when I run the build :</p>  <p><code>docker-compose build --build-arg  NODE_ENV=development api</code></p>  <p>But it gives me this message :</p>  <pre><code>[Warning] One or more build-args [NODE_ENV] were not consumed Successfully built 9b14dd5abc3f </code></pre>  <p>And I would really prefer to use the first or second methods</p>  <p>docker version : 18.06.1-ce docker-compose version : 1.19.0</p> ",
    "OwnerUserId": "7337055",
    "LastEditorUserId": "7337055",
    "LastEditDate": "2018-09-20T17:07:13.347",
    "LastActivityDate": "2022-03-14T20:53:02.407",
    "Title": "docker-compose build environment variable",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "5",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "66912085",
    "PostTypeId": "1",
    "AcceptedAnswerId": "66912110",
    "CreationDate": "2021-04-01T22:00:08.163",
    "Score": "96",
    "ViewCount": "251790",
    "Body": "<p>I've been running docker-compose build for days, many times per day, and haven't changed my DOCKERFILEs or docker-compose.yml. Suddenly an hour ago I started getting this:</p> <pre><code>Building frontdesk-api failed to get console mode for stdout: The handle is invalid. [+] Building 10.0s (3/4)  =&gt; [internal] load build definition from Dockerfile                       0.0s [+] Building 10.1s (4/4) FINISHED  =&gt; [internal] load build definition from Dockerfile                       0.0s  =&gt; =&gt; transferring dockerfile: 32B                                        0.0s  =&gt; [internal] load .dockerignore                                          0.0s  =&gt; =&gt; transferring context: 2B                                            0.0s  =&gt; ERROR [internal] load metadata for mcr.microsoft.com/dotnet/sdk:5.0.  10.0sailed to do request: Head https://mcr.microsoft.com/v2/dotnet/sdk/manifests/5.0.201-buster-slim: dial tcp: lookup mcr.microsoft.com on 192.168.65.5:53:  =&gt; [internal] load metadata for mcr.microsoft.com/dotnet/aspnet:5.0-bust  0.0s ------  &gt; [internal] load metadata for mcr.microsoft.com/dotnet/sdk:5.0.201-buster-slim: ------ ERROR: Service 'frontdesk-api' failed to build </code></pre> <p>Things I've tried:</p> <ul> <li>Running it again</li> <li><code> docker rm -f $(docker ps -a -q)</code></li> <li><code>docker login</code></li> <li>Different SDK image</li> </ul> <p>Here is the DOCKERFILE:</p> <pre><code>FROM mcr.microsoft.com/dotnet/aspnet:5.0-buster-slim AS base WORKDIR /app EXPOSE 80 EXPOSE 443  FROM mcr.microsoft.com/dotnet/sdk:5.0.201-buster-slim AS build WORKDIR /app # run this from repository root COPY ./ ./  #RUN ls -lha .  RUN echo 'Building FrontDesk container'  WORKDIR /app/FrontDesk/src/FrontDesk.Api #RUN ls -lha . RUN dotnet restore  RUN dotnet build &quot;FrontDesk.Api.csproj&quot; -c Release -o /app/build  FROM build AS publish RUN dotnet publish &quot;FrontDesk.Api.csproj&quot; -c Release -o /app/publish  FROM base AS final WORKDIR /app COPY --from=publish /app/publish . ENTRYPOINT [&quot;dotnet&quot;, &quot;FrontDesk.Api.dll&quot;] </code></pre> <p>How can I get my build working again?</p> ",
    "OwnerUserId": "13729",
    "LastActivityDate": "2023-12-21T15:27:54.907",
    "Title": "Why is docker-compose failing with ERROR internal load metadata suddenly?",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "32",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "67642620",
    "PostTypeId": "1",
    "AcceptedAnswerId": "67643907",
    "CreationDate": "2021-05-21T19:03:01.900",
    "Score": "96",
    "ViewCount": "87563",
    "Body": "<p>I might have a bit of a messed Docker installation on my Mac.. At first I installed Docker desktop but then running it I learned that as I'm on an older Mac I had to install VirtualBox so I did following these steps:</p> <ol> <li><p>enable writing on the <code>/usr/local/bin</code> folder for user</p> <p><code>sudo chown -R $(whoami) /usr/local/bin</code></p> </li> <li><p>install Docker-Machine</p> </li> </ol> <pre class='lang-sh prettyprint-override'><code>base=https://github.com/docker/machine/releases/download/v0.16.0 &amp;&amp;   curl -L $base/docker-machine-$(uname -s)-$(uname -m) &gt;/usr/local/bin/docker-machine &amp;&amp;   chmod +x /usr/local/bin/docker-machine </code></pre> <ol start='3'> <li><p>install Xcode CLI..manually from dev account</p> </li> <li><p>Install Home Brew</p> </li> </ol> <pre class='lang-sh prettyprint-override'><code>/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot; </code></pre> <ol start='5'> <li><p>Install  Docker  + wget ( Using Brew)</p> <p><code>brew install docker</code></p> <p><code>brew install wget</code></p> </li> <li><p>Install bash completion scripts</p> </li> </ol> <pre class='lang-sh prettyprint-override'><code>base=https://raw.githubusercontent.com/docker/machine/v0.16.0 for i in docker-machine-prompt.bash docker-machine-wrapper.bash docker-machine.bash do     sudo wget &quot;$base/contrib/completion/bash/${i}&quot; -P /etc/bash_completion.d done </code></pre> <ol start='7'> <li><p>enable the docker-machine shell prompt</p> <p><code>echo 'PS1='[\\u@\\h \\W$(__docker_machine_ps1)]\\$ '' &gt;&gt; ~/.bashrc</code></p> </li> <li><p>Install VirtualBox, ExtensionPack and SDK: <a href='https://www.virtualbox.org/wiki/Downloads' rel='noreferrer'>https://www.virtualbox.org/wiki/Downloads</a></p> </li> </ol> <p>I now installed docker-compose (docker-compose version 1.29.2, build unknown) with home-brew but when running <code>docker-compose up</code> I get the following error:</p> <blockquote> <p><code>docker.credentials.errors.InitializationError: docker-credential-desktop not installed or not available in PATH</code></p> </blockquote> <p><code>which docker</code> prints /usr/local/bin/docker.</p> <p>Brew installations are in <code>/usr/local/Cellar/docker/20.10.6</code> and <code>/usr/local/Cellar/docker-compose/1.29.2</code>. As I see there is also a home-brew for docker-machine should I install docker-machine via home-brew instead?</p> <p>What can I check to make sure that I use the docker installations from home-brew and wipe/correct the installations made from steps above?</p> ",
    "OwnerUserId": "9663497",
    "LastEditorUserId": "1708751",
    "LastEditDate": "2022-02-16T17:37:11.043",
    "LastActivityDate": "2024-01-16T23:07:02.527",
    "Title": "docker-credential-desktop not installed or not available in PATH",
    "Tags": "<docker><docker-compose><homebrew><docker-machine>",
    "AnswerCount": "7",
    "CommentCount": "5",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "40801772",
    "PostTypeId": "1",
    "CreationDate": "2016-11-25T09:39:10.243",
    "Score": "956",
    "ViewCount": "625609",
    "Body": "<p>What is the difference between <code>ports</code> and <code>expose</code> options in <code>docker-compose.yml</code>?</p> ",
    "OwnerUserId": "84143",
    "LastEditorUserId": "8747928",
    "LastEditDate": "2022-10-21T11:26:46.430",
    "LastActivityDate": "2024-02-14T05:15:00.360",
    "Title": "What is the difference between ports and expose in docker-compose?",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "5",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "48727548",
    "PostTypeId": "1",
    "AcceptedAnswerId": "48730146",
    "CreationDate": "2018-02-11T02:03:45.517",
    "Score": "95",
    "ViewCount": "215950",
    "Body": "<p>I'm trying to connect two containers with a docker-compose-yml, but it isn't working. This is my docker-compose.yml file:</p> <pre class='lang-yaml prettyprint-override'><code>version: &quot;3&quot; services:     datapower:         build: .         ports:             - &quot;9090:9090&quot;         depends_on:             - db     db:         image: &quot;microsoft/mssql-server-linux:2017-latest&quot;         environment:             SA_PASSWORD: &quot;your_password&quot;             ACCEPT_EULA: &quot;Y&quot;         ports:         - &quot;1433:1433&quot; </code></pre> <p>When I make:</p> <blockquote> <p>docker-compose up</p> </blockquote> <p>This up my two containers. Then I stop one container and then I run the same container stoped independiently like:</p> <blockquote> <p>docker-compose run -u root --name nameofcontainer 'name of container named in docker-compose.yml'</p> </blockquote> <p>With this, the connection of the containers works. Exists a method to configure my docker-compose.yml to connect my containers like root without stop a container and run independently?</p> ",
    "OwnerUserId": "7288685",
    "LastEditorUserId": "1402846",
    "LastEditDate": "2020-07-16T10:08:25.307",
    "LastActivityDate": "2022-04-05T10:58:56.513",
    "Title": "How to configure docker-compose.yml to up a container as root",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "69054921",
    "PostTypeId": "1",
    "CreationDate": "2021-09-04T11:37:58.750",
    "Score": "94",
    "ViewCount": "137218",
    "Body": "<p>I want to run a docker container for <code>Ganache</code> on my MacBook M1, but get the following error:</p> <pre><code>The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested </code></pre> <p>After this line nothing else will happen anymore and the whole process is stuck, although the qemu-system-aarch64 is running on 100% CPU according to Activity Monitor until I press <kbd>CTRL</kbd>+<kbd>C</kbd>.</p> <p>My docker-files come from <a href='https://github.com/unlock-protocol/unlock/blob/master/docker/docker-compose.override.yml' rel='noreferrer'>this repository</a>. After running into the same issues there I tried to isolate the root cause and came up with the smallest setup that will run into the same error.</p> <p>This is the output of <code>docker-compose up --build</code>:</p> <pre><code>Building ganache Sending build context to Docker daemon  196.6kB Step 1/17 : FROM trufflesuite/ganache-cli:v6.9.1  ---&gt; 40b011a5f8e5 Step 2/17 : LABEL Unlock &lt;ops@unlock-protocol.com&gt;  ---&gt; Using cache  ---&gt; aad8a72dac4e Step 3/17 : RUN apk add --no-cache git openssh bash  ---&gt; Using cache  ---&gt; 4ca6312438bd Step 4/17 : RUN apk add --no-cache   python   python-dev   py-pip   build-base   &amp;&amp; pip install virtualenv  ---&gt; Using cache  ---&gt; 0be290f541ed Step 5/17 : RUN npm install -g npm@6.4.1  ---&gt; Using cache  ---&gt; d906d229a768 Step 6/17 : RUN npm install -g yarn  ---&gt; [Warning] The requested image's platform (linux/amd64) does not match the detected host platform (linux/arm64/v8) and no specific platform was requested  ---&gt; Running in 991c1d804fdf </code></pre> <p><strong>docker-compose.yml:</strong></p> <pre><code>version: '3.2' services:   ganache:     restart: always     build:       context: ./development       dockerfile: ganache.dockerfile     env_file: ../.env.dev.local     ports:       - 8545:8545    ganache-standup:     image: ganache-standup     build:       context: ./development       dockerfile: ganache.dockerfile     env_file: ../.env.dev.local     entrypoint: ['node', '/standup/prepare-ganache-for-unlock.js']     depends_on:       - ganache </code></pre> <p><strong>ganache.dockerfile:</strong></p> <p>The ganache.dockerfile can be found <a href='https://github.com/unlock-protocol/unlock/blob/master/docker/development/ganache.dockerfile' rel='noreferrer'>here</a>.</p> <p>Running the whole project on an older iMac with Intel-processor works fine.</p> ",
    "OwnerUserId": "6727976",
    "LastEditorUserId": "7487335",
    "LastEditDate": "2022-05-31T22:48:23.297",
    "LastActivityDate": "2023-06-07T08:46:01.750",
    "Title": "Docker on Mac M1 gives: 'The requested image's platform (linux/amd64) does not match the detected host platform'",
    "Tags": "<docker><docker-compose><arm><apple-m1>",
    "AnswerCount": "8",
    "CommentCount": "4",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "32360687",
    "PostTypeId": "1",
    "AcceptedAnswerId": "32361238",
    "CreationDate": "2015-09-02T18:34:18.940",
    "Score": "93",
    "ViewCount": "148754",
    "Body": "<p>I have a docker mysql image running, following is what the docker-compose.yml file looks like:</p>  <pre><code>db:   image: mysql   environment:     MYSQL_ROOT_PASSWORD: ''     MYSQL_ALLOW_EMPTY_PASSWORD: yes   ports:     - '3306:3306' </code></pre>  <p>This works fine.</p>  <p>My question is: How can I connect to the MySQL instance running on that container from the command line mysql client on my the host (my macbook)?</p>  <p>To clarify:</p>  <ul> <li>I have a macbook with Docker installed</li> <li>I have a docker container with mysql</li> <li>I want to connect to the mysql instance running on the aforementioned container from the Terminal on my macbook</li> <li>I do NOT want to user a <code>docker</code> command to make this possible. Rather, I want to use the <code>mysql</code> client directly from the Terminal (without tunneling in through a docker container).</li> </ul>  <p>I don't have MySQL running locally, so port 3306 should be open and ready to use.</p>  <p>The command I am using to start the container is: <code>docker-compose run</code></p> ",
    "OwnerUserId": "507151",
    "LastEditorUserId": "507151",
    "LastEditDate": "2015-09-04T22:34:54.073",
    "LastActivityDate": "2021-01-07T07:22:15.477",
    "Title": "Connect to Docker MySQL container from localhost?",
    "Tags": "<mysql><macos><docker><docker-compose>",
    "AnswerCount": "8",
    "CommentCount": "3",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "39204142",
    "PostTypeId": "1",
    "AcceptedAnswerId": "39210054",
    "CreationDate": "2016-08-29T10:35:24.407",
    "Score": "93",
    "ViewCount": "135544",
    "Body": "<p>I'm trying to figure out how to implement docker using docker-compose.yml with 2 databases imported from sql dumps.</p>  <pre><code>httpd:     container_name: webserver     build: ./webserver/     ports:         - 80:80     links:         - mysql         - mysql2     volumes_from:         - app  mysql:     container_name: sqlserver     image: mysql:latest     ports:         - 3306:3306     volumes:         - ./sqlserver:/docker-entrypoint-initdb.d     environment:         MYSQL_ROOT_PASSWORD: root         MYSQL_DATABASE: dbname1         MYSQL_USER: dbuser         MYSQL_PASSWORD: dbpass  mysql2:     extends: mysql     container_name: sqlserver2     environment:         MYSQL_ROOT_PASSWORD: root         MYSQL_DATABASE: dbname2         MYSQL_USER: dbuser         MYSQL_PASSWORD: dbpass  app:     container_name: webdata     image: php:latest     volumes:         - ../php:/var/www/html     command: 'true' </code></pre>  <p>The above returns the following:</p>  <pre><code>Kronos:mybuild avanche$ ./run.sh  Creating sqlserver Creating webdata Creating sqlserver2  ERROR: for mysql2  driver failed programming external connectivity on endpoint sqlserver2 (6cae3dfe7997d3787a8d59a95c1b5164f7431041c1394128c14e5ae8efe647a8): Bind for 0.0.0.0:3306 failed: port is already allocated Traceback (most recent call last):   File '&lt;string&gt;', line 3, in &lt;module&gt;   File 'compose/cli/main.py', line 63, in main AttributeError: 'ProjectError' object has no attribute 'msg' docker-compose returned -1 </code></pre>  <p>Basically, I'm trying to get my whole stack setup in a single docker compose file, create 2 databases and import the respective sql dumps. Anyone have any suggestions?</p> ",
    "OwnerUserId": "1158019",
    "LastEditorUserId": "1158019",
    "LastEditDate": "2016-08-29T11:09:53.443",
    "LastActivityDate": "2024-01-13T04:27:29.530",
    "Title": "docker-compose with multiple databases",
    "Tags": "<database><docker><docker-compose>",
    "AnswerCount": "13",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "45109398",
    "PostTypeId": "1",
    "CreationDate": "2017-07-14T18:18:36.217",
    "Score": "93",
    "ViewCount": "130371",
    "Body": "<p>In recent versions <code>docker-compose</code> automatically creates a new network for the services it creates. Basically, every <code>docker-compose</code> setup is getting its own IP range, so that in theory I could call my services on the network's IP address with the predefined ports. This is great when developing multiple projects at the same time, since there is then no need to change the ports in <code>docker-compose.yml</code> (i.e. I can run multiple <code>nginx</code> projects at the same time on port 8080 on different interfaces)</p>  <p>However, this does not work as intended: every exposed port is still exposed on 0.0.0.0 and thus there are port conflicts with multiple projects. It is possible to put the bind IP into <code>docker-compose.yml</code>, however this is a killer for portability -- not every developer on the team uses the same OS or works on the same projects, therefore it's not clear which IP to configure.</p>  <p>It's be great to define the IP to bind the containers to in terms of the network created for this particular project. <code>docker-compose</code> should both know which network it created as well as its IP, so this shouldn't be a problem, however I couldn't find an easy way to do it. Is there a way or is this something yet to be implemented?</p>  <p>EDIT: An example of a port conflict: imagine two projects, each with an application server running on port 8080 and a MySQL database running on port 3306, both respectively exposed as '8080:8080' and '3306:3306'. Running the first one with <code>docker-compose</code> creates a network called something like <code>app1_network</code> with an IP range of 172.18.0.0/16. Every exposed port is exposed on 0.0.0.0, i.e. on 127.0.0.1, on the WAN address, on the default bridge (172.17.0.0/16) and also on the 172.18.0.0/16. In this case I can reach my application server of all of 127.0.0.1:8080, 172.17.0.1:8080, 172.18.0.1:8080 and als on <code>$WAN_IP:8080</code>. If I start the second application now, it starts a second network <code>app2_network</code> 172.19.0.0/16, but still tries to bind every exposed port on all interfaces. Those ports are of course already taken (except for 172.19.0.1). If there had been a possibility to restrict each application to its network, application 1 would have available at 172.18.0.1:8080 and the second at 172.19.0.1:8080 and I wouldn't need to change port mappings to 8081 and 3307 respectively to run both applications at the same time. </p> ",
    "OwnerUserId": "6460",
    "LastEditorUserId": "6460",
    "LastEditDate": "2017-07-14T19:09:04.970",
    "LastActivityDate": "2021-07-05T07:26:48.393",
    "Title": "How can I make docker-compose bind the containers only on defined network instead of 0.0.0.0?",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "3",
    "CommentCount": "6",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "53093487",
    "PostTypeId": "1",
    "AcceptedAnswerId": "53101932",
    "CreationDate": "2018-10-31T23:59:03.717",
    "Score": "93",
    "ViewCount": "81032",
    "Body": "<p>How can I specify multi-stage build with in a <code>docker-compose.yml</code>?</p>  <p>For each variant (e.g. dev, prod...) I have a multi-stage build with 2 docker files:</p>  <ul> <li>dev: <code>Dockerfile.base</code> + <code>Dockerfile.dev</code></li> <li>or prod: <code>Dockerfile.base</code> + <code>Dockerfile.prod</code></li> </ul>  <p>File <code>Dockerfile.base</code> (common for all variants):</p>  <pre><code>FROM python:3.6 RUN apt-get update &amp;&amp; apt-get upgrade -y RUN pip install pipenv pip COPY Pipfile ./ # some more common configuration... </code></pre>  <p>File <code>Dockerfile.dev</code>:</p>  <pre><code>FROM flaskapp:base RUN pipenv install --system --skip-lock --dev ENV FLASK_ENV development ENV FLASK_DEBUG 1 </code></pre>  <p>File <code>Dockerfile.prod</code>:</p>  <pre><code>FROM flaskapp:base RUN pipenv install --system --skip-lock ENV FLASK_ENV production </code></pre>  <p>Without docker-compose, I can build as:</p>  <pre><code># Building dev docker build --tag flaskapp:base -f Dockerfile.base . docker build --tag flaskapp:dev -f Dockerfile.dev . # or building prod docker build --tag flaskapp:base -f Dockerfile.base . docker build --tag flaskapp:dev -f Dockerfile.dev . </code></pre>  <p>According to the <a href='https://docs.docker.com/compose/compose-file/#build' rel='noreferrer'>compose-file doc</a>, I can specify a Dockerfile to build.</p>  <pre><code># docker-compose.yml version: '3' services:   webapp:     build:       context: ./dir       dockerfile: Dockerfile-alternate </code></pre>  <p>But how can I specify 2 Dockerfiles in <code>docker-compose.yml</code> (for multi-stage build)?</p> ",
    "OwnerUserId": "3858883",
    "LastActivityDate": "2020-04-30T16:06:48.007",
    "Title": "multi-stage build in docker compose?",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "70256928",
    "PostTypeId": "1",
    "AcceptedAnswerId": "70257438",
    "CreationDate": "2021-12-07T08:24:21.110",
    "Score": "93",
    "ViewCount": "203823",
    "Body": "<p>I had setup Docker Desktop with Windows WSL integration version 2 and I run into issue when execute certain <code>docker compose</code> command with following errors</p> <pre><code>docker compose logs no configuration file provided: not found </code></pre> <p>However, there were no problem found when executing the following</p> <pre><code>docker compose up </code></pre> <p>and image built and fired up successfully.</p> <p>Is there anyone who can help with this?</p> <hr /> <h3>Output of <code>docker info</code></h3> <pre><code>Client:  Context:    default  Debug Mode: false  Plugins:   buildx: Docker Buildx (Docker Inc., v0.7.1)   compose: Docker Compose (Docker Inc., v2.2.1)   scan: Docker Scan (Docker Inc., 0.9.0)  Server:  Containers: 3   Running: 3   Paused: 0   Stopped: 0  Images: 4  Server Version: 20.10.11  Storage Driver: overlay2   Backing Filesystem: extfs   Supports d_type: true   Native Overlay Diff: true   userxattr: false  Logging Driver: json-file  Cgroup Driver: cgroupfs  Cgroup Version: 1  Plugins:   Volume: local   Network: bridge host ipvlan macvlan null overlay   Log: awslogs fluentd gcplogs gelf journald json-file local logentries splunk syslog  Swarm: inactive  Runtimes: io.containerd.runc.v2 io.containerd.runtime.v1.linux runc  Default Runtime: runc  Init Binary: docker-init  containerd version: 7b11cfaabd73bb80907dd23182b9347b4245eb5d  runc version: v1.0.2-0-g52b36a2  init version: de40ad0  Security Options:   seccomp    Profile: default  Kernel Version: 5.10.60.1-microsoft-standard-WSL2  Operating System: Docker Desktop  OSType: linux  Architecture: x86_64  CPUs: 8  Total Memory: 24.95GiB  Name: docker-desktop  ID: FUMA:ZOXR:BA4L:YSOZ:4NQT:HHIZ:ASAD:EJGA:NJRG:SO4S:GXN3:JG5H  Docker Root Dir: /var/lib/docker  Debug Mode: false  Registry: https://index.docker.io/v1/  Labels:  Experimental: false  Insecure Registries:   127.0.0.0/8  Live Restore Enabled: false  WARNING: No blkio throttle.read_bps_device support WARNING: No blkio throttle.write_bps_device support WARNING: No blkio throttle.read_iops_device support WARNING: No blkio throttle.write_iops_device support </code></pre> <hr /> <h1>UPDATED</h1> <p>It was my mistake that I should execute the <code>docker compose</code> command under the correct directory where <code>docker-compose.yml</code> file located at.</p> <p>The issue is resolved.</p> ",
    "OwnerUserId": "7928825",
    "LastEditorUserId": "814702",
    "LastEditDate": "2023-10-10T19:09:36.553",
    "LastActivityDate": "2024-02-05T11:30:23.623",
    "Title": "Docker Compose prompted error: no configuration file provided: not found",
    "Tags": "<docker><docker-compose><windows-subsystem-for-linux><docker-desktop>",
    "AnswerCount": "11",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "33799885",
    "PostTypeId": "1",
    "AcceptedAnswerId": "41841714",
    "CreationDate": "2015-11-19T09:30:17.317",
    "Score": "91",
    "ViewCount": "37389",
    "Body": "<p>Up until recently, when one was doing <code>docker-compose up</code> for a bunch of containers and one of the started containers stopped, all of the containers were stopped. This is not the case anymore since <a href='https://github.com/docker/compose/issues/741' rel='noreferrer'>https://github.com/docker/compose/issues/741</a> and this is a really annoying for us: We use docker-compose to run selenium tests which means starting application server, starting selenium hub + nodes, starting tests driver, then exiting when tests driver stops.</p>  <p>Is there a way to get back old behaviour?</p> ",
    "OwnerUserId": "137871",
    "LastEditorUserId": "11248508",
    "LastEditDate": "2020-06-20T09:05:06.897",
    "LastActivityDate": "2020-06-20T09:05:06.897",
    "Title": "How to stop all containers when one container stops with docker-compose?",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "4",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "29061026",
    "PostTypeId": "1",
    "CreationDate": "2015-03-15T13:17:51.473",
    "Score": "90",
    "ViewCount": "156707",
    "Body": "<p>I want to create a <strong>docker-compose</strong> file that is able to run on different servers. </p>  <p>For that I have to be able to specify the host-ip or hostname of the server (where all the containers are running) in several places in the <strong>docker-compose.yml</strong>. </p>  <p>E.g. for a consul container where I want to define how the server can be found by fellow consul containers.</p>  <pre><code>consul:   image: progrium/consul   command: -server -advertise 192.168.1.125 -bootstrap </code></pre>  <p>I don't want to hardcode 192.168.1.125 obviously.</p>  <p>I could use  <strong><a href='https://docs.docker.com/compose/env-file/' rel='noreferrer'>env_file</a>:</strong> to specify the hostname or ip and adopt it on every server, so I have that information in one place and use that in docker-compose.yml. But this can only be used to specifiy environment variables and not for the advertise parameter.</p>  <p>Is there a better solution?</p> ",
    "OwnerUserId": "2425939",
    "LastEditorUserId": "598513",
    "LastEditDate": "2019-01-08T10:47:12.313",
    "LastActivityDate": "2023-09-04T15:32:34.940",
    "Title": "Using the host ip in docker-compose",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "7",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "30040708",
    "PostTypeId": "1",
    "CreationDate": "2015-05-04T21:58:47.083",
    "Score": "90",
    "ViewCount": "74625",
    "Body": "<p>I am trying to use docker-machine with docker-compose. The file docker-compose.yml has definitions as follows:</p>  <pre><code>web:   build: .   command: ./run_web.sh   volumes:     - .:/app   ports:     - '8000:8000'   links:     - db:db     - rabbitmq:rabbit     - redis:redis </code></pre>  <p>When running <code>docker-compose up -d</code> all goes well until trying to execute the command and an error is produced:</p>  <blockquote>   <p>Cannot start container b58e2dfa503b696417c1c3f49e2714086d4e9999bd71915a53502cb6ef43936d: [8] System error: exec: './run_web.sh': stat ./run_web.sh: no such file or directory</p> </blockquote>  <p>Local volumes are not mounted to the remote machine. Whats the recommended strategy to mount the local volumes with the webapps' code?</p> ",
    "OwnerUserId": "1675422",
    "LastEditorUserId": "7225971",
    "LastEditDate": "2017-01-05T13:21:44.913",
    "LastActivityDate": "2019-12-20T02:49:25.207",
    "Title": "How to mount local volumes in docker machine",
    "Tags": "<docker><dockerfile><docker-compose>",
    "AnswerCount": "12",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "38086453",
    "PostTypeId": "1",
    "AcceptedAnswerId": "38095099",
    "CreationDate": "2016-06-28T21:17:12.450",
    "Score": "90",
    "ViewCount": "135166",
    "Body": "<p>I have following docker command to run container </p>  <pre><code>docker run -d --name test -v /etc/hadoop/conf:/etc/hadoop/conf -v /usr/lib/python2.7/dist-packages/hdinsight_common:/usr/lib/python2.7/dist-packages/hdinsight_common -v /etc/hive/conf/:/etc/hive/conf/ -v /etc/tez/conf/:/etc/tez/conf/ -v /usr/hdp/2.4.2.0-258/sqoop/lib/:/usr/hdp/2.4.2.0-258/sqoop/lib/ -i -t hdinsight /bin/bash </code></pre>  <p>This was to complicated so I was trying to create docker-compose file like this</p>  <pre><code>version: '2' services:   hdinsight:     image: hdinsight     container_name: ABC     volumes:      - /etc/hadoop/conf:/etc/hadoop/conf      - /usr/lib/python2.7/dist-packages/hdinsight_common:/usr/lib/python2.7/dist-packages/hdinsight_common      - /etc/hive/conf/:/etc/hive/conf/      - /etc/tez/conf/:/etc/tez/conf/      - /usr/hdp/2.4.2.0-258/sqoop/lib/:/usr/hdp/2.4.2.0-258/sqoop/lib/     entrypoint:      - bash     labels:      - 'HDInsight client VM' </code></pre>  <p>But I am not sure where to pass <code>-d</code>, <code>-i</code> &amp; <code>-t</code> flages from my original docker run command</p>  <p>I was running docker-compose like this </p>  <pre><code>docker-compose -f docker-compose.yml run hdinsight </code></pre>  <p>can anyone point me to right direction here ?</p>  <p>UPDATE after first answer </p>  <p>I tried to run <code>docker-compose up -d</code></p>  <pre><code>root@abc-docker:~/ubuntu# docker-compose up -d Creating ABC root@sbd-docker:~/ubuntu# docker ps -a CONTAINER ID        IMAGE               COMMAND             CREATED             STATUS                     PORTS               NAMES ffa4c359abf7        hdinsight           '/bin/bash'         5 seconds ago       Exited (0) 5 seconds ago                       ABC root@sbd-docker:~/ubuntu# </code></pre>  <p>Dont know why its in <code>Exited</code> status</p>  <p>Any idea ?</p>  <p>Thanks</p> ",
    "OwnerUserId": "3579198",
    "LastEditorUserId": "3579198",
    "LastEditDate": "2016-06-29T12:27:54.210",
    "LastActivityDate": "2022-01-14T21:46:02.897",
    "Title": "docker-compose for Detached mode",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "5",
    "CommentCount": "3",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "47223280",
    "PostTypeId": "1",
    "AcceptedAnswerId": "47336776",
    "CreationDate": "2017-11-10T12:55:06.133",
    "Score": "90",
    "ViewCount": "111645",
    "Body": "<p><strong>Issue</strong>: Can not stop docker containers, whenever I try to stop containers I get the following Error message,</p>  <pre><code>ERROR: for yattyadocker_web_1  cannot stop container: 1f04148910c5bac38983e6beb3f6da4c8be3f46ceeccdc8d7de0da9d2d76edd8: Cannot kill container 1f04148910c5bac38983e6beb3f6da4c8be3f46ceeccdc8d7de0da9d2d76edd8: rpc error: code = PermissionDenied desc = permission denied </code></pre>  <p><strong>OS Version/build:</strong> Ubuntu 16.04 | Docker Version 17.09.0-ce, build afdb6d4 | Docker Compose version 1.17.1, build 6d101fb</p>  <p><strong>Steps to reproduce:</strong></p>  <ul> <li>Created a rails project with Dockerfile and docker-compose.yml. docker-compose.yml is of version 3.</li> <li>Image is built successfully with either <code>docker build -t &lt;project name&gt; .</code> or <code>docker-compose up --build</code></li> <li>Containers boots up and runs successfully.</li> <li>Try to stop docker compose with docker-compose down.</li> </ul>  <p><strong>What I tried:</strong>: </p>  <ul> <li>I have to run <code>sudo service docker restart</code> and then the containers can be removed.</li> <li>Uninstalled docker, removed docker directory and then re installed everything. Still facing same issue. </li> </ul>  <p><strong>Note</strong>: This configuration was working correctly earlier, but somehow file permissions might have changed and I am seeing this error. I have to run <code>sudo service docker restart</code> and then the containers can be removed. But this is highly inconvenient and I don't know how to troubleshoot this.</p>  <p><strong>Reference Files:</strong></p>  <pre><code># docker-compose.yml version: '3' volumes:   db-data:     driver: local   redis-data:     driver: local   services:   db:     image: postgres:9.4.1     volumes:       - db-data:/var/lib/postgresql/data     ports:       - '5432:5432'     env_file: local_envs.env   web:     image: yattya_docker:latest     command: bundle exec puma -C config/puma.rb     tty: true     stdin_open: true     ports:       - '3000:3000'     links:       - db       - redis       - memcached     depends_on:       - db       - redis       - memcached     env_file: local_envs.env   redis:     image: redis:3.2.4-alpine     ports:       # We'll bind our host's port 6379 to redis's port 6379, so we can use       # Redis Desktop Manager (or other tools) with it:       - 6379:6379     volumes:       # We'll mount the 'redis-data' volume into the location redis stores it's data:       - redis-data:/var/lib/redis     command: redis-server --appendonly yes   memcached:     image: memcached:1.5-alpine     ports:       - '11211:11211'   clock:     image: yattya_docker:latest     command: bundle exec clockwork lib/clock.rb     links:       - db     depends_on:       - db     env_file: local_envs.env   worker:     image: yattya_docker:latest     command: bundle exec rake jobs:work     links:        - db     depends_on:        - db     env_file: local_envs.env </code></pre>  <p>And Dockerfile:</p>  <pre><code># Dockerfile FROM ruby:2.4.1  RUN apt-get update &amp;&amp; apt-get install -y nodejs --no-install-recommends &amp;&amp; rm -rf /var/lib/apt/lists/*  ENV APP_HOME /app RUN mkdir -p $APP_HOME WORKDIR $APP_HOME  ADD Gemfile* $APP_HOME/ RUN bundle install  ADD . $APP_HOME  RUN mkdir -p ${APP_HOME}/log RUN cat /dev/null &gt; '$APP_HOME/log/development.log'  RUN mkdir -p ${APP_HOME}/tmp/cache \\     &amp;&amp; mkdir -p ${APP_HOME}/tmp/pids \\     &amp;&amp; mkdir -p ${APP_HOME}/tmp/sockets  EXPOSE 3000 </code></pre> ",
    "OwnerUserId": "4933185",
    "LastEditorUserId": "4933185",
    "LastEditDate": "2017-11-16T11:46:07.410",
    "LastActivityDate": "2024-01-29T12:36:52.313",
    "Title": "Docker Containers can not be stopped or removed - permission denied Error",
    "Tags": "<ruby-on-rails><docker><docker-compose><docker-swarm>",
    "AnswerCount": "10",
    "CommentCount": "7",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "59296801",
    "PostTypeId": "1",
    "AcceptedAnswerId": "59297469",
    "CreationDate": "2019-12-12T02:21:39.550",
    "Score": "90",
    "ViewCount": "235927",
    "Body": "<p>When I run the following command, I expect the exit code to be 0 since my <code>combined</code> container runs a test that successfully exits with an exit code of 0.</p>  <pre><code>docker-compose up --build --exit-code-from combined </code></pre>  <p>Unfortunately, I consistently receive an exit code of 137 even when the tests in my <code>combined</code> container run successfully and I exit that container with an exit code of 0 (more details on how that happens are specified below).</p>  <p>Below is my docker-compose version:</p>  <pre><code>docker-compose version 1.25.0, build 0a186604 </code></pre>  <p>According to this <a href='https://success.docker.com/article/what-causes-a-container-to-exit-with-code-137' rel='noreferrer'>post</a>, the exit code of 137 can be due to two main issues.</p>  <ol> <li>The container received a <code>docker stop</code> and the app is not gracefully handling SIGTERM</li> <li>The container has run out of memory (OOM).</li> </ol>  <p><em>I know the 137 exit code is not because my container has run out of memory.</em> When I run <code>docker inspect &lt;container-id&gt;</code>, I can see that 'OOMKilled' is false as shown in the snippet below. I also have 6GB of memory allocated to the Docker Engine which is plenty for my application.</p>  <pre><code>[     {         'Id': 'db4a48c8e4bab69edff479b59d7697362762a8083db2b2088c58945fcb005625',         'Created': '2019-12-12T01:43:16.9813461Z',         'Path': '/scripts/init.sh',         'Args': [],         'State': {             'Status': 'exited',             'Running': false,             'Paused': false,             'Restarting': false,             'OOMKilled': false, &lt;---- shows container did not run out of memory             'Dead': false,             'Pid': 0,             'ExitCode': 137,             'Error': '',             'StartedAt': '2019-12-12T01:44:01.346592Z',             'FinishedAt': '2019-12-12T01:44:11.5407553Z'         }, </code></pre>  <p><em>My container doesn't exit from a <code>docker stop</code> so I don't think the first reason is relevant to my situation either.</em></p>  <p><strong>How my Docker containers are set up</strong></p>  <p>I have two Docker containers:</p>  <ol> <li><strong>b-db</strong> - contains my database</li> <li><strong>b-combined</strong> - contains my web application and a series of tests, which run once the container is up and running.</li> </ol>  <p>I'm using a docker-compose.yml file to start both containers.</p>  <pre><code>version: '3' services:     db:         build:             context: .             dockerfile: ./docker/db/Dockerfile         container_name: b-db         restart: unless-stopped         volumes:                  - dbdata:/data/db         ports:             - '27017:27017'         networks:             - app-network      combined:         build:             context: .             dockerfile: ./docker/combined/Dockerfile         container_name: b-combined         restart: unless-stopped         env_file: .env         ports:             - '5000:5000'             - '8080:8080'         networks:             - app-network         depends_on:             - db  networks:     app-network:         driver: bridge  volumes:     dbdata:     node_modules: </code></pre>  <p>Below is the Dockerfile for the <code>combined</code> service in <code>docker-compose.yml</code>.</p>  <pre><code>FROM cypress/included:3.4.1  WORKDIR /usr/src/app  COPY package*.json ./  RUN npm install  COPY . .  EXPOSE 5000  RUN npm install -g history-server nodemon  RUN npm run build-test  EXPOSE 8080  COPY ./docker/combined/init.sh /scripts/init.sh  RUN ['chmod', '+x', '/scripts/init.sh']  ENTRYPOINT [ '/scripts/init.sh' ] </code></pre>  <p>Below is what is in my <code>init.sh</code> file.</p>  <pre><code>#!/bin/bash # Start front end server history-server dist -p 8080 &amp; front_pid=$!  # Start back end server that interacts with DB nodemon -L server &amp; back_pid=$!  # Run tests NODE_ENV=test $(npm bin)/cypress run --config video=false --browser chrome  # Error code of the test test_exit_code=$?  echo 'TEST ENDED WITH EXIT CODE OF: $test_exit_code'  # End front and backend server kill -9 $front_pid kill -9 $back_pid  # Exit with the error code of the test echo 'EXITING SCRIPT WITH EXIT CODE OF: $test_exit_code' exit '$test_exit_code' </code></pre>  <p>Below is the Dockerfile for my <code>db</code> service. All its doing is copying some local data into the Docker container and then initialising the database with this data.</p>  <pre><code>FROM  mongo:3.6.14-xenial  COPY ./dump/ /tmp/dump/  COPY mongo_restore.sh /docker-entrypoint-initdb.d/  RUN chmod 777 /docker-entrypoint-initdb.d/mongo_restore.sh </code></pre>  <p>Below is what is in <code>mongo_restore.sh</code>.</p>  <pre><code>#!/bin/bash # Creates db using copied data mongorestore /tmp/dump </code></pre>  <p>Below are the last few lines of output when I run <code>docker-compose up --build --exit-code-from combined; echo $?</code>.</p>  <pre><code>... b-combined | user disconnected b-combined | Mongoose disconnected b-combined | Mongoose disconnected through Heroku app shutdown b-combined | TEST ENDED WITH EXIT CODE OF: 0 =========================== b-combined | EXITING SCRIPT WITH EXIT CODE OF: 0 ===================================== Aborting on container exit... Stopping b-combined   ... done 137 </code></pre>  <p><strong>What is confusing as you can see above, is that the test and script ended with exit code of 0 since all my tests passed successfully but the container still exited with an exit code of 137.</strong> </p>  <p><strong>What is even more confusing is that when I comment out the following line (which runs my Cypress integration tests) from my <code>init.sh</code> file, the container exits with a 0 exit code as shown below.</strong></p>  <pre><code>NODE_ENV=test $(npm bin)/cypress run --config video=false --browser chrome </code></pre>  <p>Below is the output I receive when I comment out / remove the above line from <code>init.sh</code>, which is a command that runs my Cypress integration tests.</p>  <pre><code>... b-combined | TEST ENDED WITH EXIT CODE OF: 0 =========================== b-combined | EXITING SCRIPT WITH EXIT CODE OF: 0 ===================================== Aborting on container exit... Stopping b-combined   ... done 0 </code></pre>  <p><strong>How do I get docker-compose to return me a zero exit code when my tests run successfully and a non-zero exit code when they fail?</strong></p>  <p><strong>EDIT:</strong> </p>  <p>After running the following docker-compose command in debug mode, I noticed that b-db seems to have some trouble shutting down and potentially is receiving a SIGKILL signal from Docker because of that.</p>  <pre><code>docker-compose --log-level DEBUG up --build --exit-code-from combined; echo $? </code></pre>  <p>Is this indeed the case according to the following output?</p>  <pre><code>... b-combined exited with code 0 Aborting on container exit... http://localhost:None 'GET /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/json HTTP/1.1' 200 None http://localhost:None 'GET /v1.25/containers/json?limit=-1&amp;all=1&amp;size=0&amp;trunc_cmd=0&amp;filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Db-property%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1' 200 3819 http://localhost:None 'GET /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/json HTTP/1.1' 200 None http://localhost:None 'GET /v1.25/containers/0626d6bf49e5236440c82de4e969f31f4f86280d6f8f555f05b157fa53bae9b8/json HTTP/1.1' 200 None http://localhost:None 'GET /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/json HTTP/1.1' 200 None http://localhost:None 'GET /v1.25/containers/json?limit=-1&amp;all=0&amp;size=0&amp;trunc_cmd=0&amp;filters=%7B%22label%22%3A+%5B%22com.docker.compose.project%3Db-property%22%2C+%22com.docker.compose.oneoff%3DFalse%22%5D%7D HTTP/1.1' 200 4039 http://localhost:None 'POST /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/attach?logs=0&amp;stdout=1&amp;stderr=1&amp;stream=1 HTTP/1.1' 101 0 http://localhost:None 'GET /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/json HTTP/1.1' 200 None http://localhost:None 'GET /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/json HTTP/1.1' 200 None http://localhost:None 'GET /v1.25/containers/0626d6bf49e5236440c82de4e969f31f4f86280d6f8f555f05b157fa53bae9b8/json HTTP/1.1' 200 None Stopping b-combined   ... Stopping b-db         ... Pending: {&lt;Container: b-db (0626d6)&gt;, &lt;Container: b-combined (196f3e)&gt;} Starting producer thread for &lt;Container: b-combined (196f3e)&gt; http://localhost:None 'GET /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/json HTTP/1.1' 200 None http://localhost:None 'GET /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/json HTTP/1.1' 200 None Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} http://localhost:None 'GET /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/json HTTP/1.1' 200 None Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} Pending: {&lt;Container: b-db (0626d6)&gt;} http://localhost:None 'POST /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/wait HTTP/1.1' 200 32 http://localhost:None 'POST /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/stop?t=10 HTTP/1.1' 204 0 http://localhost:None 'GET /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/json HTTP/1.1' 200 None http://localhost:None 'POST /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561bStopping b-combined   ... done Finished processing: &lt;Container: b-combined (196f3e)&gt; Pending: {&lt;Container: b-db (0626d6)&gt;} Starting producer thread for &lt;Container: b-db (0626d6)&gt; http://localhost:None 'GET /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/json HTTP/1.1' 200 None http://localhost:None 'GET /v1.25/containers/0626d6bf49e5236440c82de4e969f31f4f86280d6f8f555f05b157fa53bae9b8/json HTTP/1.1' 200 None Pending: set() Pending: set() Pending: set() Pending: set() Pending: set() Pending: set() http://localhost:None 'GET /v1.25/containers/0626d6bf49e5236440c82de4e969f31f4f86280d6f8f555f05b157fa53bae9b8/json HTTP/1.1' 200 None http://localhost:None 'POST /v1.25/containers/0626d6bf49e5236440c82de4e969f31f4f86280d6f8f555f05b157fa53bae9b8/stop?t=10 HTTP/1.1' 204 0 http://localhost:None 'POST /v1.25/containers/0626d6bf49e5236440c82de4e969f31f4f86280d6f8f555f05b157fa53bae9b8/wait HTTP/1.1' 200 30 Stopping b-db         ... done Pending: set() http://localhost:None 'GET /v1.25/containers/0626d6bf49e5236440c82de4e969f31f4f86280d6f8f555f05b157fa53bae9b8/json HTTP/1.1' 200 None http://localhost:None 'GET /v1.25/containers/196f3e622847b4c4c82d8d761f9f19155561be961eecfe874bbb04def5b7c9e5/json HTTP/1.1' 200 None 137 </code></pre> ",
    "OwnerUserId": "7489488",
    "LastEditorUserId": "7489488",
    "LastEditDate": "2019-12-12T04:43:07.133",
    "LastActivityDate": "2023-07-19T15:35:57.000",
    "Title": "Docker-compose exit code is 137 when there is no OOM exception",
    "Tags": "<docker><docker-compose><cypress>",
    "AnswerCount": "9",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "59715622",
    "PostTypeId": "1",
    "AcceptedAnswerId": "59715738",
    "CreationDate": "2020-01-13T11:20:17.247",
    "Score": "90",
    "ViewCount": "94001",
    "Body": "<p>I have a question. I am pretty new to docker, so what I am trying to do is create a docker-compose file that on compose command will also create the database. Problem is that does not create DB as I ask it nicely. So my docker-compose looks like:</p>  <pre><code>version: '3'  services:   db:     image: postgres:latest     restart: always     ports:       - 5432:5432     environment:       POSTGRES_PASSWORD: 'postgres'     volumes:       - database_data:/var/lib/postgresql/data       - ./init.sql:/docker-entrypoint-initdb.d/init.sql  volumes:   database_data:     driver: local </code></pre>  <p>And when I start docker-compose up in log I can see</p>  <pre><code>db_1  | PostgreSQL Database directory appears to contain a database; Skipping initialization db_1  | db_1  | 2020-01-13 11:14:36.259 UTC [1] LOG:  starting PostgreSQL 12.1 (Debian 12.1-1.pgdg100+1) on x86_64-pc-linux-gnu, compiled by gcc (Debian 8.3.0-6) 8.3.0, 64-bit db_1  | 2020-01-13 11:14:36.259 UTC [1] LOG:  listening on IPv4 address '0.0.0.0', port 5432 db_1  | 2020-01-13 11:14:36.260 UTC [1] LOG:  listening on IPv6 address '::', port 5432 db_1  | 2020-01-13 11:14:36.264 UTC [1] LOG:  listening on Unix socket '/var/run/postgresql/.s.PGSQL.5432' db_1  | 2020-01-13 11:14:36.277 UTC [29] LOG:  database system was shut down at 2020-01-13 11:10:57 UTC db_1  | 2020-01-13 11:14:36.280 UTC [1] LOG:  database system is ready to accept connections </code></pre>  <p>In my init SQL there is only 1 line:</p>  <pre><code>CREATE DATABASE 'MyDataBase'; </code></pre>  <p>As I list DB is Postgres container my DB is nowhere to be found. What could be the source root of this problem?</p> ",
    "OwnerUserId": "1662139",
    "LastEditorUserId": "6499760",
    "LastEditDate": "2020-01-13T11:56:29.130",
    "LastActivityDate": "2023-06-29T09:21:21.600",
    "Title": "docker-compose and create db in Postgres on init",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "7",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "29564268",
    "PostTypeId": "1",
    "AcceptedAnswerId": "29565333",
    "CreationDate": "2015-04-10T14:40:40.403",
    "Score": "9",
    "ViewCount": "11652",
    "Body": "<p>From my understanding of docker compose / fig, creating a link between two services/images is one main reason if you do not want to exposes ports to others.</p>  <p>like here <strong>db</strong> does not expose any ports and is only linked:</p>  <pre><code>web:   build: .   links:    - db   ports:    - '8000:8000'    db:   image: postgres </code></pre>  <p>Does <strong>web</strong> thinks <strong>db</strong> runs on its localhost? Would i connect from a script/program in <strong>web</strong> to localhost:5432 (standard port from postgresql) to get a database connection? </p>  <p>And if this is correct, how can you change port 5432 to 6432, without exposing? would i just run postgresql on a different port?</p>  <p>Update:</p>  <p>useful links after some input:</p>  <p><a href='http://docs.docker.com/userguide/dockerlinks/'>http://docs.docker.com/userguide/dockerlinks/</a></p>  <p><a href='https://docs.docker.com/compose/yml/#links'>https://docs.docker.com/compose/yml/#links</a></p> ",
    "OwnerUserId": "1584115",
    "LastEditorUserId": "1584115",
    "LastEditDate": "2015-04-11T11:18:50.467",
    "LastActivityDate": "2016-11-22T10:12:20.007",
    "Title": "Understanding ports and links in docker compose",
    "Tags": "<docker><fig><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "29729537",
    "PostTypeId": "1",
    "CreationDate": "2015-04-19T11:57:35.533",
    "Score": "9",
    "ViewCount": "7017",
    "Body": "<p>I am trying to use <code>docker-compose up</code> the way you can use <code>docker run [APP_CONTAINER_NAME] [APP_OPTIONS]</code>.</p> ",
    "OwnerUserId": "4793737",
    "LastActivityDate": "2017-02-09T18:00:00.290",
    "Title": "How can I send command line options to my dockerized program that I start with 'docker-compose up'?",
    "Tags": "<ubuntu><docker><fig><docker-compose>",
    "AnswerCount": "3",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "33061464",
    "PostTypeId": "1",
    "AcceptedAnswerId": "33061840",
    "CreationDate": "2015-10-11T04:17:04.123",
    "Score": "9",
    "ViewCount": "3869",
    "Body": "<p>I have a Rails app. In the development and test environments, I want the Rails app to connect to a dockerized Postgres. The Rails app itself will not be in a container though - just Postgres.</p>  <p>What should my database.yml look like?</p>  <p>I have a docker <code>default</code> machine running. I created docker-compose.yml:</p>  <pre><code>postgres:   image: postgres   ports:     - '5432:5432'   environment:     - POSTGRES_USER=timbuktu     - POSTGRES_PASSWORD=mysecretpassword </code></pre>  <p>I ran <code>docker-compose up</code> to get Postgres running.</p>  <p>Then I ran <code>docker-machine ip default</code> to get the IP address of the Docker virtual machine, and I updated database.yml accordingly:</p>  <pre><code>... development:    adapter: postgresql   host: 192.168.99.100   port: 5432   database: timbuktu_development   username: timbuktu   password: mysecretpassword   encoding: unicode   pool: 5 ... </code></pre>  <p>So all is well and I can connect to Postgres in its container. </p>  <p>But, if someone else pulls the repo, they won't be able to connect to Postgres using my database.yml, because the IP address of their Docker default machine will be different from mine. </p>  <p>So how can I change my database.yml to account for this?</p>  <p>One idea I have is to ask them to get the IP address of their Docker default machine by running <code>docker-machine env default</code>, and pasting the env DOCKER_HOST line into their bash_rc. For example,</p>  <pre><code>export DOCKER_HOST='tcp://192.168.99.100:2376' </code></pre>  <p>Then my database.yml host can include the line </p>  <pre><code>host: &lt;%= ENV['DOCKER_HOST'].match(/tcp:\\/\\/(.+):\\d{3,}/)[1] %&gt; </code></pre>  <p>But this feels ugly and hacky. Is there a better way?</p> ",
    "OwnerUserId": "5331394",
    "LastActivityDate": "2024-01-10T09:37:48.147",
    "Title": "How to setup database.yml to connect to Postgres Docker container?",
    "Tags": "<ruby-on-rails><postgresql><docker><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "33230871",
    "PostTypeId": "1",
    "CreationDate": "2015-10-20T07:46:55.680",
    "Score": "9",
    "ViewCount": "11473",
    "Body": "<p>I build 2 dockers, one docker with apache, one docker with php5, and I use docker-compose to start.</p>  <p>apache2 Dockerfile in directoy apache2:</p>  <pre><code>FROM debian:latest RUN apt-get update &amp;&amp; apt-get install -y apache2 ADD test.php /var/www/html  CMD ['/usr/sbin/apache2ctl', '-D', 'FOREGROUND'] </code></pre>  <p>and test.php:</p>  <pre><code>&lt;?php phpinfo(); ?&gt; </code></pre>  <p>php5 Dorckerfile in directory php:</p>  <pre><code>FROM debian:latest RUN apt-get update &amp;&amp; apt-get install -y php5 </code></pre>  <p>docker-compose.yml:</p>  <pre><code>apache:     build: ./apache2     container_name: apache     ports:       - '80:80'     links:       - 'php5'  php5:     build: ./php     container_name: php </code></pre>  <p>then I run:</p>  <pre><code>docker-compose up </code></pre>  <p>apache2 server start successfully. Then I access this server by <a href='http://server_ip' rel='noreferrer'>http://server_ip</a>, then I get index of debian.But when I access <a href='http://server_ip/test.php' rel='noreferrer'>http://server_ip/test.php</a>, just occur this:</p>  <pre><code>&lt;?php phpinfo(); ?&gt; </code></pre>  <p>php just doesn't work.And I don't why.</p> ",
    "OwnerUserId": "4432999",
    "LastActivityDate": "2017-12-03T19:55:43.117",
    "Title": "php docker link apache docker",
    "Tags": "<php><apache><docker><docker-compose>",
    "AnswerCount": "3",
    "CommentCount": "3",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "34343025",
    "PostTypeId": "1",
    "AcceptedAnswerId": "34345794",
    "CreationDate": "2015-12-17T19:46:08.223",
    "Score": "9",
    "ViewCount": "9980",
    "Body": "<p>When you are running a <strong>docker-compose up -d</strong> command, by default the build image is going to take the name of the current folder.</p>  <p>So for example for this <strong>docker-compose.yml</strong> file my image will be named: <strong>dockersymfony_php</strong> because my current folder is named <strong>docker-symfony</strong> and I indicated <strong>php</strong> for my image in my yaml file</p>  <pre><code>php:     build: ./docker/php     container_name: symfony </code></pre>  <p>Is there a way to override that ? Like <strong>container_name</strong> to renaming the container...</p>  <p>I know that the command <strong>docker build -t  .</strong> can do it but I need to use my <strong>docker-compose.yml</strong> file.</p> ",
    "OwnerUserId": "3676576",
    "LastActivityDate": "2018-01-14T04:14:49.083",
    "Title": "Docker Compose - Image name",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "34441975",
    "PostTypeId": "1",
    "AcceptedAnswerId": "34445379",
    "CreationDate": "2015-12-23T18:52:28.110",
    "Score": "9",
    "ViewCount": "7789",
    "Body": "<p>When my Dockerfile ends with </p>  <pre><code>CMD node . </code></pre>  <p>docker runs that container with the command <code>/bin/sh -c 'node .'</code> instead of simply <code>node .</code> (I know, I could do that with <code>CMD ['node', '.']</code>).</p>  <p>I thought that this behavior is actually nice, since it means that inside the container <code>PID1</code> is <code>/bin/sh</code> and not my humble node script. </p>  <p>If I understand correctly <code>PID1</code> is responsible for reaping orphaned zombie processes, and I don't really wan't to be responsible for that... So if <code>/bin/sh</code> could do that, that would be nice. (I actually thought that this is the reason why docker does rewrite my <code>CMD</code>).</p>  <p>The problem is that when I send a <code>SIGTERM</code> to the container (started with <code>/bin/sh -c 'node .'</code>), either via <code>docker-composer stop</code> or <code>docker-composer kill -s SIGTERM</code>, the signal doesn't reach my <code>node</code> process and therefore it get's forcefully killed everytime with a <code>SIGKILL</code> after the 10 seconds grace period. Not nice.</p>  <p>Is there a way to have someone manage my zombies and have my node instance receive the signals sent by docker?</p> ",
    "OwnerUserId": "913761",
    "LastActivityDate": "2015-12-28T12:05:53.990",
    "Title": "SIGTERM does not reach node script when docker runs it with `/bin/sh -c`",
    "Tags": "<linux><node.js><docker><docker-compose>",
    "AnswerCount": "3",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "34458042",
    "PostTypeId": "1",
    "CreationDate": "2015-12-24T21:26:13.417",
    "Score": "9",
    "ViewCount": "2472",
    "Body": "<p>I have spent the past few day working on creating a docker swarm on Digtital Ocean. Note: I don't want to use <code>-link</code> to communicate with the other apps/containers becasue they are technically considered deprecated and don't work well with docker swarm (i.e. I can't add more app instances to the load balancer without re composing the entire swarm)</p>  <p>I am using one server as a kv-store server running console according to <a href='https://docs.docker.com/engine/userguide/networking/get-started-overlay/'>this guide</a>. Becasue i'm on Digital Ocean, i'm using private networking on DO so the machines can communicate with each other.</p>  <p>I then create a hive master and slave, and start the overlay network, which is running on all machines. Here is my docker-compose.yml</p>  <pre><code>proxy:     image: tutum/haproxy      ports:         - '1936:1936'         - '80:80'  web:     image: tutum/hello-world     expose:         - '80' </code></pre>  <p>So when I do this it creates the 2 containers. HAProxy is running because I can access the stats at port 1936 at <code>http://&lt;ip-address&gt;:1936</code>, however, when I try to go to the web server/load balancer at port 80 I get connection refused. I everything <em>seems</em> to be connected though, when I run <code>docker-compose ps</code>:</p>  <pre><code>       Name                      Command               State                                 Ports -------------------------------------------------------------------------------------------------------------------------------- splashcloud_proxy_1   python /haproxy/main.py          Up      104.236.109.58:1936-&gt;1936/tcp, 443/tcp, 104.236.109.58:80-&gt;80/tcp splashcloud_web_1     /bin/sh -c php-fpm -d vari ...   Up      80/tcp </code></pre>  <p>The only thing I can think of is that it's not linking to the web container, but i'm not sure how to troubleshoot this.</p>  <p>I'd appreciate any help on this.</p> ",
    "OwnerUserId": "1530554",
    "LastEditorUserId": "1530554",
    "LastEditDate": "2015-12-27T05:44:41.327",
    "LastActivityDate": "2016-06-18T04:26:47.777",
    "Title": "Docker Swarm HAProxy Not Load Balancing w/ Overlay Networking",
    "Tags": "<docker><haproxy><docker-compose><docker-swarm>",
    "AnswerCount": "2",
    "CommentCount": "7",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "34511336",
    "PostTypeId": "1",
    "AcceptedAnswerId": "34513016",
    "CreationDate": "2015-12-29T12:43:17.907",
    "Score": "9",
    "ViewCount": "5315",
    "Body": "<p>I'm having trouble in configuring persistent data with <code>Mariadb</code>. I'm using <code>docker-compose</code>, with each service in a single container (<code>Nginx</code>, <code>PHP-FPM</code> and <code>Mariadb</code>). Everything is working, except <code>Mariadb</code> doesn't store data. Every time I restart the container, I lose all the data. Then I found out that I can use another container just to keep data, and it doesn't even have to be running.</p>  <p>So I'm using, in <code>Mariadb</code> container <code>volume_from</code> content container. But when I do that, when I try to map the volume <code>/var/lib/mysql</code>, the Container <code>MariaDb</code> doesn't start.</p>  <p><strong>Error</strong></p>  <blockquote>   <p>2015-12-29 12:16:40 7f2f02e4a780<br />   InnoDB: Operating system error number 13 in a file operation.<br />   InnoDB: The error means mysqld does not have the access rights to<br />   InnoDB: the directory.</p> </blockquote>  <p>The error refers to a problem about volume permissions, but I've tried to set permissions through <code>Dockerfile</code> in both containers, and the problem persists. I'm a bit lost. I'm using OSX, so I believe this is an OSX problem. Can anyone help me on this?</p>  <p>This is my code:</p>  <p><strong>My Docker Compose</strong></p>  <pre> content:   build: containers/content   container_name: content   hostname: content   volumes:     - /var/lib/mysql mariadb:   build: containers/mariadb   container_name: mariadb   hostname: mariadb   ports:     - '3306:3306'   volumes_from:     - content   environment:     - MYSQL_ROOT_PASSWORD=mariadb     - TERM=xterm     - PORT=3306 </pre>  <p><strong>MariaDB Dockerfile</strong><br></p>  <pre> FROM debian:jessie  RUN apt-get update && apt-get install -y  mariadb-server  EXPOSE 3306 </pre>  <p><strong>Content Dockerfile</strong><br></p>  <pre> FROM debian:jessie  VOLUME /var/lib/mysql  CMD ['true'] </pre> ",
    "OwnerUserId": "5723090",
    "LastEditorUserId": "3393505",
    "LastEditDate": "2015-12-31T20:36:07.067",
    "LastActivityDate": "2016-09-22T18:55:07.623",
    "Title": "Docker-Compose Persistent Data Trouble",
    "Tags": "<macos><docker><mariadb><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "34537168",
    "PostTypeId": "1",
    "CreationDate": "2015-12-30T20:59:53.813",
    "Score": "9",
    "ViewCount": "26573",
    "Body": "<p>I'm trying to set up a development environment using docker-compose and my container does not seem to have permissions to the host directory that is mounted to the container, i'm getting this error when running a grunt task that tries to modify folders inside the volume:</p>  <pre><code>app_1                   | Warning: Unable to delete '.tmp' file (EACCES, permission denied '.tmp'). Use --force to continue. </code></pre>  <p>here's my docker file:</p>  <pre><code>FROM node:0.10  RUN mkdir -p /usr/src/app WORKDIR /usr/src/app  RUN apt-get update \\     &amp;&amp; apt-get install -y --no-install-recommends ruby-sass \\     &amp;&amp; rm -rf /var/lib/apt/lists/* \\     &amp;&amp; apt-get clean -y \\     &amp;&amp; apt-get autoremove -y  RUN npm install -g grunt-cli bower  RUN groupadd -r node \\ &amp;&amp;  useradd -r -m -g node node  RUN chown -R node:node /usr/src/app  USER node  EXPOSE 8080 </code></pre>  <p>and my docker-compose file:</p>  <pre><code>app:   build: .   dockerfile: Dockerfile.dev   ports:    - '9000:9000'   env_file:    - ./server/config/env/development.env   volumes:    - ./:/usr/src/app:Z   command: bash -c 'npm install &amp;&amp; bower install &amp;&amp; grunt dev &amp;&amp; npm start'  db:   ports:    - '27017:27017' </code></pre>  <ul> <li>I'm running ubuntu 15.10 with docker-compose version 1.5.2, build 7240ff3</li> <li>Note that I am using the :Z permission</li> </ul> ",
    "OwnerUserId": "2458504",
    "LastActivityDate": "2015-12-31T08:38:14.743",
    "Title": "Adding permissions to host directory with docker-compose",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "4",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "34833640",
    "PostTypeId": "1",
    "AcceptedAnswerId": "34835504",
    "CreationDate": "2016-01-17T00:13:10.040",
    "Score": "9",
    "ViewCount": "5137",
    "Body": "<p>My docker-compose.yml looks something like this:</p>  <pre><code>django:   build: .   user: django   links:     # LINK TO AMAZON RDS?   command: /gunicorn.sh   env_file: config/settings/.env  nginx:   build: ./compose/nginx   links:     - django   ports:     - '0.0.0.0:80:80' </code></pre>  <p>How do I link the django container to the Amazon RDS, which has an url like: <code>example.blahblahblah.eu-west-1.rds.amazonaws.com:5432</code> </p> ",
    "OwnerUserId": "1051624",
    "LastActivityDate": "2016-01-17T05:42:14.307",
    "Title": "How to link from docker-compose to Amazon RDS",
    "Tags": "<django><amazon-web-services><docker><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "35760760",
    "PostTypeId": "1",
    "CreationDate": "2016-03-03T00:12:41.613",
    "Score": "9",
    "ViewCount": "31008",
    "Body": "<p>I have a docker setup with some websites for localhost. I use Smarty as my template engine and it requires to have a writable templates_c folder. Any idea how I can make this folder writable?</p>  <p>The error is as following:</p>  <pre><code>PHP Fatal error:  Smarty error: unable to write to $compile_dir  '/var/www/html/sitename.local/httpdocs/templates_c'.  Be sure $compile_dir is writable by the web server user. in  /var/www/html/sitename.local/httpdocs/libs/Smarty.class.php on  line 1093 </code></pre>  <p>I know this could be set manually with linux but I am looking for an automatic <strong><em>global</em></strong> solution since I have many websites who have this issue</p>  <p>Also worth mentioning I am using a pretty clean docker-compose.yml</p>  <pre><code>php56:   build: .   dockerfile: /etc/docker/dockerfile_php_56   volumes:     - ./sites:/var/www/html     - ./etc/php:/usr/local/etc/php     - ./etc/apache2/apache2.conf:/etc/apache2/conf-enabled/apache2.conf     - ./etc/apache2/hosts.conf:/etc/apache2/sites-enabled/hosts.conf   ports:     - '80:80'     - '8080:8080'   links:     - mysql   mysql:   image: mysql   ports:     - '3306:3306'   environment:     - MYSQL_ROOT_PASSWORD=MY_PASSWORD     - MYSQL_DATABASE=YOUR_DATABASE_NAME   volumes:      - ./etc/mysql:/docker-entrypoint-initdb.d </code></pre>  <p>With a small dockerfile for basics:</p>  <pre><code>FROM php:5.6-apache  RUN /usr/local/bin/docker-php-ext-install mysqli mysql RUN    docker-php-ext-configure mysql --with-libdir=lib/x86_64-linux-gnu/ \\     &amp;&amp; docker-php-ext-install mysql RUN a2enmod rewrite </code></pre>  <p><a href='https://github.com/wesleyd85/docker-php7-httpd-apache2-mysql' rel='noreferrer'>https://github.com/wesleyd85/docker-php7-httpd-apache2-mysql</a> (but then with php 5.6)</p> ",
    "OwnerUserId": "5322269",
    "LastEditorUserId": "5322269",
    "LastEditDate": "2016-03-03T00:24:14.830",
    "LastActivityDate": "2016-11-13T13:21:50.190",
    "Title": "Writable folder permissions in docker",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "7",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "35955853",
    "PostTypeId": "1",
    "AcceptedAnswerId": "35956974",
    "CreationDate": "2016-03-12T09:20:41.043",
    "Score": "9",
    "ViewCount": "26481",
    "Body": "<p>my OS is : ubuntu:15.10</p>  <p>And i want to use the <strong>official docker-hub redis</strong> , but met problems .</p>  <p>my docker-compose.yml </p>  <pre><code>version: '2' services:    redis:     image: redis     ports:       - '6379:6379'     volumes:       -  ~/dbdata/redis_conf/redis.conf:/usr/local/etc/redis/redis.conf     volumes_from:       -  redisdata     environment:       - REDIS_PASSWORD: 29c4181fb842b5f24a3103dbd2ba17accb1f7e3c8f19868955401ab921     command: redis-server /usr/local/etc/redis/redis.conf  redisdata:     image: redis     volumes:       - /home/keryhu/dbdata/redisdb:/data     command: --break-redis </code></pre>  <p>I copy the default redis.conf to the '~/dbdata/redis_conf/redis.conf' directory . And just modify the 'requirepass' to '29c4181fb842b5f24a3103dbd2ba17accb1f7e3c8f19868955401ab921'</p>  <p>when i start the container ,i met an error -</p>  <pre><code>*** FATAL CONFIG FILE ERROR *** Reading the configuration file, at line 103 &gt;&gt;&gt; 'logfile /var/log/redis/redis-server.log' Can't open the log file: No such file or directory </code></pre>  <p>Can help me ?</p> ",
    "OwnerUserId": "5097551",
    "LastActivityDate": "2018-12-12T08:04:17.470",
    "Title": "docker redis -Can't open the log file: No such file or directory",
    "Tags": "<docker><redis><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "36120679",
    "PostTypeId": "1",
    "AcceptedAnswerId": "36130772",
    "CreationDate": "2016-03-20T22:58:48.947",
    "Score": "9",
    "ViewCount": "16684",
    "Body": "<p>I run Docker 1.8.1 in OSX 10.11 via an local docker-machine VM.</p>  <p>I have the following docker-compose.yml:</p>  <pre><code>web:     build: docker/web     ports:         - 80:80         - 8080:8080     volumes:         - $PWD/cms:/srv/cms </code></pre>  <p>My Dockerfile looks like this:</p>  <pre><code>FROM alpine  # install nginx and php RUN apk add --update \\     nginx \\     php \\     php-fpm \\     php-pdo \\     php-json \\     php-openssl \\     php-mysql \\     php-pdo_mysql \\     php-mcrypt \\     php-ctype \\     php-zlib \\     supervisor \\     wget \\     curl \\     &amp;&amp; rm -rf /var/cache/apk/*  RUN mkdir -p /etc/nginx &amp;&amp; \\     mkdir -p /etc/nginx/sites-enabled &amp;&amp; \\     mkdir -p /var/run/php-fpm &amp;&amp; \\     mkdir -p /var/log/supervisor &amp;&amp; \\     mkdir -p /srv/cms  RUN rm /etc/nginx/nginx.conf ADD nginx.conf /etc/nginx/nginx.conf ADD thunder.conf /etc/nginx/sites-enabled/thunder.conf  ADD nginx-supervisor.ini /etc/supervisor.d/nginx-supervisor.ini  WORKDIR '/srv/cms' VOLUME '/srv/cms'  EXPOSE 80 EXPOSE 8080 EXPOSE 22  CMD ['/usr/bin/supervisord'] </code></pre>  <p>When I run everything with <code>docker-compose up</code> everything works fine, my volumes are mounted at the correct place.</p>  <p>But the permissions in the mounted folder /srv/cms look wrong. The user is '1000' and the group is '50' in the container. The webserver could not create any files in this folder, because it runs with the user 'root'.</p> ",
    "OwnerUserId": "651764",
    "LastActivityDate": "2023-03-26T09:35:59.530",
    "Title": "Wrong permissions in volume in Docker container",
    "Tags": "<macos><docker><docker-compose><docker-machine>",
    "AnswerCount": "3",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "36179087",
    "PostTypeId": "1",
    "CreationDate": "2016-03-23T13:08:29.230",
    "Score": "9",
    "ViewCount": "1985",
    "Body": "<p>Currently I'm setting up my app using docker. I've got a minimal rails app, with 1 controller. You can get my setup by running these:</p>  <pre><code>rails new app --database=sqlite --skip-bundle cd app rails generate controller --skip-routes Home index echo 'Rails.application.routes.draw { root 'home#index' }' &gt; config/routes.rb echo 'gem 'foreman'' &gt;&gt; Gemfile echo 'web: rails server -b 0.0.0.0' &gt; Procfile echo 'port: 3000' &gt; .foreman </code></pre>  <p>And I have the following setup:</p>  <p><code>Dockerfile</code>:</p>  <pre><code>FROM ruby:2.3  # Install dependencies RUN apt-get update &amp;&amp; apt-get install -y \\       nodejs \\       sqlite3 \\       --no-install-recommends \\       &amp;&amp; rm -rf /var/lib/apt/lists/*  # Configure bundle RUN bundle config --global frozen 1 RUN bundle config --global jobs 7  # Expose ports and set entrypoint and command EXPOSE 3000 CMD ['foreman', 'start']  # Install Gemfile in different folder to allow caching WORKDIR /tmp COPY ['Gemfile', 'Gemfile.lock', '/tmp/'] RUN bundle install --deployment  # Set environment ENV RAILS_ENV production ENV RACK_ENV production  # Add files ENV APP_DIR /app RUN mkdir -p $APP_DIR COPY . $APP_DIR WORKDIR $APP_DIR  # Compile assets RUN rails assets:precompile VOLUME '$APP_DIR/public' </code></pre>  <p>Where <code>VOLUME '$APP_DIR/public'</code> is creating a volume that's shared with the Nginx container, which has this in the <code>Dockerfile</code>:</p>  <pre><code>FROM nginx  ADD nginx.conf /etc/nginx/nginx.conf </code></pre>  <p>And then <code>docker-compose.yml</code>:</p>  <pre><code>version: '2'  services:   web:     build: config/docker/web     volumes_from:       - app     links:       - app:app     ports:       - 80:80       - 443:443   app:     build: .     environment:       SECRET_KEY_BASE: 'af3...ef0'     ports:       - 3000:3000 </code></pre>  <p>This works, but only the first time I build it. If I change any assets, and build the images again, they're not updated. Possibly because volumes are not updated on image build, I think because how Docker handles caching.</p>  <p>I want the assets to be updated every time I run <code>docker-compose built &amp;&amp; docker-compose up</code>. Any idea how to accomplish this?</p> ",
    "OwnerUserId": "2059127",
    "LastActivityDate": "2016-03-25T16:40:15.030",
    "Title": "Serving Rails' precompiled assets using nginx in Docker",
    "Tags": "<ruby-on-rails><docker><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "36312699",
    "PostTypeId": "1",
    "AcceptedAnswerId": "36321403",
    "CreationDate": "2016-03-30T15:01:54.303",
    "Score": "9",
    "ViewCount": "37749",
    "Body": "<p>I have the following example</p>  <pre><code>version: '2'  services:   proxy:     container_name: proxy     hostname: proxy     image: nginx     ports:       - 80:80       - 443:443     volumes:       - proxy_conf:/etc/nginx       - proxy_htdocs:/usr/share/nginx/html  volumes:   proxy_conf: {}   proxy_htdocs: {} </code></pre>  <p>which works fine. When I run <code>docker-compose up</code> it creates those named volumes in <code>/var/lib/docker/volumes</code> and all is good. However, from the host, I can only access <code>/var/lib/docker</code> as root, because it's <code>root:root</code> (makes sense). I was wondering if there is a way of <code>chown</code>ing the host's directories to something more sensible/safe (like, my relatively unprivileged user that I use to do most things on the host) or if I just have to suck it up and <code>chown</code> them manually. I'm starting to have a number of scripts already to work around other issues, so having an extra couple of lines won't be much of a problem, but I'd really like to keep my self-written automation minimal, if I can -- fewer chances for stupid mistakes.</p>  <p>By the way, no: if I mount host directories instead of creating volumes, they get overlaid, meaning that if they start empty, they stay empty, and I don't get the default configuration (or whatever) from inside the container.</p>  <p>Extra points: can I just move the volumes to a more convenient location? Say, <code>/home/myuser/myserverstuff/volumes</code>?</p> ",
    "OwnerUserId": "554491",
    "LastActivityDate": "2017-05-17T15:48:03.617",
    "Title": "chown docker volumes on host (possibly through docker-compose)",
    "Tags": "<docker><docker-compose><chown><docker-volume>",
    "AnswerCount": "1",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "36623457",
    "PostTypeId": "1",
    "AcceptedAnswerId": "36624612",
    "CreationDate": "2016-04-14T12:41:22.950",
    "Score": "9",
    "ViewCount": "3145",
    "Body": "<p>I have 2 containers: <code>web</code> and <code>nginx</code>. When I build <code>web</code> container, static assets for frontend are generated within the container.</p>  <p>Now, I want to share those assets between <code>web</code> and <code>nginx</code> without using a volume on the host machine. Otherwise, I'll have to build those static assets on the host side and then include as a volume into the <code>web</code> container and share it with <code>nginx</code> container. This is undesirable from my build system's standpoint.</p>  <p>Is there a way to build static assets in the <code>web</code> container and then share them with <code>nginx</code>?</p> ",
    "OwnerUserId": "1360544",
    "LastActivityDate": "2016-04-14T13:27:54.820",
    "Title": "Docker: Is it possible to share data between 2 containers without a volume?",
    "Tags": "<nginx><docker><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "37153053",
    "PostTypeId": "1",
    "CreationDate": "2016-05-11T04:18:40.177",
    "Score": "9",
    "ViewCount": "6422",
    "Body": "<p>I am new to docker and have just started exploring it. What I am trying to achieve is to publish a Docker image, which would just have some configuration files. These files would be shared across multiple projects.</p>  <p><strong>So the image I want to publish is 'my-config-image'.</strong></p>  <hr>  <p><strong>This is how the directory structure is:</strong></p>  <pre><code>/my-config-settings      /folder1/multiple files      /folder2/multiple files      file1.txt      file2.txt </code></pre>  <hr>  <p>After reading online and going through the docker quick start I have got some understanding.</p>  <p>I decided to use Create a simple base image using <code>scratch</code>. referred from (<a href='https://docs.docker.com/engine/userguide/eng-image/baseimages/' rel='noreferrer'>https://docs.docker.com/engine/userguide/eng-image/baseimages/</a>)</p>  <p><strong>This is how my Dockerfile looks.</strong></p>  <pre><code>FROM scratch ADD folder1 / folder2 / </code></pre>  <p>This is the command I am using to publish an image.</p>  <pre><code>/my-config-settings/docker build -t my-config-image . Sending build context to Docker daemon  5.12 kB Step 1 : FROM scratch  ---&gt;  Step 2 : ADD folder1 / folder2 /  ---&gt; Using cache  ---&gt; cc9c3f338f51 Successfully built cc9c3f338f51 </code></pre>  <p>When I want to check if the image was created locally I am confirming it in this way by executing</p>  <pre><code>docker images   REPOSITORY                                          TAG                 IMAGE ID            CREATED             SIZE my-config-image                                     latest              cc9c3f338f51        2 minutes ago       39 B </code></pre>  <p>My main query is how can I check if this is working, Also did this add the file1.txt and file2.txt into the image, if not how do I specify to add these files in the image.</p>  <p>Is there a way I can add all the files and directories recursively into the image I am trying to create?</p>  <p>Also how to I access this image, means how can I check if this image actually has all the folders and files. Is there a way to cd into this?</p>  <p>I am okay with suggestions and looking at another docker approach, if what I am trying to do doesn't make sense.</p>  <p>Thank you for reading.</p> ",
    "OwnerUserId": "3277169",
    "LastEditorUserId": "3277169",
    "LastEditDate": "2016-05-11T04:38:56.257",
    "LastActivityDate": "2016-05-11T04:38:56.257",
    "Title": "Using docker image to store data files",
    "Tags": "<image><docker><docker-compose><dockerfile><docker-registry>",
    "AnswerCount": "1",
    "CommentCount": "10",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "37463543",
    "PostTypeId": "1",
    "AcceptedAnswerId": "37468342",
    "CreationDate": "2016-05-26T14:20:17.010",
    "Score": "9",
    "ViewCount": "27038",
    "Body": "<p>I want to get started with docker and created a simple container environment with an nginx container, a PHP-FPM container and a MySQL container. </p>  <p>While the link between the nginx and PHP-FPM container works well I can't seem to link the PHP application server with the database server.</p>  <p>I use docker-compose to minimize the manual terminal work. My docker-compose.yml looks like this:</p>  <pre><code>web:   image: tutorial/nginx   ports:     - '8080:80'   volumes:     - ./src:/var/www     - ./src/vhost.conf:/etc/nginx/sites-enabled/vhost.conf   links:     - php php:   image: nmcteam/php56   volumes:     - ./src/php-fpm.conf:/etc/php5/fpm/php-fpm.conf     - ./src:/var/www   links:     - db db:   image: sameersbn/mysql   volumes:    - /var/lib/mysql   environment:    - DB_NAME=demoDb    - DB_USER=demoUser    - DB_PASS=demoPass </code></pre>  <p>While I try to connect to the DB with the following statement:</p>  <pre><code>$db = new \\PDO('mysql:host=db;dbname=demoName', 'demoUser', 'demoPass'); </code></pre>  <p>The MySQL container itself is working as I can connect to the containers bash and use the MySQL CLI:</p>  <pre><code>mysql&gt; show databases;  +--------------------+ | Database           | +--------------------+ | information_schema | | demoDb             | | mysql              | | performance_schema | +--------------------+ </code></pre>  <p>I just get a 500 error and can't find a reason why this wouldn't work. Any help or suggestion of what I might have missed is more than appreciated.</p> ",
    "OwnerUserId": "6290835",
    "LastActivityDate": "2021-07-24T21:06:08.517",
    "Title": "Can't connect to MySQL docker container created via docker-compose",
    "Tags": "<mysql><docker><docker-compose>",
    "AnswerCount": "4",
    "CommentCount": "10",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "38353959",
    "PostTypeId": "1",
    "CreationDate": "2016-07-13T14:04:41.510",
    "Score": "9",
    "ViewCount": "3858",
    "Body": "<p>Does anyone know how (if possible) to run docker-compose commands against a swarm using the new docker 1.12 'swarm mode' swarm? </p>  <p>I know with the previous 'Docker Swarm' you could run docker-compose commands directly against the swarm by updating the DOCKER_HOST to point to the swarm master :<br> <code>export DOCKER_HOST='tcp://123.123.123.123:3375'</code><br> and then simply execute commands as if you were running them against a single instance of Docker engine.</p>  <p>OR is this functionality something that <code>docker-compose bundle</code> is replacing?</p> ",
    "OwnerUserId": "4066662",
    "LastEditorUserId": "4066662",
    "LastEditDate": "2016-07-13T14:06:27.243",
    "LastActivityDate": "2016-09-09T12:36:58.513",
    "Title": "Docker-Compose with Docker 1.12 'Swarm Mode'",
    "Tags": "<docker><docker-compose><docker-swarm>",
    "AnswerCount": "3",
    "CommentCount": "3",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "38663834",
    "PostTypeId": "1",
    "CreationDate": "2016-07-29T16:50:16.247",
    "Score": "9",
    "ViewCount": "17341",
    "Body": "<p>I try to build containers with a docker-compose.yml file :</p>  <pre><code>version: '2'  services:      geonode:         build:              context: .         hostname: geonode         container_name: geonode         ports:             - 8000:8000         volumes:             - .:/geonode/         entrypoint:             - /usr/bin/python         command: manage.py runserver 0.0.0.0:8000         network_mode: host </code></pre>  <p>In my Dockerfile I run <code>apt-get update</code> after <code>FROM ubuntu:14.04</code> but it fails : <code>Could not resolve 'archive.ubuntu.com'</code></p>  <p>I tried <code>docker run -i -t --net=host ubuntu:14.04 /bin/bash</code> and then run <code>apt-get update</code> and it works. So it seems to me that the network_mode in docker-compose and the <code>--net=host</code> with docker run don't work the same way.</p>  <p>Does somebody has an explanation?</p> ",
    "OwnerUserId": "2886075",
    "LastActivityDate": "2022-04-05T14:27:58.487",
    "Title": "docker-compose network_mode: 'host' doesn't seem to work",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "39326602",
    "PostTypeId": "1",
    "AcceptedAnswerId": "39329600",
    "CreationDate": "2016-09-05T08:31:28.837",
    "Score": "9",
    "ViewCount": "17206",
    "Body": "<p>Trying to run cluster application on different virtual machines with use of Swarm stand alone and docker-compose version '2'. Overlay network is set. But want to force certain containers to run on specific hosts. </p>  <p>In documentation there is following advice, but with this parameter I was not able to start any container at all:</p>  <pre><code>environment:   - 'constraint:node==node-1'  ERROR: for elasticsearch1  Cannot create container for service elasticsearch1: Unable to find a node that satisfies the following conditions [available container slots] [node==node-1] </code></pre>  <p>Should we register hosts as node-1 node-2... or it is done by default.</p>  <pre><code>[root@ux-test14 ~]# docker node ls Error response from daemon: 404 page not found [root@ux-test14 ~]# docker run swarm list [root@ux-test14 ~]#    [root@ux-test14 ~]# docker info Containers: 8  Running: 6  Paused: 0  Stopped: 2 Images: 8 Server Version: swarm/1.2.5 Role: primary Strategy: spread Filters: health, port, containerslots, dependency, affinity, constraint Nodes: 2  ux-test16.rs: 10.212.212.2:2375   \u00e2 ID: JQPG:GKFF:KJZJ:AY3N:NHPZ:HD6J:SH36:KEZR:2SSH:XF65:YW3N:W4DG   \u00e2 Status: Healthy   \u00e2 Containers: 4 (4 Running, 0 Paused, 0 Stopped)   \u00e2 Reserved CPUs: 0 / 2   \u00e2 Reserved Memory: 0 B / 3.888 GiB   \u00e2 Labels: kernelversion=3.10.0-327.28.3.el7.x86_64, operatingsystem=CentOS Linux 7 (Core), storagedriver=devicemapper   \u00e2 UpdatedAt: 2016-09-05T11:11:31Z   \u00e2 ServerVersion: 1.12.1  ux-test17.rs: 10.212.212.3:2375   \u00e2 ID: Z27V:T5NU:QKSH:DLNK:JA4M:V7UX:XYGH:UIL6:WFQU:FB5U:J426:7XIR   \u00e2 Status: Healthy   \u00e2 Containers: 4 (2 Running, 0 Paused, 2 Stopped)   \u00e2 Reserved CPUs: 0 / 2   \u00e2 Reserved Memory: 0 B / 3.888 GiB   \u00e2 Labels: kernelversion=3.10.0-327.28.3.el7.x86_64, operatingsystem=CentOS Linux 7 (Core), storagedriver=devicemapper   \u00e2 UpdatedAt: 2016-09-05T11:11:17Z   \u00e2 ServerVersion: 1.12.1 Plugins:  Volume:  Network: Swarm:  NodeID:  Is Manager: false  Node Address: Security Options: Kernel Version: 3.10.0-327.28.3.el7.x86_64 Operating System: linux Architecture: amd64 CPUs: 4 Total Memory: 7.775 GiB Name: 858ac2fdd225 Docker Root Dir: Debug Mode (client): false Debug Mode (server): false WARNING: No kernel memory limit support </code></pre> ",
    "OwnerUserId": "3292147",
    "LastEditorUserId": "3292147",
    "LastEditDate": "2016-09-05T11:36:16.787",
    "LastActivityDate": "2021-10-10T15:24:54.827",
    "Title": "docker-compose swarm: force containers to run on specific hosts",
    "Tags": "<docker><docker-compose><docker-swarm>",
    "AnswerCount": "3",
    "CommentCount": "3",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "39331665",
    "PostTypeId": "1",
    "CreationDate": "2016-09-05T13:27:29.483",
    "Score": "9",
    "ViewCount": "6837",
    "Body": "<p>I am trying to build a project using maven on teamcity and getting this error during maven build step.</p>  <blockquote>   <p>[Step 2/4] [ERROR] protoc failed output:<br>   [Step 2/4] [ERROR] protoc failed error: /bin/sh: 1: protoc: Permission denied   [Step 2/4]  [13:03:14][Step 2/4] Failed to execute goal   com.google.protobuf.tools:maven-protoc-plugin:0.1.10:compile   (generate-sources) on project unit-protocol-lib: protoc did not exit   cleanly. Review output for more information.</p> </blockquote>  <p>Keep in mind I am using docker-compose for building the teamcity agent (agent running in container) and protoc is added to /usr/local/bin/protoc ($PATH has /usr/local/bin, /usr/local/bin/protoc has rwx permissions).</p>  <p>EDITED for ease</p>  <p>Forget everything above for a while.<br> I logged into the buildagent of teamcity server, access the shell using <code>/bin/sh</code> and execute the command <code>protoc</code> and it returns the error:<br> <code>protoc failed error: /bin/sh: 1: protoc: Permission denied</code>  </p>  <p>Any help??</p> ",
    "OwnerUserId": "1690527",
    "LastEditorUserId": "1690527",
    "LastEditDate": "2016-09-09T10:04:03.913",
    "LastActivityDate": "2022-10-07T11:25:37.037",
    "Title": "Permission denied for protoc on maven build in Teamcity",
    "Tags": "<maven><ubuntu><docker><teamcity><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "4",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "39331665",
    "PostTypeId": "1",
    "CreationDate": "2016-09-05T13:27:29.483",
    "Score": "9",
    "ViewCount": "6837",
    "Body": "<p>I am trying to build a project using maven on teamcity and getting this error during maven build step.</p>  <blockquote>   <p>[Step 2/4] [ERROR] protoc failed output:<br>   [Step 2/4] [ERROR] protoc failed error: /bin/sh: 1: protoc: Permission denied   [Step 2/4]  [13:03:14][Step 2/4] Failed to execute goal   com.google.protobuf.tools:maven-protoc-plugin:0.1.10:compile   (generate-sources) on project unit-protocol-lib: protoc did not exit   cleanly. Review output for more information.</p> </blockquote>  <p>Keep in mind I am using docker-compose for building the teamcity agent (agent running in container) and protoc is added to /usr/local/bin/protoc ($PATH has /usr/local/bin, /usr/local/bin/protoc has rwx permissions).</p>  <p>EDITED for ease</p>  <p>Forget everything above for a while.<br> I logged into the buildagent of teamcity server, access the shell using <code>/bin/sh</code> and execute the command <code>protoc</code> and it returns the error:<br> <code>protoc failed error: /bin/sh: 1: protoc: Permission denied</code>  </p>  <p>Any help??</p> ",
    "OwnerUserId": "1690527",
    "LastEditorUserId": "1690527",
    "LastEditDate": "2016-09-09T10:04:03.913",
    "LastActivityDate": "2022-10-07T11:25:37.037",
    "Title": "Permission denied for protoc on maven build in Teamcity",
    "Tags": "<maven><ubuntu><docker><teamcity><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "4",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "39331665",
    "PostTypeId": "1",
    "CreationDate": "2016-09-05T13:27:29.483",
    "Score": "9",
    "ViewCount": "6837",
    "Body": "<p>I am trying to build a project using maven on teamcity and getting this error during maven build step.</p>  <blockquote>   <p>[Step 2/4] [ERROR] protoc failed output:<br>   [Step 2/4] [ERROR] protoc failed error: /bin/sh: 1: protoc: Permission denied   [Step 2/4]  [13:03:14][Step 2/4] Failed to execute goal   com.google.protobuf.tools:maven-protoc-plugin:0.1.10:compile   (generate-sources) on project unit-protocol-lib: protoc did not exit   cleanly. Review output for more information.</p> </blockquote>  <p>Keep in mind I am using docker-compose for building the teamcity agent (agent running in container) and protoc is added to /usr/local/bin/protoc ($PATH has /usr/local/bin, /usr/local/bin/protoc has rwx permissions).</p>  <p>EDITED for ease</p>  <p>Forget everything above for a while.<br> I logged into the buildagent of teamcity server, access the shell using <code>/bin/sh</code> and execute the command <code>protoc</code> and it returns the error:<br> <code>protoc failed error: /bin/sh: 1: protoc: Permission denied</code>  </p>  <p>Any help??</p> ",
    "OwnerUserId": "1690527",
    "LastEditorUserId": "1690527",
    "LastEditDate": "2016-09-09T10:04:03.913",
    "LastActivityDate": "2022-10-07T11:25:37.037",
    "Title": "Permission denied for protoc on maven build in Teamcity",
    "Tags": "<maven><ubuntu><docker><teamcity><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "4",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "39439689",
    "PostTypeId": "1",
    "AcceptedAnswerId": "48448277",
    "CreationDate": "2016-09-11T19:09:56.353",
    "Score": "9",
    "ViewCount": "3061",
    "Body": "<p>Quite often, when I start my docker-composed app, I like to check that everything started correctly and everything's fine.</p>  <p>So I do <code>docker-compose up</code>, look at the logs, and then I have to do <code>docker-compose stop</code>, and <code>docker-compose -d up</code>.</p>  <p>Those are too many steps and having to stop the container means downtime on my server.</p>  <p>Ain't there a way to <em>send docker to the background</em>?</p>  <p>I tried <code>Ctrl+Z</code> but then if I try to exit the ssh session, I get <code>There are stopped jobs.</code>, so that's not the correct way to do this.</p>  <p>I use docker-compose, but I'd be curious if this is possible with docker also.</p>  <p>Thanks</p> ",
    "OwnerUserId": "1620081",
    "LastActivityDate": "2022-04-25T12:48:07.827",
    "Title": "Docker (compose) send to daemon mode without restart",
    "Tags": "<docker><daemon><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "4",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "39457241",
    "PostTypeId": "1",
    "AcceptedAnswerId": "39594533",
    "CreationDate": "2016-09-12T19:16:59.323",
    "Score": "9",
    "ViewCount": "3017",
    "Body": "<p>I have a couple of compose files (docker-compose.yml) describing a simple Django application (five containers, three images).</p>  <p>I want to run this stack in production - to have the whole stack begin on boot, and for containers to restart or be recreated if they crash. There aren't any volumes I care about and the containers won't hold any important state and can be recycled at will.</p>  <p>I haven't found much information on using specifically docker-compose in production in such a way. <a href='https://docs.docker.com/compose/production/' rel='noreferrer'>The documentation</a> is helpful but doesn't mention anything about starting on boot, and I am using Amazon Linux so don't (currently) have access to Docker Machine. I'm used to using supervisord to babysit processes and ensure they start on boot up, but I don't think this is the way to do it with Docker containers, as they end up being ultimately supervised by the Docker daemon?</p>  <p>As a simple start I am thinking to just put <code>restart: always</code> on all my services and make an init script to do <code>docker-compose up -d</code> on boot. Is there a recommended way to manage a docker-compose stack in production in a robust way?</p>  <p>EDIT: I'm looking for a 'simple' way to run the equivalent of <code>docker-compose up</code> for my container stack in a robust way. I know upfront that all the containers declared in the stack can reside on the same machine; in this case I don't have need to orchestrate containers from the same stack across multiple instances, but that would be helpful to know as well.</p> ",
    "OwnerUserId": "2387626",
    "LastEditorUserId": "2387626",
    "LastEditDate": "2016-09-18T16:53:29.983",
    "LastActivityDate": "2016-09-24T22:08:22.773",
    "Title": "Recommended way to run a Docker Compose stack in production?",
    "Tags": "<docker><docker-compose><devops>",
    "AnswerCount": "4",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "39918762",
    "PostTypeId": "1",
    "CreationDate": "2016-10-07T13:43:43.997",
    "Score": "9",
    "ViewCount": "7154",
    "Body": "<p>What I want to do is to use a dump.rdb that I've taken from a production server, and use it in my development environment, that is defined by a very simple compose file. </p>  <p>For simplicity, assume that my app is the same as this <a href='https://docker.github.io/compose/gettingstarted/' rel='noreferrer'>compose example from the docker docs</a> for redis and flask, so the docker-compose.yml looks like: </p>  <pre><code>version: '2'  services:    web:      build: .      ports:       - '5000:5000'      volumes:       - .:/code      depends_on:       - redis    redis:      image: redis </code></pre>  <p>This persists redis data between restarts, but you just cannot access the redis files as there is no volume mounted for redis in the docker-compose.yml.  So I change my compose file to mount a volume for redis, and I also want to force redis to persist data and the <a href='https://hub.docker.com/_/redis/' rel='noreferrer'>official redis image docs</a> say that happens if I use 'appendonly'.</p>  <pre><code>redis:   image: redis   command: redis-server --appendonly yes   volumes:     - ./redis:/data </code></pre>  <p>If I do this, my data are persisted, as they were in the original example, and I can now see a dump.rdb and and appendonly.aof in the /redis path. The problem is, if I want to restore from a dump.rdb I need to turn off appendonly (for example, see digital ocean's how-to-back-up-and-restore-your-redis-data-on-ubuntu-14-04), and without append-only I cannot see how to get the compose file to write to the volume.</p>  <p>How can I produce a docker compose that will persist redis in a volume where I can switch the dump.rdb files, and therefore insert the production snapshot into my development environment?</p>  <p><strong>Update</strong> The following compose works, but be patient when testing, as the creation of the dump.rdb is not instant (hence it seeming like it failed). Also the redis official image doc, implies you have to use appendonly when you don't:</p>  <pre><code>redis:   image: redis   volumes:     - ./redis:/data </code></pre> ",
    "OwnerUserId": "6937453",
    "LastEditorUserId": "6937453",
    "LastEditDate": "2016-10-07T17:18:09.177",
    "LastActivityDate": "2018-06-15T01:12:12.747",
    "Title": "Restoring redis running on docker from dump.rdb",
    "Tags": "<redis><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "39991284",
    "PostTypeId": "1",
    "CreationDate": "2016-10-12T05:45:42.040",
    "Score": "9",
    "ViewCount": "13920",
    "Body": "<p>I'm trying to import a large database to a mysql container. I've mounted host directories as volumes for the mysql container. So the data is persistent on host. The importing sql file is <code>14 GB</code>+. The mysql container becomes unresponsive half way of through importing. When I run <code>docker stats</code> I can see the <code>CPU %</code> usage becomes <code>&lt; 1</code> once mysql container ate all the memory available. I tried increasing memory of docker up to <code>10 GB</code> and It creates more tables from import when I allocate more memory to Docker. But I cannot allocate more than <code>10GB</code> from host.</p>  <p>Following is my <code>docker-compose.yml</code> file</p>  <pre><code>mysql:     image: mysql:5.6     environment:         - MYSQL_ROOT_PASSWORD=12345678     volumes:         - ./mysql/lib:/var/lib/mysql         - ./mysql/conf.d:/etc/mysql/conf.d         - ./mysql/log:/var/log/mysql         - /tmp:/tmp     ports:         - '3306:3306' </code></pre>  <p>I'm using <code>Docker for mac</code> which has docker version <code>1.12.1</code></p>  <p>I was using <code>docker exec -it docker_mysql_1 /bin/bash</code> to login to container and import the sql file from <code>/tmp</code></p>  <p>Also I tried the way recommended by mysql repo by mounting sql file to <code>/docker-entrypoint-initdb.d</code>. But that also halt the mysql init.</p>  <p><strong>UPDATE 1</strong>  </p>  <pre><code>$ docker info Containers: 1  Running: 0  Paused: 0  Stopped: 1 Images: 2 Server Version: 1.12.1 Storage Driver: aufs  Root Dir: /var/lib/docker/aufs  Backing Filesystem: extfs  Dirs: 18  Dirperm1 Supported: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: host bridge null overlay Swarm: inactive Runtimes: runc Default Runtime: runc Security Options: seccomp Kernel Version: 4.4.20-moby Operating System: Alpine Linux v3.4 OSType: linux Architecture: x86_64 CPUs: 4 Total Memory: 9.744 GiB Name: moby ID: 43S4:LA5E:6MTG:IFOG:HHJC:HYLX:LYIT:YU43:QGBQ:K5I5:Z6LP:AENZ Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): true  File Descriptors: 16  Goroutines: 27  System Time: 2016-10-12T07:52:58.516469676Z  EventsListeners: 1 No Proxy: *.local, 169.254/16 Registry: https://index.docker.io/v1/ Insecure Registries:  127.0.0.0/8   $ df -h Filesystem      Size   Used  Avail Capacity iused      ifree %iused  Mounted on /dev/disk1     233Gi  141Gi   92Gi    61% 2181510 4292785769    0%   / devfs          193Ki  193Ki    0Bi   100%     668          0  100%   /dev map -hosts       0Bi    0Bi    0Bi   100%       0          0  100%   /net map auto_home    0Bi    0Bi    0Bi   100%       0          0  100%   /home /dev/disk2s2   466Gi   64Gi  401Gi    14%    1857 4294965422    0%   /Volumes/mac /dev/disk2s3   465Gi   29Gi  436Gi     7%  236633    3575589    6%   /Volumes/PORTABLE /dev/disk3s1   100Mi   86Mi   14Mi    86%      12 4294967267    0%   /Volumes/Vagrant </code></pre>  <p>I was using /dev/disk1 directories to mount volumes.</p> ",
    "OwnerUserId": "625144",
    "LastEditorUserId": "625144",
    "LastEditDate": "2016-10-12T07:57:59.670",
    "LastActivityDate": "2020-10-31T10:59:24.700",
    "Title": "unable to import large database to docker mysql container",
    "Tags": "<mysql><docker><docker-compose>",
    "AnswerCount": "3",
    "CommentCount": "4",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "40245749",
    "PostTypeId": "1",
    "CreationDate": "2016-10-25T17:06:02.367",
    "Score": "9",
    "ViewCount": "10377",
    "Body": "<p>I created a <strong>docker swarm cluster</strong> with <strong>4 nodes</strong> out of it <strong>2 is swarm manager</strong> (swarm supports multiple manager) I understand if the <strong>current</strong> manager node <strong>goes down</strong> then the <strong>second</strong> manager <strong>takes the role</strong> of being the swarm manager. </p>  <p>In my case I am firing the <strong>rest call</strong> to the swarm manager for creating the services with replicas and so on. </p>  <p>At some point if this manager goes down and the second manager becomes manager how do I know ??</p>  <p>Is there any way it gives notified that the particular node is a manager dynamically ?? </p>  <p>Please give me the clarification on this ??</p> ",
    "OwnerUserId": "4278321",
    "LastEditorUserId": "861127",
    "LastEditDate": "2016-11-21T16:12:05.523",
    "LastActivityDate": "2018-04-05T23:00:55.047",
    "Title": "How to find which node is the currently the manager node in docker swarm in a multiple swarm manager cluster?",
    "Tags": "<docker><docker-compose><docker-machine><docker-swarm>",
    "AnswerCount": "4",
    "CommentCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "41221532",
    "PostTypeId": "1",
    "AcceptedAnswerId": "41263454",
    "CreationDate": "2016-12-19T11:25:18.693",
    "Score": "9",
    "ViewCount": "9988",
    "Body": "<p>I'm working on a flask server (in a virtualenv with python 3.5) which is used as a REST API (only for development as suggested for flask). In the beginning it connects to a local sqlite database and it will commit any db changes as soon as possible. Now I wanted to run everything in a docker container and I was wondering how I can access the database because the sqlite file is located in the container.</p>  <p>So I created a volume in a docker-compose file which points to the dockerfile building the application.</p>  <p>Dockerfile:</p>  <pre><code>FROM python:latest ENV HOME /home/parkrep WORKDIR $HOME ADD requirements.txt $HOME/requirements.txt RUN pip install -r requirements.txt ADD . $HOME EXPOSE 80 CMD ['python', 'server.py'] </code></pre>  <p>.dockerignore</p>  <pre><code>__pycache__ venv .gitignore .dockerignore README.md Dockerfile docker-compose.yml </code></pre>  <p>docker-compose.yml</p>  <pre><code>version: '2' services:   parkrep:     build:       context: ./       dockerfile: Dockerfile     volumes:       - ./output:/home/parkrep/output     command: ['python', 'server.py']     ports:       - '80:80' </code></pre>  <p>If I run <code>docker-compose up</code> I get the following </p>  <pre><code>parkrep_1  |   File '/home/parkrep/db_connector.py', line 45, in _connect_db parkrep_1  |     self._connection = sqlite3.connect(path, check_same_thread=False) parkrep_1  | sqlite3.OperationalError: unable to open database file parkrep_parkrep_1 exited with code 1 </code></pre>  <p>If I create the database at output/reports.db and start docker-compose again, it returns the following error:</p>  <pre><code>parkrep_1  | sqlite3.OperationalError: attempt to write a readonly database </code></pre>  <p>So obviously I don't have permissions to write to the file. I tested this behavior by writing to a test file which is mounted like this:</p>  <pre><code>... volumes:   - ./output:/home/parkrep/output   - ./test.txt:/home/parkrep/text.txt command: bash -c 'echo 'hallo' &gt; test.txt' </code></pre>  <p>Error message:</p>  <pre><code>parkrep_1  | bash: text.txt: Permission denied </code></pre>  <p>Let's see who owns this file:</p>  <pre><code>parkrep_1  | drwxr-xr-x 7 root root 4.0K Dec 19 10:45 . parkrep_1  | -rw-rw-r-- 1 root root  143 Dec 12 15:08 config.yaml parkrep_1  | -rw-rw-r-- 1 root root 7.9K Dec 12 14:37 db_connector.py parkrep_1  | drwxrwxr-x 2 4262 4262 4.0K Dec 19 11:10 output parkrep_1  | -rw-rw-r-- 1 root root  144 Dec 12 13:20 requirements.txt parkrep_1  | -rw-rw-r-- 1 root root 2.7K Dec 19 10:14 server.py parkrep_1  | -rw-rw-r-- 1 4262 4262 2.7K Dec 19 10:14 test.txt </code></pre>  <p>It turns out that there is no user 4262 in the container but on the host machine my user account has this id. So I think I know what the problem is now, but I have no clue how to get access to these files. I tried adding ':rw' to the volume definitions but I still don't have write permissions. How can I tell docker to not change the file/directory owner if a volume is defined.</p>  <p>I'm thinking of a problem with my local volume driver, but maybe someone else already had this problem and can tell me how to configure my image to get the required permissions.</p>  <p>Greetings, Thomas</p>  <p><code>docker info</code></p>  <pre><code>     Containers: 1  Running: 0  Paused: 0  Stopped: 1 Images: 19 Server Version: 1.12.5 Storage Driver: aufs  Root Dir: /var/lib/docker/aufs  Backing Filesystem: extfs  Dirs: 19  Dirperm1 Supported: true Logging Driver: json-file Cgroup Driver: cgroupfs Plugins:  Volume: local  Network: host bridge null overlay Swarm: inactive Runtimes: runc Default Runtime: runc Security Options: apparmor seccomp Kernel Version: 4.4.0-53-generic Operating System: Ubuntu 16.04.1 LTS OSType: linux Architecture: x86_64 CPUs: 8 Total Memory: 15.56 GiB Name: de3lxd-107769 ID: PU5F:LZ55:EEK7:W3R7:SYR3:336J:2VRH:35H2:MTLY:6Q6L:BWBP:EM5R Docker Root Dir: /var/lib/docker Debug Mode (client): false Debug Mode (server): false Registry: https://index.docker.io/v1/ WARNING: No swap limit support Insecure Registries:  127.0.0.0/8 </code></pre>  <p><code>docker-compose -v</code></p>  <pre><code>docker-compose version 1.9.0, build 2585387 </code></pre>  <p><code>lsb_release -a</code></p>  <pre><code>No LSB modules are available. Distributor ID: Ubuntu Description:    Ubuntu 16.04.1 LTS Release:    16.04 Codename:   xenial </code></pre> ",
    "OwnerUserId": "4816930",
    "LastActivityDate": "2016-12-21T13:04:36.457",
    "Title": "Docker volume - need permissions to write to database",
    "Tags": "<python><sqlite><docker><docker-compose><docker-volume>",
    "AnswerCount": "1",
    "CommentCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "41332673",
    "PostTypeId": "1",
    "AcceptedAnswerId": "41332978",
    "CreationDate": "2016-12-26T14:30:36.000",
    "Score": "9",
    "ViewCount": "6522",
    "Body": "<p>I've built a custom Docker image based off an <a href='https://hub.docker.com/_/php/' rel='noreferrer'>official PHP FPM image</a> <code>php:7.0.14-fpm-alpine</code> </p>  <p>I wanted to keep the size of the image small, so I went for the official <code>alpine</code> PHP-FPM version as it weighs only <strong>27 MB</strong>.</p>  <p>I installed only few additional packages through my <code>Dockerfile</code>, and the image grew in size to as much as <strong>277.5 MB</strong>. Here is my Dockerfile:</p>  <pre><code>FROM php:7.0.14-fpm-alpine  COPY ./config/www-pool.conf /usr/local/etc/php-fpm.d/www.conf COPY ./scripts/download-composer.sh /root/download-composer.sh  WORKDIR /root  RUN chmod +x download-composer.sh \\     &amp;&amp; ./download-composer.sh \\     &amp;&amp; mv composer.phar /usr/local/bin/composer  RUN ['mkdir', '/var/log/php-fpm']  RUN apk --update add \\       autoconf g++ make \\       openssl-dev \\       libxml2-dev  RUN pecl install \\         xdebug \\         mongodb  RUN docker-php-ext-enable \\         xdebug.so \\         mongodb.so  RUN  docker-php-ext-install \\         pdo_mysql \\         soap  RUN addgroup sudo RUN adduser -S luqo33 -G sudo RUN echo '%sudo ALL=(ALL) NOPASSWD:ALL' &gt;&gt; /etc/sudoers </code></pre>  <p>277.5 MB is a ten-fold increase in size compared to the base image. Apart from Composer, all I needed were several PHP extensions:</p>  <ul> <li>mongodb</li> <li>xdebug</li> <li>pdo</li> <li>soap</li> </ul>  <p>I'm not sure what contributed the most to increasing the size of my image so much. I suspect that it might be due to the <code>dev</code> dependencies that needed to be installed in order to successfully run <code>pecl</code> (<code>openssl-dev</code>, <code>libxml2-dev</code>), and that might have installed their own tree of dependencies.</p>  <p>Could you please advise on how I can reduce the size of my custom PHP-FPM image and still keep the necessary extensions?</p> ",
    "OwnerUserId": "3785777",
    "LastActivityDate": "2016-12-26T15:05:44.633",
    "Title": "Best way to reduce the size of a custom Docker image",
    "Tags": "<php><docker><docker-compose><dockerfile>",
    "AnswerCount": "1",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "41407452",
    "PostTypeId": "1",
    "CreationDate": "2016-12-31T10:23:21.953",
    "Score": "9",
    "ViewCount": "5182",
    "Body": "<p>I decided to change the project name of a docker composition:</p>  <pre class='lang-sh prettyprint-override'><code>$ docker-compose -p old_name up -d # Before Starting old_name_web_1 $ docker-compose -p new_name up -d # After Creating new_name_web_1 </code></pre>  <p>But I don't wanted to delete my containers, so I renamed them:</p>  <pre class='lang-sh prettyprint-override'><code>$ docker rename old_name_web_1 new_name_web_1 ... </code></pre>  <p>I thought docker-compose was based on container names, but it does not seem to be the case:</p>  <pre class='lang-sh prettyprint-override'><code>$ docker-compose -p new_name up -d </code></pre>  <blockquote>   <p>ERROR: for web  Cannot create container for service web: Conflict. The name '/new_name_web_1' is already in use by container 4930deaabb[...]. You have to remove (or rename) that container to be able to reuse that name.   ERROR: Encountered errors while bringing up the project.</p> </blockquote>  <p>How can I relink my old containers to the new composition ?</p> ",
    "OwnerUserId": "305189",
    "LastEditorUserId": "305189",
    "LastEditDate": "2017-06-01T14:47:16.573",
    "LastActivityDate": "2017-06-01T14:47:16.573",
    "Title": "Rename a project by keeping containers",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "3",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "41423349",
    "PostTypeId": "1",
    "CreationDate": "2017-01-02T08:15:58.300",
    "Score": "9",
    "ViewCount": "87944",
    "Body": "<p>I use this to set up nginx for PHP:</p>  <pre><code>nginx:     image: nginx:latest     ports:         - 8080:80     volumes:         - ./code:/code         - ./site.conf:/etc/nginx/conf.d/site.conf     links:         - php php:     image: php:7-fpm     volumes:         - ./code:/code </code></pre>  <p>But how about Apache? How can I set up Apache + PHP in docker-compose.yml?</p>  <p>Following this <a href='https://www.kinamo.be/en/support/faq/setting-up-a-development-environment-with-docker-compose' rel='noreferrer'>guide</a>:</p>  <pre><code>version: '2'  services:   php:     build: php     ports:       - '80:80'       - '443:443'     volumes:       - ./php/www:/var/www/html </code></pre>  <p>Error:</p>  <pre><code>ERROR: In file './docker-compose.yml' service 'version' doesn't have any configuration options. All top level keys in your docker-compose.yml must map to a dictionary of configuration options. </code></pre>  <p>Any ideas? I'm on Xubuntu 16.04.</p>  <p><strong>EDIT:</strong></p>  <p>After managing to upgrade docker-compose to 1.9, I try with this file below:</p>  <pre><code>version: '2' services:     php:         build: php         expose:             - 9000         volumes:             - ./php/www:/var/www/html      apache2:         image: webdevops/apache:latest         args:             - PHP_SOCKET=php:9000         volumes:             - ./php/www:/var/www/html         ports:             - 80:80             - 443:443         links:             - php </code></pre>  <p>Error:</p>  <pre><code>$ sudo docker-compose up -d Building php ERROR: Cannot locate specified Dockerfile: Dockerfile </code></pre>  <p>Docker is such as pain!</p>  <p>Any ideas how to fix this?</p> ",
    "OwnerUserId": "413225",
    "LastEditorUserId": "413225",
    "LastEditDate": "2017-01-02T10:51:33.317",
    "LastActivityDate": "2023-09-18T10:19:41.760",
    "Title": "Docker - how to set up Apache + PHP in docker-compose.yml",
    "Tags": "<php><apache><docker><docker-compose><ubuntu-16.04>",
    "AnswerCount": "7",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "41691584",
    "PostTypeId": "1",
    "AcceptedAnswerId": "41711291",
    "CreationDate": "2017-01-17T07:47:17.197",
    "Score": "9",
    "ViewCount": "24188",
    "Body": "<p>I'm trying to use docker-compose to volume my php.ini file so I can make changes on the fly on my local machine to see how it affects the host machine.  Unfortunately the only way I've been able to get the php.ini file into the container is directly during creation in the Dockerfile so far.</p>  <p>Attached is an image of the container running fine with the current settings below.</p>  <p><a href='https://i.stack.imgur.com/qWhvO.png' rel='noreferrer'><img src='https://i.stack.imgur.com/qWhvO.png' alt='enter image description here'></a></p>  <p><strong>My Dockerfile is below:</strong></p>  <pre><code>FROM ubuntu:14.04 MAINTAINER Joe Astrahan &lt;jastrahan@poolservice.software&gt;  VOLUME ['/var/www']   RUN apt-get update &amp;&amp; \\     apt-get install -y software-properties-common &amp;&amp; \\     apt-get update &amp;&amp; \\     apt-get install -y \\       apache2 \\       curl \\       libcurl3 \\       libcurl3-dev \\       php5 \\       php5-cli \\       libapache2-mod-php5 \\       php5-gd \\       php5-json \\       php5-ldap \\       php5-mysqlnd \\       php5-pgsql \\       php5-curl \\       mysql-client  COPY config/php.ini /etc/php5/apache2/php.ini  # install php-5.5.30 COPY config/install_php-5.5.30.sh /tmp/install_php-5.5.30.sh RUN /bin/bash /tmp/install_php-5.5.30.sh   COPY config/apache_default.conf /etc/apache2/sites-available/000-default.conf COPY config/run /usr/local/bin/run  RUN chmod +x /usr/local/bin/run RUN a2enmod rewrite  #This will allow us to modify files in the container for testing if we need to RUN apt-get update &amp;&amp; \\     apt-get install -y vim  EXPOSE 80 CMD ['/usr/local/bin/run'] </code></pre>  <p><strong>My docker-compose.yml file is below:</strong></p>  <pre><code>version: '2' services:     dblive:         image: mysql:5.5.52         volumes:             - ./db_data_live:/var/lib/mysql         restart: always         environment:             MYSQL_ROOT_PASSWORD: ****             MYSQL_DATABASE: ****             MYSQL_USER: ****             MYSQL_PASSWORD: ****      dbdev:         image: mysql:5.5.52         volumes:             - ./db_data_dev:/var/lib/mysql         restart: always         environment:             MYSQL_ROOT_PASSWORD:****             MYSQL_DATABASE: ****             MYSQL_USER: ****             MYSQL_PASSWORD: ****      phpmyadmin:         depends_on:             - dblive             - dbdev         image: phpmyadmin/phpmyadmin         environment:             PMA_ARBITRARY : 1         restart: always         ports:             - '8081:80'      web:         build: ./         depends_on:             - dblive             - dbdev         volumes:             - ./web:/var/www             - ./config/php.ini:/etc/php5/apache2/conf.d/custom.ini             - ./logs/apache_error.log:/var/log/apache2/error.log             - ./logs/apache_access.log:/var/log/apache2/access.log             - ./config/apache_default.conf:/etc/apache2/sites-enabled/000-default.conf         restart: always         ports:              - '80:80'             - '443:443' </code></pre>  <p>I tried following the advice here, <a href='https://stackoverflow.com/questions/39875543/cant-upate-php-ini-file-in-docker-container'>can&#39;t upate php.ini file in Docker container</a>, by creating a custom.ini file and mounting it in that location.  I actually did it correctly I think because if you look at my image I attached for phpinfo(), you can see that under additional .ini files parsed my custom.ini is there at the end.  I did a test though by setting asp_tags = On instead of Off and I can't.  phpinfo() will always show it as off.  Refer to my attached image of it showing it off despite loading my config file.</p>  <p>I'm not even sure if its really honoring any of the commands in there at all?</p>  <p><a href='https://i.stack.imgur.com/jFtAj.png' rel='noreferrer'><img src='https://i.stack.imgur.com/jFtAj.png' alt='enter image description here'></a></p>  <p><a href='https://i.stack.imgur.com/48moq.png' rel='noreferrer'><img src='https://i.stack.imgur.com/48moq.png' alt='enter image description here'></a></p>  <p><strong>Extra Files Used</strong></p>  <p><strong>Run</strong></p>  <pre><code>#!/bin/bash set -e  PHP_ERROR_REPORTING=${PHP_ERROR_REPORTING:-'E_ALL &amp; ~E_DEPRECATED &amp; ~E_NOTICE'} sed -ri 's/^display_errors\\s*=\\s*Off/display_errors = On/g' /etc/php5/apache2/php.ini sed -ri 's/^display_errors\\s*=\\s*Off/display_errors = On/g' /etc/php5/cli/php.ini sed -ri 's/^error_reporting\\s*=.*$//g' /etc/php5/apache2/php.ini sed -ri 's/^error_reporting\\s*=.*$//g' /etc/php5/cli/php.ini echo 'error_reporting = $PHP_ERROR_REPORTING' &gt;&gt; /etc/php5/apache2/php.ini echo 'error_reporting = $PHP_ERROR_REPORTING' &gt;&gt; /etc/php5/cli/php.ini  source /etc/apache2/envvars &amp;&amp; exec /usr/sbin/apache2 -DFOREGROUND </code></pre>  <p><strong>install_php-5.5.30.sh</strong></p>  <pre><code>#!/bin/bash  # install dependencies apt-get -y update &amp;&amp; \\ apt-get install -y \\   build-essential \\   apache2-dev \\   libxml2-dev  # download PHP 5.5.30 source code cd /tmp curl -fsSL http://php.net/get/php-5.5.30.tar.bz2/from/this/mirror | tar xjf - cd php-5.5.30  # configure build options ./configure --prefix=/usr \\             --with-config-file-path=/etc/php5/apache2 \\             --with-config-file-scan-dir=/etc/php5/apache2/conf.d \\             --disable-pdo \\             --disable-json \\             --enable-mbstring \\             --with-apxs2  # compile and install NUM_CORES=`cat /proc/cpuinfo | grep processor | wc -l` make -j $NUM_CORES make install  # configure extension directory echo 'extension_dir='/usr/lib/php5/20121212'' &gt;&gt; /etc/php5/apache2/php.ini  # cleanup rm -rf /tmp/php-5.5.30 /tmp/install_php-5.5.30.sh </code></pre>  <p><strong>My file structure</strong></p>  <p><a href='https://i.stack.imgur.com/9uu5Y.png' rel='noreferrer'><img src='https://i.stack.imgur.com/9uu5Y.png' alt='enter image description here'></a></p> ",
    "OwnerUserId": "1606689",
    "LastEditorUserId": "-1",
    "LastEditDate": "2017-05-23T12:16:41.197",
    "LastActivityDate": "2024-01-22T15:40:06.547",
    "Title": "Docker-Compose won't volume my php.ini file",
    "Tags": "<php><docker><docker-compose><dockerfile><docker-volume>",
    "AnswerCount": "3",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "41871950",
    "PostTypeId": "1",
    "AcceptedAnswerId": "41907584",
    "CreationDate": "2017-01-26T10:55:46.110",
    "Score": "9",
    "ViewCount": "3837",
    "Body": "<p>I'm trying to deploy an app that's built with docker-compose, but it feels like I'm going in completely the wrong direction.</p>  <ol> <li>I have everything working locally\u2014<code>docker-compose up</code> brings up my app with the appropriate networks and hosts in place.</li> <li>I want to be able to run the same configuration of containers and networks on a production machine, just using a different <code>.env</code> file.</li> </ol>  <p>My current workflow looks something like this:</p>  <pre><code>docker save [web image] [db image] &gt; containers.tar zip deploy.zip containers.tar docker-compose.yml rsync deploy.zip user@server  ssh user@server unzip deploy.zip ./ docker load -i containers.tar  docker-compose up </code></pre>  <p>At this point, I was hoping to be able to run <code>docker-compose up</code> again when they get there, but that tries to rebuild the containers as per the <code>docker-compose.yml</code> file.</p>  <p>I'm getting the distinct feeling that I'm missing something. Should I be shipping over my full application then building the images at the server instead? How would you start composed containers if you were storing/loading the images from a registry?</p> ",
    "OwnerUserId": "1088797",
    "LastEditorUserId": "1088797",
    "LastEditDate": "2017-01-26T11:44:41.020",
    "LastActivityDate": "2017-01-28T07:56:27.800",
    "Title": "Deploying docker-compose containers",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "6",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "42302632",
    "PostTypeId": "1",
    "AcceptedAnswerId": "42302633",
    "CreationDate": "2017-02-17T16:19:08.077",
    "Score": "9",
    "ViewCount": "8005",
    "Body": "<p>I am looking for a way to deploy <code>docker-compose</code> images and / or builds to a remote sever, specifically but not limited to a DigitalOcean VPS.</p>  <p><code>docker-compose</code> is currently working on the CircleCI Continuous Integration service, where it automatically verifies that tests pass. But, it <strong>should deploy automatically on success</strong>.</p>  <p>My <code>docker-compose.yml</code> is looking like this:</p>  <pre><code>version: '2' services:   web:     image: name/repo:latest     ports:       - '3000:3000'     volumes:       - /app/node_modules       - .:/app     depends_on:        - mongo       - redis   mongo:     image: mongo     command: --smallfiles     volumes:       - ./data/mongodb:/data/db   redis:     image: redis     volumes:       - ./data/redis:/data </code></pre>  <p><code>docker-compose.override.yml</code>:</p>  <pre><code>version: '2' services:   web:     build: . </code></pre>  <p><code>circle.yml</code> relevant part:</p>  <pre><code>deployment:   latest:     branch: master     commands:       - docker login -e $DOCKER_EMAIL -u $DOCKER_USER -p $DOCKER_PASS       - docker push name/repo:$CIRCLE_SHA1       - docker push name/repo:latest </code></pre> ",
    "OwnerUserId": "2013580",
    "LastActivityDate": "2018-07-21T00:54:42.407",
    "Title": "Docker Compose Continuous Deployment setup",
    "Tags": "<docker><deployment><docker-compose><continuous-deployment>",
    "AnswerCount": "2",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "42398199",
    "PostTypeId": "1",
    "AcceptedAnswerId": "42416093",
    "CreationDate": "2017-02-22T17:19:32.183",
    "Score": "9",
    "ViewCount": "20997",
    "Body": "<p>I am trying to build and run two Docker containers hosting PostgreSQL and Citus extension using <code>ansible-container</code>. I am aware that Citus provides containers, but I want to build my own.</p>  <p>My <code>container.yaml</code> looks as follows:</p>  <pre class='lang-yaml prettyprint-override'><code>version: '2'  services:    database_master:     image: hackermd/ubuntu-trusty-python     user: postgres     expose:       - 5043     entrypoint: ['dumb-init', '--']     command: ['/usr/bin/pg_ctlcluster', '9.6', 'master', 'start']     links:       - database_worker     depends_on:       - database_worker    database_worker:     image: hackermd/ubuntu-trusty-python     user: postgres     expose:     - 9700   entrypoint: ['dumb-init', '--']   command: ['/usr/bin/pg_ctlcluster', '9.6', 'worker', 'start'] </code></pre>  <p>During the build process I can start and stop the cluster via <code>pg_ctlcluster</code> and it finishes successfully. However, when I subsequently run the containers, I get the following error:</p>  <pre class='lang-none prettyprint-override'><code>$ docker logs ansible_database_master_1 Removed stale pid file. Warning: connection to the database failed, disabling startup checks: psql: FATAL:  the database system is starting up </code></pre>  <p>When I build containers with <code>command: []</code> and run <code>ps aux</code> inside the container, I see the following process:</p>  <pre class='lang-none prettyprint-override'><code>postgres    14  1.6  0.1 307504  3480 ?        Ds   16:46   0:00 postgres: 9.6/master: startup process </code></pre>  <p>I've also tried without the <code>dumb-init</code> entrypoint. What am I missing?</p> ",
    "OwnerUserId": "5483098",
    "LastEditorUserId": "5483098",
    "LastEditDate": "2017-02-22T23:14:45.610",
    "LastActivityDate": "2020-05-06T15:00:07.077",
    "Title": "Dockerized PostgreSQL: psql: FATAL: the database system is starting up",
    "Tags": "<postgresql><docker><ansible><docker-compose><ansible-container>",
    "AnswerCount": "2",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "42426378",
    "PostTypeId": "1",
    "CreationDate": "2017-02-23T21:19:09.850",
    "Score": "9",
    "ViewCount": "5383",
    "Body": "<p>I'm creating an entrypoint for a Docker container, and then attempting to run it using a <code>docker-compose.yml</code> file.  <strong>This works just fine in Ubuntu and OS X</strong>, but I get a permissions error (without much additional information) in Windows</p>  <p>Here is the Dockerfile:</p>  <pre><code>FROM node:6.9  MAINTAINER Some Dude &lt;dude@dude.com&gt;  WORKDIR /opt  # Install Compass RUN DEBIAN_FRONTEND=noninteractive apt-get -y dist-upgrade RUN apt-get -y update RUN apt-get -y install gcc rubygems ruby-dev RUN gem update --system RUN gem install compass  # Install Compass Extensions RUN gem install compass-blend-modes compass-import-once  # Install glup globally RUN npm install -g gulp  # Copy the setup file COPY setup/gulp/docker-gulp-setup.sh /usr/local/bin/docker-gulp-setup.sh RUN chmod +x /usr/local/bin/docker-gulp-setup.sh  CMD ['gulp'] </code></pre>  <p>Here is the docker-compose.yml entry:</p>  <pre><code>version: '2'  services:          mycontainer-for-gulp:                 build:                         context: .                         dockerfile: Dockerfile.gulp                 volumes:                         - ./:/opt:Z                 command: /usr/local/bin/docker-gulp-setup.sh </code></pre>  <p>Here is the output when the build command is run on Windows:</p>  <pre><code>\u03bb docker-compose build mycontainer-for-gulp Building mycontainer-for-gulp Traceback (most recent call last):  File '&lt;string&gt;', line 3, in &lt;module&gt;  File 'compose\\cli\\main.py', line 65, in main  File 'compose\\cli\\main.py', line 117, in perform_command  File 'compose\\cli\\main.py', line 223, in build  File 'compose\\project.py', line 300, in build  File 'compose\\service.py', line 742, in build  File 'site-packages\\docker\\api\\build.py', line 55, in build  File 'site-packages\\docker\\utils\\utils.py', line 95, in tar  File 'tarfile.py', line 2023, in add  File 'tarfile.py', line 2052, in addfile  File 'tarfile.py', line 278, in copyfileobj IOError: [Errno 13] Permission denied docker-compose returned -1 </code></pre>  <p>Note that it IS the <code>COPY</code> command that's generating the error, because we tried commenting out both that and the <code>RUN chmod</code> statement individually.</p>  <p>When I run a raw docker build query:</p>  <pre><code>docker build -f Dockerfile.gulp . </code></pre>  <p>Then I get a bunch of error output as it tries to tar up the current directory.  Basically every file add fails.  Full output is here:</p>  <p><a href='https://gist.github.com/danieltalsky/4cb6bddb6534c46b051230bc45578072' rel='noreferrer'>https://gist.github.com/danieltalsky/4cb6bddb6534c46b051230bc45578072</a></p> ",
    "OwnerUserId": "22452",
    "LastEditorUserId": "22452",
    "LastEditDate": "2017-02-24T19:16:21.897",
    "LastActivityDate": "2021-02-23T08:31:13.243",
    "Title": "Docker build fails on COPY or ADD statement for entrypoint, Windows only",
    "Tags": "<docker><docker-compose><file-permissions><docker-for-windows>",
    "AnswerCount": "2",
    "CommentCount": "13",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "42672171",
    "PostTypeId": "1",
    "AcceptedAnswerId": "42676571",
    "CreationDate": "2017-03-08T13:05:14.477",
    "Score": "9",
    "ViewCount": "11498",
    "Body": "<p>I am having problem sharing a folder between Docker containers running on different nodes of Docker Swarm. My swarm consist of one manager and two workers.</p>  <p>I am using this compose file to deploy applications:</p>  <pre><code>version: '3'  services:    redis:     image:       redis:latest     networks:       - default     ports:       - 6379:6379     volumes:       - test-volume:/test     deploy:       replicas: 1       update_config:         parallelism: 2         delay: 10s       restart_policy:         condition: on-failure       placement:         constraints: [node.role == manager]    logstash:     image: docker.elastic.co/logstash/logstash:5.2.2     networks:       - default     volumes:       - test-volume:/test     deploy:       placement:         constraints: [node.role == worker]  networks:   default:     external: false  volumes:   test-volume: </code></pre>  <p>I can confirm that the folder is successfully mounted in both containers with use of <code>docker exec _id_ ls /test</code>. But when I add a file into this folder  with <code>docker exec _id_ touch /test/file</code> second container does not see created file.</p>  <p>How to configure the swarm so the files are visible in both containers?</p> ",
    "OwnerUserId": "3423236",
    "LastActivityDate": "2017-12-07T12:04:49.477",
    "Title": "Volume is not shared between nodes of Docker Swarm",
    "Tags": "<docker><docker-compose><docker-swarm>",
    "AnswerCount": "1",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "43121897",
    "PostTypeId": "1",
    "AcceptedAnswerId": "43130286",
    "CreationDate": "2017-03-30T15:16:56.700",
    "Score": "9",
    "ViewCount": "14691",
    "Body": "<p>I'm using docker-compose to run my project created by node,mongodb,nginx;</p>  <p>and I have build the project using <code>docker build</code></p>  <p>and then I use <code>docker up -d nginx</code> to start my project. but I haven't found the config to run mongodb image with '--auth', so how to add '--auth' when compose start the mongodb?</p>  <p>here is my docker-compose.yml:</p>  <pre><code>version: '2' services:   mongodb:     image: mongo:latest     expose:         - '27017'     volumes:         - '/home/open/mymongo:/data/db'   nginx:     build: /home/open/mynginx/     ports:         - '8080:8080'         - '80:80'     links:         - node_server:node   node_server:     build: /home/laoqiren/workspace/isomorphic-redux-CNode/      links:         - mongodb:mongo     expose:         - '3000' </code></pre> ",
    "OwnerUserId": "6271247",
    "LastActivityDate": "2017-04-15T19:45:24.233",
    "Title": "how to add --auth for mongodb image when using docker-compose?",
    "Tags": "<node.js><mongodb><nginx><docker><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "43281251",
    "PostTypeId": "1",
    "CreationDate": "2017-04-07T14:57:04.983",
    "Score": "9",
    "ViewCount": "2752",
    "Body": "<p>I'm trying to write a compose-file using a service (node) that I'd like to scale to 3 containers. This service has a volume to be bond to my local system for persistence, but I'd like the different tasks having different binding on my system ? I tried to use the template <code>{{.Task.Slot}}</code> inside my docker-compose.yml as shown below, but I cannot figured out out to make it work...</p>  <pre><code>version: '3.2' services:      node:         build:             context: ./node         volumes:             - nodeVol:/data         command: ['myapp']  volumes:     nodeVol:         external:             name: './persistence/{{.Task.Slot}}' </code></pre>  <p>Any idea of what went wrong ?</p> ",
    "OwnerUserId": "7833346",
    "LastActivityDate": "2017-04-07T14:57:04.983",
    "Title": "docker-compose scale service with independent volumes",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "0",
    "CommentCount": "4",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "43517984",
    "PostTypeId": "1",
    "CreationDate": "2017-04-20T11:15:18.620",
    "Score": "9",
    "ViewCount": "9932",
    "Body": "<p>I am using docker-compose version 2. I am starting containers with <code>docker-compose -p some_name up -d</code> and trying to kill them with <code>docker-compose stop</code>. The commands exits with <code>0</code> code but the containers are still up and running. </p>  <p>Is this the expected behaviour for version? If yes, any idea how can I work around it?</p>  <p>my <code>docker-compose.yml</code> file looks like this</p>  <pre><code>version: '2' services:    elasticsearch:     image: docker.elastic.co/elasticsearch/elasticsearch:5.3.0     ports:       - '9200:9200'     environment:       ES_JAVA_OPTS: '-Xmx512m -Xms512m'       xpack.security.enabled: 'false'       xpack.monitoring.enabled: 'false'       xpack.graph.enabled: 'false'       xpack.watcher.enabled: 'false'     ulimits:       memlock:         soft: -1         hard: -1       nofile:         soft: 262144         hard: 262144    kafka-server:     image: spotify/kafka     environment:       - TOPICS=my-topic     ports:      - '9092:9092'    test:     build: .     depends_on:       - elasticsearch       - kafka-server </code></pre>  <p><strong>update</strong></p>  <p>I found that the problem is caused by using the <code>-p</code> parameter and giving explicit prefix to the container. Still looking for the best way to solve it.</p> ",
    "OwnerUserId": "4068678",
    "LastEditorUserId": "4068678",
    "LastEditDate": "2017-04-20T13:11:45.553",
    "LastActivityDate": "2019-01-12T00:29:39.653",
    "Title": "docker-compose stop not working after docker-compose -p <name> up",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "7",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "44166269",
    "PostTypeId": "1",
    "AcceptedAnswerId": "44187181",
    "CreationDate": "2017-05-24T18:41:21.723",
    "Score": "9",
    "ViewCount": "14497",
    "Body": "<p>I have a docker container from which I am trying to run a pyqt app. Everything works well except a chunk of the GUI is not able to render. The docker logs throw this out:</p>  <pre><code>libGL error: failed to load driver: swrast X Error: GLXBadContext 169  Extension:    154 (Uknown extension)  Minor opcode: 6 (Unknown request)  Resource id:  0x6400003 X Error: BadValue (integer parameter out of range for operation) 2  Extension:    154 (Uknown extension)  Minor opcode: 3 (Unknown request)  Resource id:  0x0 ... QGLContext::makeCurrent(): Failed. </code></pre>  <p>In my Dockerfile, I tried installing pretty much all the packages I could find that might be related, including <code>mesa-utils</code>.</p>  <p>In terms of the docker-compose file, here's what it looks like:</p>  <pre><code>version: '2'     services:     gui:         build: .         volumes:         - .:/usr/src         - /tmp/.X11-unix:/tmp/.X11-unix         command: /bin/bash -c 'python start.py'         environment:         - DISPLAY=unix$DISPLAY         - QT_X11_NO_MITSHM=1         devices:         - '/dev/snd:/dev/snd'         - '/dev/dri:/dev/dri'         privileged: true </code></pre>  <p>Any ideas what I might be missing?</p> ",
    "OwnerUserId": "1631331",
    "LastActivityDate": "2017-05-25T18:11:54.837",
    "Title": "libGL error: failed to load driver swrast in docker container",
    "Tags": "<docker><pyqt><docker-compose><dockerfile><nvidia>",
    "AnswerCount": "1",
    "CommentCount": "1",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "44535976",
    "PostTypeId": "1",
    "AcceptedAnswerId": "44551468",
    "CreationDate": "2017-06-14T05:16:32.410",
    "Score": "9",
    "ViewCount": "21652",
    "Body": "<p>Here is the docker-compose.yml</p>  <pre><code>version: \u201c2\u201d services:   web:    build: .    environment:     MONGO_URI='mongodb://ravimongo:27017'    ports:     \u2014 \u201c3000:3000\u201d    links:     \u2014 ravimongo    depends_on:     \u2014 ravimongo   ravimongo:    image: mongo:3.2.6    ports:      \u2014 \u201c27017:27017\u201d </code></pre>  <p>Here is the error:</p>  <pre><code>ERROR: Version in './docker-compose.yml' is unsupported. You might be seeing this error because you're using the wrong Compose file version. Either specify a supported version ('2.0', '2.1', '3.0') and place your service definitions under the `services` key, or omit the `version` key and place your service definitions at the root of the file to use version 1. For more on the Compose file format versions, see https://docs.docker.com/compose/compose-file/ </code></pre>  <p>Version details are as follows: docker-compose version</p>  <pre><code>docker-compose version 1.11.2, build dfed245 docker-py version: 2.1.0 CPython version: 2.7.12 OpenSSL version: OpenSSL 1.0.2j  26 Sep 2016 </code></pre>  <p>docker version</p>  <pre><code>Client:  Version:      17.03.1-ce  API version:  1.27  Go version:   go1.7.5  Git commit:   c6d412e  Built:        Tue Mar 28 00:40:02 2017  OS/Arch:      darwin/amd64  Server:  Version:      17.03.1-ce  API version:  1.27 (minimum version 1.12)  Go version:   go1.7.5  Git commit:   c6d412e  Built:        Fri Mar 24 00:00:50 2017  OS/Arch:      linux/amd64  Experimental: true </code></pre>  <p>I verified the yaml syntax in <a href='http://www.yamllint.com/' rel='noreferrer'>http://www.yamllint.com/</a> and <a href='https://codebeautify.org/yaml-validator' rel='noreferrer'>https://codebeautify.org/yaml-validator</a>. I am unable to find the problem.</p> ",
    "OwnerUserId": "3871015",
    "LastActivityDate": "2019-09-03T07:52:47.820",
    "Title": "ERROR: Version in './docker-compose.yml' is unsupported. You might be seeing this error because you're using the wrong Compose file version",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "4",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "44738469",
    "PostTypeId": "1",
    "CreationDate": "2017-06-24T16:20:56.010",
    "Score": "9",
    "ViewCount": "7110",
    "Body": "<p>I have a spring cloud config server and packaged it as a docker image then I have spring cloud eureka server which is also packaged as docker image.</p>  <p>When I run the two using docker compose I get the following error.</p>  <p><code>discovery-service_1  | 2017-06-24 15:36:12.059  INFO 5 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at: http://config-service:9001 discovery-service_1  | 2017-06-24 15:36:12.997  WARN 5 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for 'http://config-service:9001/cls-discovery-service/default': Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused) </code></p>  <blockquote>   <p>Although the config service is up and running successfully, discover service still does not find it for some reason.</p> </blockquote>  <p><strong>Docker compose file being used here is this</strong>  <code> version: '2' services:         config-service:                 image: cloudsea/cls-config-service                 ports:                 - 9001:9001                 expose:                 - '9001'         discovery-service:                 image: cloudsea/cls-discovery-service                 depends_on:                 - config-service                 environment:                         CLOUD_SEA_CONFIG_SERVER_URI: http://config-service:9001                         EUREKA_DEFAULT_ZONE_URL: http://discovery-service:8761/eureka/                 ports:                 - 8761:8761                 links:                 - config-service:config-service </code></p>  <p>Below is the <strong>bootstrap.properties</strong> for DISCOVERY SERVICE</p>  <p><code>spring.cloud.config.uri = ${CLOUD_SEA_CONFIG_SERVER_URI:http://localhost:9001} spring.application.name = ${SPRING_APPLICATION_NAME:cls-discovery-service} </code></p>  <p>Below is the <strong>cls-discovery-service.properties</strong> for DISCOVERY SERVICE located in github.</p>  <p><code>server.port=${SERVER_PORT:8761} eureka.client.registerWithEureka: false eureka.client.fetchRegistry: false eureka.client.serviceUrl.defaultZone: ${EUREKA_DEFAULT_ZONE_URL:http://localhost:8761/eureka/} eureka.server.eviction-interval-timer-in-ms: 1000 </code></p>  <p>I am assuming something is wrong with my docker-compose.yml but I am not sure.</p>  <p>Any help will I am stick in this for hours ... heading close to days :(</p> ",
    "OwnerUserId": "3058432",
    "LastActivityDate": "2018-02-06T23:23:47.990",
    "Title": "Spring Cloud Config Server not working with Docker compose",
    "Tags": "<spring-boot><docker-compose><spring-cloud><spring-cloud-netflix><spring-cloud-config>",
    "AnswerCount": "3",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "44738469",
    "PostTypeId": "1",
    "CreationDate": "2017-06-24T16:20:56.010",
    "Score": "9",
    "ViewCount": "7110",
    "Body": "<p>I have a spring cloud config server and packaged it as a docker image then I have spring cloud eureka server which is also packaged as docker image.</p>  <p>When I run the two using docker compose I get the following error.</p>  <p><code>discovery-service_1  | 2017-06-24 15:36:12.059  INFO 5 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at: http://config-service:9001 discovery-service_1  | 2017-06-24 15:36:12.997  WARN 5 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for 'http://config-service:9001/cls-discovery-service/default': Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused) </code></p>  <blockquote>   <p>Although the config service is up and running successfully, discover service still does not find it for some reason.</p> </blockquote>  <p><strong>Docker compose file being used here is this</strong>  <code> version: '2' services:         config-service:                 image: cloudsea/cls-config-service                 ports:                 - 9001:9001                 expose:                 - '9001'         discovery-service:                 image: cloudsea/cls-discovery-service                 depends_on:                 - config-service                 environment:                         CLOUD_SEA_CONFIG_SERVER_URI: http://config-service:9001                         EUREKA_DEFAULT_ZONE_URL: http://discovery-service:8761/eureka/                 ports:                 - 8761:8761                 links:                 - config-service:config-service </code></p>  <p>Below is the <strong>bootstrap.properties</strong> for DISCOVERY SERVICE</p>  <p><code>spring.cloud.config.uri = ${CLOUD_SEA_CONFIG_SERVER_URI:http://localhost:9001} spring.application.name = ${SPRING_APPLICATION_NAME:cls-discovery-service} </code></p>  <p>Below is the <strong>cls-discovery-service.properties</strong> for DISCOVERY SERVICE located in github.</p>  <p><code>server.port=${SERVER_PORT:8761} eureka.client.registerWithEureka: false eureka.client.fetchRegistry: false eureka.client.serviceUrl.defaultZone: ${EUREKA_DEFAULT_ZONE_URL:http://localhost:8761/eureka/} eureka.server.eviction-interval-timer-in-ms: 1000 </code></p>  <p>I am assuming something is wrong with my docker-compose.yml but I am not sure.</p>  <p>Any help will I am stick in this for hours ... heading close to days :(</p> ",
    "OwnerUserId": "3058432",
    "LastActivityDate": "2018-02-06T23:23:47.990",
    "Title": "Spring Cloud Config Server not working with Docker compose",
    "Tags": "<spring-boot><docker-compose><spring-cloud><spring-cloud-netflix><spring-cloud-config>",
    "AnswerCount": "3",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "44738469",
    "PostTypeId": "1",
    "CreationDate": "2017-06-24T16:20:56.010",
    "Score": "9",
    "ViewCount": "7110",
    "Body": "<p>I have a spring cloud config server and packaged it as a docker image then I have spring cloud eureka server which is also packaged as docker image.</p>  <p>When I run the two using docker compose I get the following error.</p>  <p><code>discovery-service_1  | 2017-06-24 15:36:12.059  INFO 5 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Fetching config from server at: http://config-service:9001 discovery-service_1  | 2017-06-24 15:36:12.997  WARN 5 --- [           main] c.c.c.ConfigServicePropertySourceLocator : Could not locate PropertySource: I/O error on GET request for 'http://config-service:9001/cls-discovery-service/default': Connection refused (Connection refused); nested exception is java.net.ConnectException: Connection refused (Connection refused) </code></p>  <blockquote>   <p>Although the config service is up and running successfully, discover service still does not find it for some reason.</p> </blockquote>  <p><strong>Docker compose file being used here is this</strong>  <code> version: '2' services:         config-service:                 image: cloudsea/cls-config-service                 ports:                 - 9001:9001                 expose:                 - '9001'         discovery-service:                 image: cloudsea/cls-discovery-service                 depends_on:                 - config-service                 environment:                         CLOUD_SEA_CONFIG_SERVER_URI: http://config-service:9001                         EUREKA_DEFAULT_ZONE_URL: http://discovery-service:8761/eureka/                 ports:                 - 8761:8761                 links:                 - config-service:config-service </code></p>  <p>Below is the <strong>bootstrap.properties</strong> for DISCOVERY SERVICE</p>  <p><code>spring.cloud.config.uri = ${CLOUD_SEA_CONFIG_SERVER_URI:http://localhost:9001} spring.application.name = ${SPRING_APPLICATION_NAME:cls-discovery-service} </code></p>  <p>Below is the <strong>cls-discovery-service.properties</strong> for DISCOVERY SERVICE located in github.</p>  <p><code>server.port=${SERVER_PORT:8761} eureka.client.registerWithEureka: false eureka.client.fetchRegistry: false eureka.client.serviceUrl.defaultZone: ${EUREKA_DEFAULT_ZONE_URL:http://localhost:8761/eureka/} eureka.server.eviction-interval-timer-in-ms: 1000 </code></p>  <p>I am assuming something is wrong with my docker-compose.yml but I am not sure.</p>  <p>Any help will I am stick in this for hours ... heading close to days :(</p> ",
    "OwnerUserId": "3058432",
    "LastActivityDate": "2018-02-06T23:23:47.990",
    "Title": "Spring Cloud Config Server not working with Docker compose",
    "Tags": "<spring-boot><docker-compose><spring-cloud><spring-cloud-netflix><spring-cloud-config>",
    "AnswerCount": "3",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "44926335",
    "PostTypeId": "1",
    "AcceptedAnswerId": "44926594",
    "CreationDate": "2017-07-05T12:29:33.263",
    "Score": "9",
    "ViewCount": "15090",
    "Body": "<p>I'm trying to run Elasticsearch using docker compose but I'm not sure how to correctly pass the <code>ES_JAVA_OPTS='-Xms512m -Xmx512m'</code> environmental variable. I've tried lots of combinations of single and double quotes but they all result in: <code>Error: Could not find or load main class '-Xms512m</code>.</p>  <p>My docker-compose config is:</p>  <pre><code>elasticsearch:   image: 'docker.elastic.co/elasticsearch/elasticsearch:5.4.3'   ports:    - '6379:6379'   environment:    - 'http.host=0.0.0.0'    - 'transport.host=127.0.0.1'    - 'xpack.security.enabled=false'    - 'ES_JAVA_OPTS='-Xms512m -Xmx512m'' </code></pre>  <p>This environmental variable works just fine when running the container directly with:</p>  <pre><code>docker run --detach \\   --name elasticsearch \\   --publish 9200:9200 \\   --env 'http.host=0.0.0.0' \\   --env 'transport.host=127.0.0.1' \\   --env 'xpack.security.enabled=false' \\   --env 'ES_JAVA_OPTS=''-Xms512m -Xmx512m''' \\   docker.elastic.co/elasticsearch/elasticsearch:5.4.3 </code></pre>  <p>What am I missing here?</p> ",
    "OwnerUserId": "8799",
    "LastActivityDate": "2022-07-25T08:40:06.707",
    "Title": "Passing ES_JAVA_OPTS variable with spaces when using docker compose",
    "Tags": "<elasticsearch><docker><environment-variables><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "45160692",
    "PostTypeId": "1",
    "AcceptedAnswerId": "45163491",
    "CreationDate": "2017-07-18T07:55:15.203",
    "Score": "9",
    "ViewCount": "8897",
    "Body": "<p>I have just started out with Docker, and I am currently trying to run <code>docker-compose run --rm setup</code> on a docker-compose.yml file, but whenever I do, I receive the following:</p>  <pre><code>Traceback (most recent call last):   File '/home/wickywills/.local/bin/docker-compose', line 11, in &lt;module&gt;     sys.exit(main())   File '/home/wickywills/.local/lib/python2.7/site-packages/compose/cli/main.py', line 68, in main     command()   File '/home/wickywills/.local/lib/python2.7/site-packages/compose/cli/main.py', line 118, in perform_command     handler(command, command_options)   File '/home/wickywills/.local/lib/python2.7/site-packages/compose/cli/main.py', line 750, in run     run_one_off_container(container_options, self.project, service, options)   File '/home/wickywills/.local/lib/python2.7/site-packages/compose/cli/main.py', line 1136, in run_one_off_container     rescale=False   File '/home/wickywills/.local/lib/python2.7/site-packages/compose/project.py', line 388, in up     warn_for_swarm_mode(self.client)   File '/home/wickywills/.local/lib/python2.7/site-packages/compose/project.py', line 614, in warn_for_swarm_mode     info = client.info()   File '/home/wickywills/.local/lib/python2.7/site-packages/docker/api/daemon.py', line 90, in info     return self._result(self._get(self._url('/info')), True)   File '/home/wickywills/.local/lib/python2.7/site-packages/docker/utils/decorators.py', line 46, in inner     return f(self, *args, **kwargs)   File '/home/wickywills/.local/lib/python2.7/site-packages/docker/api/client.py', line 189, in _get     return self.get(url, **self._set_request_timeout(kwargs))   File '/home/wickywills/.local/lib/python2.7/site-packages/requests/sessions.py', line 515, in get     return self.request('GET', url, **kwargs)   File '/home/wickywills/.local/lib/python2.7/site-packages/requests/sessions.py', line 502, in request     resp = self.send(prep, **send_kwargs)   File '/home/wickywills/.local/lib/python2.7/site-packages/requests/sessions.py', line 612, in send     r = adapter.send(request, **kwargs)   File '/home/wickywills/.local/lib/python2.7/site-packages/requests/adapters.py', line 440, in send     timeout=timeout   File '/home/wickywills/.local/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.py', line 582, in urlopen     timeout_obj = self._get_timeout(timeout)   File '/home/wickywills/.local/lib/python2.7/site-packages/requests/packages/urllib3/connectionpool.py', line 309, in _get_timeout     return Timeout.from_float(timeout)   File '/home/wickywills/.local/lib/python2.7/site-packages/requests/packages/urllib3/util/timeout.py', line 154, in from_float     return Timeout(read=timeout, connect=timeout)   File '/home/wickywills/.local/lib/python2.7/site-packages/requests/packages/urllib3/util/timeout.py', line 97, in __init__     self._connect = self._validate_timeout(connect, 'connect')   File '/home/wickywills/.local/lib/python2.7/site-packages/requests/packages/urllib3/util/timeout.py', line 127, in _validate_timeout     'int or float.' % (name, value)) ValueError: Timeout value connect was Timeout(connect=60, read=60, total=None), but it must be an int or float. </code></pre>  <h2>Pip Freeze</h2>  <pre><code>backports.ssl-match-hostname==3.5.0.1 boto==2.40.0 cached-property==1.3.0 certifi==2017.4.17 chardet==3.0.4 colorama==0.3.9 cryptography==1.5 docker==2.4.2 docker-compose==1.14.0 docker-pycreds==0.2.1 dockerpty==0.4.1 docopt==0.6.2 duplicity==0.7.6 enum34==1.1.6 functools32==3.2.3.post2 idna==2.5 ipaddress==1.0.18 jsonschema==2.6.0 lockfile==0.12.2 mysql-connector-python==2.1.3 mysql-utilities==1.6.3 ndg-httpsclient==0.4.2 paramiko==2.0.0 pexpect==4.2.0 ptyprocess==0.5.1 pyasn1==0.1.9 pycrypto==2.6.1 pygobject==3.22.0 pyodbc==3.0.10 pyOpenSSL==16.1.0 pysqlite==2.7.0 python-cloudfiles==1.7.10 PyYAML==3.12 requests==2.18.1 six==1.10.0 texttable==0.8.8 urllib3==1.21.1 websocket-client==0.44.0 </code></pre>  <p>Seems like this is a common issue, without a real solution. I am running Ubuntu 16.10, and followed the installation instructions as per the Docker documentation. Can anyone advise?</p> ",
    "OwnerUserId": "2136354",
    "LastEditorUserId": "2136354",
    "LastEditDate": "2017-07-18T10:33:48.150",
    "LastActivityDate": "2023-05-23T17:29:19.713",
    "Title": "Docker - Timeout value connect was Timeout",
    "Tags": "<python><docker><python-requests><docker-compose>",
    "AnswerCount": "3",
    "CommentCount": "5",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "45193939",
    "PostTypeId": "1",
    "CreationDate": "2017-07-19T14:40:57.183",
    "Score": "9",
    "ViewCount": "3745",
    "Body": "<p>In a Docker Compose file, I can easily publish a range of ports using the short-form syntax: </p>  <pre><code>ports:   - '3000-3010:3000-3010/udp' </code></pre>  <p>But in my case, I need those ports as 'mode=host' to bypass the swarm overlay network. The short-form syntax can't express that, so I need to use the long-form:</p>  <pre><code>ports:   - published: '3000-3010'     target: '3000-3010'     protocol: udp     mode: host </code></pre>  <p>However, it seems that Docker doesn't like specifying ranges with the long-form syntax, as I get that error when deploying a stack: </p>  <blockquote>   <p>services.test.ports.0.target must be a integer</p> </blockquote>  <p>Is there a way to do that (except brute-force by specifying each and every port in the range as long-form) ?</p> ",
    "OwnerUserId": "8332359",
    "LastActivityDate": "2018-02-02T00:09:46.267",
    "Title": "How to publish a range of ports with 'mode=host' with a Docker Compose file?",
    "Tags": "<docker><docker-compose><docker-swarm>",
    "AnswerCount": "1",
    "CommentCount": "2",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "45306484",
    "PostTypeId": "1",
    "CreationDate": "2017-07-25T14:37:06.180",
    "Score": "9",
    "ViewCount": "11333",
    "Body": "<p>I'm trying to deploy a very simple Symfony application using nginx &amp; php-fpm via Docker.</p>  <p>Two docker services :<br> 1. web : running nginx<br> 2. php : running php-fpm; containing application source.</p>  <p>I want to build images that can be deployed without any external dependency. That's why I'm copying source code within the <strong>php container</strong>.<br> On development process; i'm overriding <strong>/var/www/html</strong> volume with local path.</p>  <pre><code># file: php-fpm/Dockerfile FROM php:7.1-fpm-alpine  COPY ./vendor /var/www/html COPY . /var/www/html  VOLUME /var/www/html </code></pre>  <p>Now the docker-compose configuration file.</p>  <pre><code># file : docker-compose-prod.yml version: '2' services:   web:     image: 'private/web'     ports:       - 80:80     volumes_from:       - php   php:     image: 'private/php'     ports:       - 9000:9000 </code></pre>  <p>The problem is about permissions.<br> When accessing localhost, Symfony is botting up, but <strong>cache</strong> / <strong>logs</strong> / <strong>sessions</strong> folders are not writable.</p>  <ol> <li>nginx is using <strong>/var/www/html</strong> to serve static files.  </li> <li>php-fpm is using <strong>/var/www/html</strong> to execute php files.</li> </ol>  <p>I'm not sure about the problem.  But how can I be sure about the following:</p>  <ol> <li><strong>/var/www/html</strong> have to be readable for nginx ?  </li> <li><strong>/var/www/html</strong> have to be writable for php-fpm ?  </li> </ol>  <p>Note: I'm building images from MacbookPro; <strong>cache / logs / sessions</strong> are 777.</p> ",
    "OwnerUserId": "1642991",
    "LastActivityDate": "2020-01-28T23:42:26.393",
    "Title": "How to deal with permissions using docker - nginx / php-fpm",
    "Tags": "<php><symfony><nginx><docker><docker-compose>",
    "AnswerCount": "3",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "45381623",
    "PostTypeId": "1",
    "AcceptedAnswerId": "45381801",
    "CreationDate": "2017-07-28T20:07:23.690",
    "Score": "9",
    "ViewCount": "14438",
    "Body": "<p>I have this <code>docker-compose.yml</code> file</p>  <pre><code>version: '3'  volumes:   jenkins_home:  services:    registry:      image: registry:2      ports:        - '5000:5000'    jenkins:     image: jenkins/jenkins     ports:       - '9090:8080'     volumes:       - jenkins_home:/var/jenkins_home </code></pre>  <p>As you can see, there is a named volume called <code>jenkins_home</code>, now I wonder, where does the data get really persisted?</p>  <p>running <code>docker inspect infra_jenkins</code> i got this:</p>  <pre><code> ...  'Mounts': [     {       'Type': 'volume',       'Source': 'infra_jenkins_home',       'Target': '/var/jenkins_home',       'VolumeOptions': {       'Labels': {       'com.docker.stack.namespace': 'infra'               }           }       } ], ... </code></pre>  <p>I am running those services on a local docker swarm cluster using <code>docker stack deploy</code> command, the cluster is composed of three VirtualBox instances.</p> ",
    "OwnerUserId": "2429966",
    "LastActivityDate": "2018-08-31T12:38:21.610",
    "Title": "Where docker named volumes are stored?",
    "Tags": "<docker><docker-compose><dockerfile>",
    "AnswerCount": "1",
    "CommentCount": "0",
    "ClosedDate": "2017-07-30T07:21:20.573",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "45412799",
    "PostTypeId": "1",
    "AcceptedAnswerId": "45420160",
    "CreationDate": "2017-07-31T10:00:41.980",
    "Score": "9",
    "ViewCount": "22561",
    "Body": "<p>My docker-compose have a two  service, and docker-compose.yml define enviroment variable  ip address with container name,</p>  <pre><code> version: '2'  services:   api:     build: ./api/     command: python3 manage.py runserver     volumes:       - ./api:/code     ports:       - '8000:80'     networks:       - dock_net     container_name: con_api    web:     build: ./web/     command: python3 manage.py runserver     volumes:       - ./web:/code     ports:       - '8001:80'     networks:       - dock_net     container_name: con_web     environment:         Ip:con_ip  networks:   dock_net:       driver: bridge </code></pre>  <p>But variable see 'con_ip' not 127.0.0.3</p> ",
    "OwnerUserId": "8392832",
    "LastActivityDate": "2017-07-31T17:34:35.167",
    "Title": "Docker-Compose container ip address with container name",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "4",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "45658144",
    "PostTypeId": "1",
    "AcceptedAnswerId": "45658385",
    "CreationDate": "2017-08-13T07:32:21.063",
    "Score": "9",
    "ViewCount": "14187",
    "Body": "<p>I have an application using Flask and MySQL. The application does not connect to MySQL container from the Flask Application but it can be accessed using Sequel Pro with the same credentials.</p>  <p><strong>Docker Compose File</strong></p>  <pre><code>version: '2'  services:   web:     build: flask-app     ports:      - '5000:5000'     volumes:      - .:/code   mysql:     build: mysql-server     environment:       MYSQL_DATABASE: test       MYSQL_ROOT_PASSWORD: root       MYSQL_ROOT_HOST: 0.0.0.0       MYSQL_USER: testing       MYSQL_PASSWORD: testing     ports:       - '3306:3306' </code></pre>  <p><strong>Docker file for MySQL</strong></p>  <p>The docker file for MySQL will add schema from <code>test.dump</code> file.</p>  <pre><code>FROM mysql/mysql-server ADD test.sql  /docker-entrypoint-initdb.d </code></pre>  <p><strong>Docker file for Flask</strong></p>  <pre><code>FROM python:latest COPY . /app WORKDIR /app RUN pip install -r requirements.txt ENTRYPOINT ['python'] CMD ['app.py'] </code></pre>  <p><strong>Starting point <code>app.py</code></strong></p>  <pre><code>from flask import Flask, request, jsonify, Response import json import mysql.connector from flask_cors import CORS, cross_origin  app = Flask(__name__)  def getMysqlConnection():     return mysql.connector.connect(user='testing', host='0.0.0.0', port='3306', password='testing', database='test')  @app.route('/') def hello():     return 'Flask inside Docker!!'  @app.route('/api/getMonths', methods=['GET']) @cross_origin() # allow all origins all methods. def get_months():     db = getMysqlConnection()     print(db)     try:         sqlstr = 'SELECT * from retail_table'         print(sqlstr)         cur = db.cursor()         cur.execute(sqlstr)         output_json = cur.fetchall()     except Exception as e:         print('Error in SQL:\\n', e)     finally:         db.close()     return jsonify(results=output_json)  if __name__ == '__main__':     app.run(debug=True,host='0.0.0.0') </code></pre>  <p>When I do a GET request on <code>http://localhost:5000/</code> using REST Client I get a valid response. </p>  <p>A GET request on <code>http://localhost:5000/api/getMonths</code> gives error message:</p>  <pre><code>mysql.connector.errors.InterfaceError: 2003: Can't connect to MySQL server on '0.0.0.0:3306' (111 Connection refused) </code></pre>  <p>When the same credentials were used on Sequel Pro, I was able to access the database. <a href='https://i.stack.imgur.com/LdPon.png' rel='noreferrer'><img src='https://i.stack.imgur.com/LdPon.png' alt='enter image description here'></a></p>  <p>Please advice me on  how to connect the MySQL container from the Flask Application. This is my first time suing Docker and do forgive me if this is a silly mistake from my part.</p> ",
    "OwnerUserId": "5165377",
    "LastActivityDate": "2020-03-19T08:05:29.803",
    "Title": "Connecting to MySQL from Flask Application using docker-compose",
    "Tags": "<docker><docker-compose><mysql-python>",
    "AnswerCount": "2",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "45711618",
    "PostTypeId": "1",
    "AcceptedAnswerId": "45713363",
    "CreationDate": "2017-08-16T10:52:54.577",
    "Score": "9",
    "ViewCount": "10616",
    "Body": "<p>I am trying to setup mysql to run in a docker container. I have a simple docker compose file :-</p>  <pre><code>db:   image: mysql:latest   ports:     - '3306:3306'   environment:     - MYSQL_RANDOM_ROOT_PASSWORD=yes </code></pre>  <p>when i run the docker-compose file, I get the following warning in docker logs instead of the random generated password.</p>  <blockquote>   <p>[Warning] root@localhost is created with an empty password ! Please   consider switching off the --initialize-insecure option.</p> </blockquote>  <p>Is there something I am missing?</p> ",
    "OwnerUserId": "7877397",
    "LastActivityDate": "2020-12-03T22:54:30.453",
    "Title": "Docker-compose mysql does not seem to recognize environment variable MYSQL_RANDOM_ROOT_PASSWORD",
    "Tags": "<mysql><docker><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "45889233",
    "PostTypeId": "1",
    "CreationDate": "2017-08-25T20:50:08.943",
    "Score": "9",
    "ViewCount": "8528",
    "Body": "<p>I have an existing app that uses a app config file that looks like:</p>  <pre><code>'ConnectionInfo': {     'ServerName': 'The Server URL',     'DatabaseName': 'The DatabaseName',     'UserName': 'The User Name',     'Password': 'The Password'} </code></pre>  <p>Now, when I have a simple setting, say</p>  <pre><code>'ConnectionString':'My Connection String' </code></pre>  <p>I understand how to override it in the compose.yml file:</p>  <pre><code>environment:   - ConnectionString=what I want it to be </code></pre>  <p>The question is, how do you set, say, the server name in the top?</p> ",
    "OwnerUserId": "4130724",
    "LastEditorUserId": "382838",
    "LastEditDate": "2017-12-08T19:00:03.380",
    "LastActivityDate": "2020-02-25T08:52:21.750",
    "Title": "Docker Compose Nested Environment Variable",
    "Tags": "<docker><asp.net-core><environment-variables><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "5",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "46007682",
    "PostTypeId": "1",
    "AcceptedAnswerId": "46007759",
    "CreationDate": "2017-09-01T20:37:36.663",
    "Score": "9",
    "ViewCount": "10627",
    "Body": "<p>What is an appropriate way to integration test systems that use ASB?  With something like Kafka and using docker-compose, I could spin up two services that will communicate asynchronously over Kafka.  Is there a way to do something similar with ASB?  If not, what is a common integration testing pattern?</p> ",
    "OwnerUserId": "2410065",
    "LastActivityDate": "2020-07-15T06:45:37.357",
    "Title": "Integration testing Azure Service Bus with Docker",
    "Tags": "<azure><docker-compose><integration-testing><azureservicebus>",
    "AnswerCount": "3",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "46174297",
    "PostTypeId": "1",
    "CreationDate": "2017-09-12T10:41:32.107",
    "Score": "9",
    "ViewCount": "8008",
    "Body": "<p>I'm trying to run a small docker-compose app inside a container-optimized Google Cloud Compute Engine node, but I'm getting stuck when it's trying to mount volumes during a <code>docker-compose up</code>:</p>  <pre><code>Creating lightning_redis_1 ...  Creating lightning_db_1 ...  Creating lightning_redis_1 Creating lightning_db_1 ... done Creating lightning_api_1 ...  Creating lightning_api_1 ... error ERROR: for lightning_api_1  Cannot start service api: error while creating mount source path '/rootfs/home/jeremy/lightning': mkdir /rootfs: read-only file sys tem ERROR: for api  Cannot start service api: error while creating mount source path '/rootfs/home/jeremy/lightning': mkdir /rootfs: read-only file system Encountered errors while bringing up the project. jeremy@instance-1 ~/lightning $  </code></pre>  <p>My docker-compose.yml file looks like this:</p>  <pre><code>version: '3' services:   client:     build: ./client     volumes:       - ./client:/usr/src/app     ports:       - '4200:4200'       - '9876:9876'     links:       - api     command: bash -c 'yarn --pure-lockfile &amp;&amp; yarn start'   sidekiq:     build: .     command: bundle exec sidekiq     volumes:       - .:/api     depends_on:       - db       - redis       - api   redis:     image: redis     ports:       - '6379:6379'   db:     image: postgres     ports:       - '5433:5432'   api:     build: .     command: bash -c 'rm -f tmp/pids/server.pid &amp;&amp; bundle exec rails s -p 3000 -b '0.0.0.0''     volumes:       - .:/myapp     ports:       - '3000:3000'     depends_on:       - db </code></pre>  <p>I don't want to have to change anything in the docker-compose.yml file - I'd prefer to be able to fix this issue by running commands inside the VM itself, or in how I set the VM up. Reason being is it's not my code and I can't change the docker-compose.yml file easily, and all I need to do is run it for a short period of time and execute a few docker-compose commands inside the VM.</p> ",
    "OwnerUserId": "4382519",
    "LastActivityDate": "2020-05-06T19:07:01.223",
    "Title": "Running docker-compose inside a Google Cloud Engine",
    "Tags": "<docker-compose><google-compute-engine>",
    "AnswerCount": "2",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "46239662",
    "PostTypeId": "1",
    "AcceptedAnswerId": "46239994",
    "CreationDate": "2017-09-15T12:31:12.953",
    "Score": "9",
    "ViewCount": "8945",
    "Body": "<p>I'm unable to get the Docker Compose <a href='https://docs.docker.com/compose/compose-file/#domainname-hostname-ipc-mac_address-privileged-read_only-shm_size-stdin_open-tty-user-working_dir' rel='noreferrer'><code>hostname</code></a> command to work. </p>  <p>I'm running a simple <code>docker-compose.yml</code>:</p>  <pre><code>version: '3' services:   redis1:     image: 'redis:alpine'     hostname: redis1host   redis2:     image: 'redis:alpine'     hostname: redis2host </code></pre>  <p>Once I run this with <code>docker-compose up</code>, I should be able to run <code>docker-compose exec redis1 /bin/ash</code> and then <code>ping redis2host</code> to talk to the other Redis container, but the ping just doesn't reach its destination. I can ping the other Redis container with <code>ping redis2</code>.</p>  <p><code>ping redishost2</code> should work, no?</p> ",
    "OwnerUserId": "729819",
    "LastEditorUserId": "147356",
    "LastEditDate": "2017-09-15T12:41:12.227",
    "LastActivityDate": "2017-09-15T12:48:56.520",
    "Title": "Docker Compose hostname command not working",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "46536361",
    "PostTypeId": "1",
    "CreationDate": "2017-10-03T02:29:28.987",
    "Score": "9",
    "ViewCount": "15023",
    "Body": "<p>I'm using Docker Toolbox on Windows 10</p>  <p>I can access the php part succesfully via <a href='http://192.168.99.100:8000' rel='noreferrer'>http://192.168.99.100:8000</a>, I have been working around with the mariadb part but still having several problems</p>  <p>I have an sql file as <code>/mariadb/initdb/abc.sql</code> so I should be copied into <code>/docker-entrypoint-initdb.d</code>, after the container is created I use <code>docker-compose exec mariadb</code> to access the container, there is the file as <code>/docker-entrypoint-initdb.d/abc.sql</code> but the file never get executed, I also have tested to import the sql file to the container manually, it was succesful so the sql file is valid</p>  <p>I don't quite understand about the data folder mapping, and what to do to get the folder sync with the container, I always get the warning when recreate the container using <code>docker-compose up -d</code></p>  <p><code>WARNING: Service 'mariadb' is using volume '/var/lib/mysql' from the previous container. Host mapping '/.../mariadb/data' has no effect. Remove the existing containers (with docker-compose rm mariadb) to use the Recreating db ... done</code></p>  <p><strong>Questions</strong></p>  <ol> <li>How to get the sql file in <code>/docker-entrypoint-initdb.d</code> to be executed ?</li> <li>What is the right way to map the data folder with the mariadb container ?</li> </ol>  <p>Please guide Thanks</p>  <p>This is my <code>docker-compose.yml</code></p>  <pre><code>version: '3.2' services:     php:         image: php:7.1-apache         container_name: web         restart: always         volumes:             - /.../php:/var/www/html         ports:             - '8000:80'     mariadb:         image: mariadb:latest         container_name: db         restart: always         environment:             - MYSQL_ROOT_PASSWORD=12345         volumes:             - /.../mariadb/initdb:/docker-entrypoint-initdb.d             - /.../mariadb/data:/var/lib/mysql         ports:             - '3306:3306' </code></pre> ",
    "OwnerUserId": "1536973",
    "LastActivityDate": "2020-05-25T11:38:15.090",
    "Title": "File in docker-entrypoint-initdb.d never get executed when using docker compose",
    "Tags": "<docker><docker-compose><docker-machine>",
    "AnswerCount": "2",
    "CommentCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "47067944",
    "PostTypeId": "1",
    "AcceptedAnswerId": "47068162",
    "CreationDate": "2017-11-02T05:05:06.100",
    "Score": "9",
    "ViewCount": "20864",
    "Body": "<p>I hosted Git daemon on local host i.e. <code>'/usr/bin/git daemon --listen=127.0.0.1 --base-path=/opt'</code> as a <code>systemd</code> service and I am trying to access it from docker container. I didn't mentioned the port because I don't want to expose the port to outside network.</p>  <p>Dockerfile:</p>  <pre><code>RUN git clone git://127.0.0.1/repo/ repo_dir </code></pre>  <p>But its not working, its looks like inside container its trying to connect localhost of container.</p>  <p>So How to connect connect localhost of Host machine from Docker container?</p> ",
    "OwnerUserId": "2670520",
    "LastEditorUserId": "6309",
    "LastEditDate": "2017-11-02T05:25:57.780",
    "LastActivityDate": "2020-06-02T08:32:50.423",
    "Title": "How to access the Host's machine's localhost 127.0.0.1 from docker container",
    "Tags": "<docker><docker-compose><dockerfile><git-daemon>",
    "AnswerCount": "1",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "47187879",
    "PostTypeId": "1",
    "CreationDate": "2017-11-08T19:16:09.587",
    "Score": "9",
    "ViewCount": "1576",
    "Body": "<p>I have a docker-compose file like:</p>  <pre><code>services:   dns-server:     # ...   other:     image: ubuntu     dns: dns-server </code></pre>  <p>Is there any way to make the <code>other</code> container use <code>dns-server</code> as its DNS server without hardcoding the IP of that container? Using the container name doesn't give me an error but it doesn't seem to work.</p> ",
    "OwnerUserId": "115563",
    "LastActivityDate": "2017-11-08T19:16:09.587",
    "Title": "docker-compose use other container as DNS",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "0",
    "CommentCount": "1",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "47247952",
    "PostTypeId": "1",
    "AcceptedAnswerId": "47485123",
    "CreationDate": "2017-11-12T10:56:19.650",
    "Score": "9",
    "ViewCount": "34980",
    "Body": "<p>I'm on ubuntu 16.04. I have a (testing) docker (docker-compose) container running php 5.6 and apache 2.4.</p>  <p>On the production platform (without docker) the mail is sent with sendmail.</p>  <p>How to send test email on docker container (with sendmail)?</p>  <p>Thanks in advance for responses.</p> ",
    "OwnerUserId": "1768583",
    "LastEditorUserId": "1496974",
    "LastEditDate": "2020-01-06T17:00:46.990",
    "LastActivityDate": "2020-09-20T10:35:43.377",
    "Title": "Send email on testing docker container with php and sendmail",
    "Tags": "<php><docker><docker-compose><sendmail><php-5.6>",
    "AnswerCount": "2",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "47292669",
    "PostTypeId": "1",
    "CreationDate": "2017-11-14T18:14:37.283",
    "Score": "9",
    "ViewCount": "18224",
    "Body": "<p>I have problem with memcached in docker-compose. This is docker-compose.yml: </p>  <pre><code>nginx:     container_name: nginx     image: nginx:latest     ports:         - 127.0.0.2:8000:80     volumes:         - ./htdocs:/htdocs         - ./nginx.conf:/etc/nginx/conf.d/nginx.conf     links:         - php php:     container_name: php     build: ./php     volumes:         - ./htdocs:/htdocs         - ./php/php.ini:/usr/local/etc/php/php.ini       links:         - mysql         - memcached mysql:     container_name: mysql     image: mysql:latest     ports:         - 127.0.0.2:8001:3306     volumes:         - ./my.cnf:/etc/mysql/my.cnf         - ./db:/var/lib/mysql     environment:         - MYSQL_ROOT_PASSWORD=root         - MYSQL_DATABASE=db         - MYSQL_USER=root         - MYSQL_PASSWORD=root memcached:     container_name: memcached     image: memcached:latest     ports:         - '11211:11211' </code></pre>  <p>and this is my php code: </p>  <pre><code>error_reporting(E_ALL &amp; ~E_NOTICE);  $memcached = new Memcached;   $memcached-&gt;addServer('0.0.0.0', 11211);  echo '&lt;pre&gt;'; print_r($memcached-&gt;getServerList()); echo '&lt;/pre&gt;';  if($memcached-&gt;getStats() === false) {     echo 'returned false'; } else {     echo '&lt;pre&gt;'; print_r($memcached-&gt;getStats()); echo '&lt;/pre&gt;'; } </code></pre>  <p>and result is:</p>  <pre><code>Array (      [0] =&gt; Array         (             [host] =&gt; 0.0.0.0             [port] =&gt; 11211             [type] =&gt; TCP         ) )  returned false </code></pre>  <p>Why memcached cant see server? (getStats returned nothing) Command 'docker ps' return list where it`s running docker memcached:lastest as port '0.0.0.0:11211->11211/tcp'. Sorry  for my english. </p> ",
    "OwnerUserId": "4042608",
    "LastActivityDate": "2019-03-11T12:52:23.433",
    "Title": "memcached not working in docker-compose",
    "Tags": "<php><docker-compose><memcached>",
    "AnswerCount": "1",
    "CommentCount": "3",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "47454597",
    "PostTypeId": "1",
    "AcceptedAnswerId": "52201432",
    "CreationDate": "2017-11-23T11:36:39.237",
    "Score": "9",
    "ViewCount": "6130",
    "Body": "<p>My postgres <code>yaml</code> part looking like this:</p>  <pre><code>postgres:     container_name: 'postgres'     image: postgres:10.1     environment:       - POSTGRES_USER=postgres       - POSTGRES_PASSWORD=root       - POSTGRES_DB=myids     ports:       - '5432:5432'     networks:       - app-network </code></pre>  <p>Then when I am logging in with that credentials using HeidiSQL I cant see my database: <a href='https://i.stack.imgur.com/q4vlu.png' rel='noreferrer'><img src='https://i.stack.imgur.com/q4vlu.png' alt='enter image description here'></a></p>  <p>Any ideas?</p>  <p>Update thanks to this answer I managed to find my database <a href='https://dba.stackexchange.com/a/1304'>https://dba.stackexchange.com/a/1304</a> using this select:</p>  <pre><code>SELECT datname FROM pg_database WHERE datistemplate = false; </code></pre>  <p>Now the question why HeidiSQL won't show that?</p> ",
    "OwnerUserId": "2926340",
    "LastActivityDate": "2022-11-08T14:46:05.577",
    "Title": "HeidiSQL won't list my database",
    "Tags": "<postgresql><docker><docker-compose><heidisql>",
    "AnswerCount": "2",
    "CommentCount": "2",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "47784863",
    "PostTypeId": "1",
    "AcceptedAnswerId": "47795951",
    "CreationDate": "2017-12-13T03:00:47.480",
    "Score": "9",
    "ViewCount": "4395",
    "Body": "<p>I would like to create a named volume for one of my containers.</p>  <p>This container will need a lot more storage than other containers I run, so I would like to store that particular volume on a different disk that has lots of free space.</p>  <p>I still want the other volumes on the default disk, only that one named volume should go on another disk.</p>  <p>I don't want to use a bind mount because it will make backing up and migrating more complicated.</p>  <p>The only option I can think of is to manually move the volume after it is created (while the container is stopped), and create a symlink from its original location in <code>/var/lib/docker/...</code> to the new location on the other hard drive. This is very manual though, which leads me to think there must be a better way.</p>  <p>What is the recommended way of achieving this?</p> ",
    "OwnerUserId": "2774883",
    "LastActivityDate": "2017-12-13T14:52:39.483",
    "Title": "How to store a specific named docker volume at a specific location without changing the default?",
    "Tags": "<docker><docker-compose><docker-volume>",
    "AnswerCount": "1",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "47981240",
    "PostTypeId": "1",
    "AcceptedAnswerId": "47981910",
    "CreationDate": "2017-12-26T16:31:24.263",
    "Score": "9",
    "ViewCount": "11532",
    "Body": "<p>I have a super simple Node app and an Nginx config which acts as a reverse proxy to the Node app. Everything works fine if I run Nginx (via homebrew) and the Node app locally. If I visit the server defined by the Nginx config at port 8080 I get the output from the node app, which is running on port 3000. </p>  <p>I've been trying to convert this simple setup to use Docker and have written the following Docker-compose file: </p>  <pre><code>version: '3.0' services:   web:     build: .     ports:       - 3000:3000   nginx:     build:       context: .       dockerfile: Dockerfile.nginx     ports:       - 8080:8080 </code></pre>  <p>On running <code>docker-compose up</code> the images are built and there are no error messages in the console. On visiting <code>localhost:3000</code> I get the response from the Node app but on visiting <code>localhost:8080</code> I get an an Nginx 502 error page and the following error in the terminal:</p>  <blockquote>   <p>connect() failed (111: Connection refused) while connecting to   upstream, client: 172.18.0.1, server: localhost, request: 'GET /   HTTP/1.1', upstream: '<a href='http://127.0.0.1:3000/' rel='noreferrer'>http://127.0.0.1:3000/</a>', host: 'localhost:8080'</p> </blockquote>  <p>My Dockerfile for the node app looks like so:</p>  <pre><code>FROM node:carbon  WORKDIR /app  ADD . /app  RUN npm install  CMD ['node', '.']  EXPOSE 3000 </code></pre>  <p>and the Dockerfile.nginx looks like so:</p>  <pre><code>FROM nginx COPY nginx.conf /etc/nginx/nginx.conf </code></pre>  <p>and the nginx.conf looks like so:</p>  <pre><code>events {   worker_connections  1024; }  http {    upstream node_app {     server 127.0.0.1:3000;   }    server_tokens off;    # Define the MIME types for files.   include       mime.types;   default_type  application/octet-stream;    # Speed up file transfers by using sendfile()   # TODO: Read up on this   sendfile on;    server {     listen 8080;     server_name localhost;      location / {       proxy_pass http://node_app;       proxy_http_version 1.1;       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;       proxy_set_header Host $http_host;       proxy_set_header X-Real-IP $remote_addr;     }   } } </code></pre>  <p>On starting Docker up I can see that Nginx is running on port 8080 (because I see the 502 Nginx page) and I can see that the node app is running (because I can visit it at localhost:3000). I can't work out why I get the 502 from nginx.</p>  <p>I've tried using various different things like using <code>links</code> to link the containers and <code>depends_on</code> but nothing seems to make any difference. I'm also using <code>docker-compose up --build</code> to make sure I'm not caching previous builds each time I make a change.</p>  <p>EDIT: Something that seems to make it work is to add a container_name property in to the docker-compose:</p>  <pre><code>  web:     container_name: nodeapp     build:       context: .       dockerfile: Dockerfile.node     ports:       - 3000:3000 </code></pre>  <p>and then using that container name in the upstream node_app config in nginx.conf: </p>  <pre><code>  upstream node_app {     server nodeapp:3000;   } </code></pre>  <p>which makes no sense to me?!</p> ",
    "OwnerUserId": "392572",
    "LastEditorUserId": "392572",
    "LastEditDate": "2017-12-26T16:59:04.680",
    "LastActivityDate": "2017-12-26T17:45:43.160",
    "Title": "Nginx can't find upstream node app when running via Docker-compose",
    "Tags": "<node.js><docker><nginx><docker-compose>",
    "AnswerCount": "1",
    "CommentCount": "2",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "47993571",
    "PostTypeId": "1",
    "AcceptedAnswerId": "47993836",
    "CreationDate": "2017-12-27T14:06:34.893",
    "Score": "9",
    "ViewCount": "14633",
    "Body": "<p>I am trying to run a site using multiple container configuration - one for apache, second for mysql and third for myadmin. Everything starts fine, setup runs smooth but when I try to run a PHP application I get <code>mysqli::__construct(): (HY000/2002): Connection refused in system/libraries/drivers/Database/Mysqli.php [54]</code> error.</p>  <p>It seems that there's something wrong with the connection settings but I checked the site through PHP MyAdmin running on separate container and copied the db host IP from there just to be sure. How can I/should I connect from PHP container to MySQL db?</p>  <p>Here's my <code>docker-compose.yml</code> file:</p>  <pre><code>version: '3' services:   web:     build:       context: ./etc/php       args:          - APP_HOST=${APP_HOST}          - MYSQL_USER=${MYSQL_USER}          - MYSQL_PASSWORD=${MYSQL_PASSWORD}          - MYSQL_PORT=${MYSQL_PORT}          - MYSQL_DATABASE=${MYSQL_DATABASE}     ports:       - ${APP_PORT}:80       - ${APP_PORT_SSL}:443     volumes:       - ./var/bin/:/tmp/bin/       - ./app/:/var/www/html/       - ./log/apache2/:/var/log/apache2/       - ./etc/php/conf/:/usr/local/etc/php/conf.d/     environment:       - VIRTUAL_HOST=${VIRTUAL_HOST}   db:     build:       context: ./etc/mysql       args:         - MYSQL_DATABASE=${MYSQL_DATABASE}         - MYSQL_USER=${MYSQL_USER}         - MYSQL_PASSWORD=${MYSQL_PASSWORD}         - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}         - DUMP_FILE=${DUMP_FILE}     volumes:       - ./etc/mysql/conf:/etc/mysql/conf/conf.d       - ./data:/var/lib/mysql       - ./log/:/var/log/     ports:       - '${MYSQL_PORT}:3306'   phpmyadmin:     image: phpmyadmin/phpmyadmin     environment:       MYSQL_ROOT_PASSWORD: root     ports:       - ${MYADMIN_PORT}:80     environment:       - VIRTUAL_HOST=phpmyadmin.localhost </code></pre>  <p>And the <code>.env</code> with variables:</p>  <pre><code>VIRTUAL_HOST=foo.local  APP_PORT=80 APP_PORT_SSL=443 MYADMIN_PORT=8081  APP_HOST=foo.local ADMIN_APP_HOST=admin-foo.local  MYSQL_DATABASE=foo_local MYSQL_USER=root MYSQL_HOST=172.26.0.2 MYSQL_PASSWORD=root MYSQL_ROOT_PASSWORD=root MYSQL_PORT=3306 </code></pre>  <p>Oh, and here's the code I try to run:</p>  <pre><code> $this-&gt;link = $socket ? new mysqli(null, $user, $pass, $database, $port, $socket) : new mysqli($host, $user, $pass, $database, $port); </code></pre>  <p>Output of <code>echo $host.'&lt;br&gt;'.$user.'&lt;br&gt;'.$pass.'&lt;br&gt;'.$database.'&lt;br&gt;'.$port.'&lt;br&gt;'.$socket;</code> is following:</p>  <pre><code>172.26.0.2 root root hq_local 3306 </code></pre> ",
    "OwnerUserId": "401499",
    "LastEditorUserId": "401499",
    "LastEditDate": "2017-12-27T14:12:12.483",
    "LastActivityDate": "2021-11-23T22:37:02.090",
    "Title": "Docker PHP MySQL connection refused",
    "Tags": "<php><mysql><docker><mysqli><docker-compose>",
    "AnswerCount": "5",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "48015477",
    "PostTypeId": "1",
    "AcceptedAnswerId": "48042583",
    "CreationDate": "2017-12-28T23:04:50.807",
    "Score": "9",
    "ViewCount": "15747",
    "Body": "<p>I am trying to setup separate docker containers for rabbitmq and the consumer for the container, i.e., the process that would listen on the queue and perform the necessary tasks.  I created the yml file, and the docker file.  </p>  <p>I am able to run the yml file, however when I check the docker-compose logs I see where there are ECONNREFUSED errors.  </p>  <p><strong>NewUserNotification.js:</strong></p>  <pre><code>require('seneca')()     .use('seneca-amqp-transport')     .add('action:new_user_notification\u2019, function(message, done) {         \u2026           return done(null, {         pid: process.pid,         status: `Process ${process.pid} status: OK`     })     .listen({         type: 'amqp',         pin: ['action:new_user_notification\u2019],         name: 'seneca.new_user_notification.queue',         url: process.env.AMQP_RECEIVE_URL,         timeout: 99999     }); </code></pre>  <p><strong>error message in docker-compose log:</strong></p>  <pre><code>    {'notice':'seneca: Action hook:listen,role:transport,type:amqp failed: connect ECONNREFUSED 127.0.0.1:5672.','code':     'act_execute','err':{'cause':{'errno':'ECONNREFUSED','code':'ECONNREFUSED','syscall':'connect','address':'127.0.0.1',     'port':5672},'isOperational':true,'errno':'ECONNREFUSED','code':'act_execute','syscall':'connect','address':'127.0.0.1',     'port':5672,'eraro':true,'orig':{'cause':{'errno':'ECONNREFUSED','code':'ECONNREFUSED','syscall':'connect','address':'127.0.0.1',     'port':5672},'isOperational':true,'errno':'ECONNREFUSED','code':'ECONNREFUSED','syscall':'connect','address':'127.0.0.1','port':5672},     'seneca':true,'package':'seneca','msg':'seneca: Action hook:listen,role:transport,type:amqp failed: connect ECONNREFUSED 127.0.0.1:5672.',     'details':{'message':'connect ECONNREFUSED 127.0.0.1:5672','pattern':'hook:listen,role:transport,type:amqp','instance':'Seneca/\u2026\u2026\u2026\u2026/\u2026\u2026\u2026\u2026/1/3.4.3/-\u201c,     \u201dorig$':{'cause':{'errno':'ECONNREFUSED','code':'ECONNREFUSED','syscall':'connect','address':'127.0.0.1','port':5672},'isOperational':true, 'errno':'ECONNREFUSED','code':'ECONNREFUSED','syscall':'connect','address':'127.0.0.1','port':5672} </code></pre>  <p><strong>sample docker-compose.yml file:</strong></p>  <pre><code>version: '2.1' services:  rabbitmq:     container_name: '4340_rabbitmq'     tty: true     image: rabbitmq:management     ports:       - 15672:15672       - 15671:15671       - 5672:5672     volumes:       - /rabbitmq/lib:/var/lib/rabbitmq       - /rabbitmq/log:/var/log/rabbitmq       - /rabbitmq/conf:/etc/rabbitmq/ account:     container_name: 'account'     build:       context: .       dockerfile: ./Account/Dockerfile     ports:       - 3000:3000     links:       - 'mongo'       - 'rabbitmq'     depends_on:       - 'mongo'       - 'rabbitmq' new_user_notification:     container_name: 'app_new_user_notification'     build:       context: .       dockerfile: ./Account/dev.newusernotification.Dockerfile     links:       - 'mongo'       - 'rabbitmq'     depends_on:       - 'mongo'       - 'rabbitmq'     command: ['./wait-for-it.sh', 'rabbitmq:5672', '-t', '90', '--', 'node', \u201cnewusernotification.js'] </code></pre>  <p><strong>amqp connection string:</strong>  (I tried both ways, with and without a user/pass) amqp://username:password@rabbitmq:5672</p>  <p>I added the link attribute to the docker-compose file and referenced the name in the .env file(rabbitmq).  I tried to run the NewUserNotification.js file from outside the container and it started fine.  What could be causing this problem?  Connection string issue?  Docker-Compose.yml configuration issue?  Other?</p> ",
    "OwnerUserId": "1790300",
    "LastActivityDate": "2018-01-01T14:47:43.430",
    "Title": "Docker and Rabbitmq: ECONNREFUSED between containers",
    "Tags": "<node.js><docker><docker-compose><seneca>",
    "AnswerCount": "2",
    "CommentCount": "6",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "48111049",
    "PostTypeId": "1",
    "AcceptedAnswerId": "48131399",
    "CreationDate": "2018-01-05T09:52:51.203",
    "Score": "9",
    "ViewCount": "15258",
    "Body": "<p>Using <code>docker stack deploy</code>, I can see the following message:</p>  <pre><code>Ignoring unsupported options: restart </code></pre>  <ul> <li>Does it mean that restart policies are not in place? </li> <li>Do they have to be specified outside the compose file?</li> </ul>  <p>You can see this message for example with the  <a href='https://hub.docker.com/_/joomla/' rel='noreferrer'>Joomla compose file available at the bottom of that page</a>. To start the compose file:</p>  <pre><code>sudo docker swarm init sudo docker stack deploy -c stackjoomla.yml joomla </code></pre> ",
    "OwnerUserId": "2641825",
    "LastActivityDate": "2021-03-23T07:58:29.227",
    "Title": "Does the Docker message: 'Ignoring unsupported options: restart' mean the restart policy is ignored?",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "2",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "48277003",
    "PostTypeId": "1",
    "CreationDate": "2018-01-16T08:34:34.977",
    "Score": "9",
    "ViewCount": "2080",
    "Body": "<p>From the count of questions tagged with <code>docker</code> i assume StackOverflow is the right place to ask (instead of e.g. <a href='https://devops.stackexchange.com/questions/tagged/docker'>DevOps</a>), if not, please point me to the right place or move this question accordingly.</p>  <p>My scenario is the following:</p>  <ul> <li>multiple applications consisting of frontend (web GUI) and backend (REST services) are being developed following <a href='https://en.wikipedia.org/wiki/Service-oriented_architecture' rel='noreferrer'>SOA</a>/microservice approaches, each application has its own git repository</li> <li>some applications require a shared additional resource like frontend needs a HTTP server and multiple backend applications need a database server (with persistent storage)</li> <li>focus is primarily on offline mobile development (on the road) so a quick setup of required services/applications should be possible and the amount of resource overhead should be minimal. But of course the whole thing will be deployed/published at some point so i dont want to obstruct that if both can be managed</li> <li>development is done on windows and linux host machines</li> <li>access to all services from host machine is required for development purposes</li> </ul>  <p>What i am trying to achieve is to have a <code>docker-compose.yaml</code> file in the application repositories which i invoke via <code>docker-compose up</code> which would then start all required containers <a href='https://stackoverflow.com/q/44731451'>if not running already</a>, e.g. the database container is started when i invoke <code>docker-compose up</code> in a backend application repository.</p>  <p>My approach was to have a new git repository which defines all shared docker images/containers, with its own <code>docker-compose.yaml</code> where all devs would have to run <code>docker-compose build</code> whenever something changed (might be automated with a git commit hook in the future). The central <code>docker-compose.yaml</code> looks like this</p>  <pre><code>version: '3' services:    postgres:     build: ./images/postgres     image: MY-postgres     container_name: MY-postgres-server     ports:       - '5432:5432'    httpd:     build: ./images/httpd     image: MY-httpd     container_name: MY-httpd-server     ports:       - '80:80' </code></pre>  <p>The <code>Dockerfile</code> describing how each image is built is in its own subfolder and i think not relevant for the question, basically the default images for alpine + apache/postgres.</p>  <p>So the problem: how would a <code>docker-compose.yaml</code> in the application git repository look like that references the services/containers defined by the above central <code>docker-compose.yaml</code>.</p>  <p>Now since this <a href='https://stackoverflow.com/q/45915182/875020'>is</a> <a href='https://stackoverflow.com/q/35597579/875020'>no</a> <a href='https://stackoverflow.com/q/43384538/875020'>new</a> <a href='https://stackoverflow.com/q/43426699/875020'>problem</a> <a href='https://stackoverflow.com/q/35113957/875020'>scenario</a>, i did some research and honestly the variety of approaches and proposed solutions was confusing, for once the <a href='https://stackoverflow.com/a/41013048/875020'>various versions</a> and compatibilities, features that were deprecated, etc.</p>  <ul> <li>We want one single database instance for now for performance reasons and simplicity (<a href='https://www.reddit.com/r/docker/comments/4rkq24/when_you_run_a_database_server_from_docker_do_you/' rel='noreferrer'>reddit</a>) or is this the problem because it is truly <a href='http://microservices.io/patterns/data/shared-database.html' rel='noreferrer'>considered an anti-pattern</a> (via <a href='https://stackoverflow.com/a/41884241/875020'>this answer</a>). Each application would be using its own database within the container, so no sync required on application level.</li> <li>I am reading about <a href='https://stackoverflow.com/a/35598804/875020'>volumes</a> or <a href='https://github.com/docker/compose/issues/942' rel='noreferrer'>data only</a> <a href='https://stackoverflow.com/a/35414699/875020'>containers</a> to solve this problem, yet i cant understand how to implement</li> <li><a href='https://forums.docker.com/t/single-db-instance-with-multiple-apps/40106/9' rel='noreferrer'>Some</a> (Single Host scenario) suggest <a href='https://docs.docker.com/compose/networking/#links' rel='noreferrer'>links</a> (with <a href='https://github.com/docker/compose/issues/942' rel='noreferrer'><code>depends_on</code></a>) while i think this concept has been superseeded by <a href='https://docs.docker.com/compose/compose-file/#networks' rel='noreferrer'>networks</a> but is it still applying? There <a href='https://stackoverflow.com/a/33034919/875020'>seemed to be</a> an <a href='https://stackoverflow.com/a/35414699/875020'><code>extends</code></a> <a href='https://stackoverflow.com/a/33408244/875020'>option</a> as well</li> <li><code>docker-compose</code> has an option <code>--no-deps</code> which is described as <code>Don't start linked services.</code>. If i omit it, i would assume it does what i need, but here i think then problem is the difference in meaning of <a href='https://stackoverflow.com/q/35565770'>image/container/service</a></li> <li>Can a combination of <a href='https://docs.docker.com/compose/extends/#multiple-compose-files' rel='noreferrer'>multiple compose files</a> solve this problem? This would add a hard requirement on <a href='https://github.com/docker/compose/issues/1647' rel='noreferrer'>project paths</a> though</li> <li>If i cant start the containers from my application directory, id like to at least link to them, is <a href='https://github.com/docker/compose/issues/942' rel='noreferrer'><code>external_links</code></a> the <a href='https://blog.virtualzone.de/2016/09/docker-compose-link-containers-outside-compose-file-using-external_links.html' rel='noreferrer'>right</a> <a href='https://github.com/docker/compose/issues/3813#issuecomment-237549950' rel='noreferrer'>approach</a>?</li> <li>There are some feature requests (<a href='https://github.com/docker/compose/issues/318' rel='noreferrer'>feature: including external docker-compose.yml</a>, <a href='https://github.com/docker/compose/issues/2075' rel='noreferrer'>allow sharing containers across services</a>) so maybe its just not possible currently with docker means? Then how to solve it with third-party like <a href='https://github.com/dnephin/compose-addons#dcao-include' rel='noreferrer'>dcao include</a> (which doesnt support <code>version 3</code>)?</li> </ul>  <p>Wow, that escalated quickly. But i wanted to show the research i have done since i just cant believe that its currently not possible. </p> ",
    "OwnerUserId": "875020",
    "LastEditorUserId": "875020",
    "LastEditDate": "2018-01-18T04:46:25.147",
    "LastActivityDate": "2018-01-18T04:46:25.147",
    "Title": "Use shared database docker container in microservice architecture",
    "Tags": "<linux><windows><docker><docker-compose><development-environment>",
    "AnswerCount": "0",
    "CommentCount": "2",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "48557607",
    "PostTypeId": "1",
    "AcceptedAnswerId": "48558712",
    "CreationDate": "2018-02-01T07:39:50.803",
    "Score": "9",
    "ViewCount": "8040",
    "Body": "<p>I got the code from two branches with following config:</p>  <p>docker-compose.yml:</p>  <pre><code>version: '3' services:   server:     build: .     restart: always     image: XXXXX     entrypoint: ['./run.sh']     container_name: XXXX     ports:       - 127.0.0.1:8000:8000     volumes:       - .:/app      depends_on:       - redis   redis:     container_name: XXXXX     image: redis:4-alpine </code></pre>  <p>When I docker compose first branch, it works well, but when I compose up the second branch, the original container become the new branch container, which I want the two branches containers exist at the same time. </p>  <p>When I compose up the second branch code, the following message shows:</p>  <pre><code>Recreating XXXXX_branch2 ... done Attaching to XXXXX_branch1 </code></pre> ",
    "OwnerUserId": "8780179",
    "LastEditorUserId": "8780179",
    "LastEditDate": "2018-02-01T07:53:23.273",
    "LastActivityDate": "2018-02-01T09:08:46.667",
    "Title": "Docker compose up keep replace existing container",
    "Tags": "<docker><docker-compose><dockerfile>",
    "AnswerCount": "1",
    "CommentCount": "3",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "48711455",
    "PostTypeId": "1",
    "AcceptedAnswerId": "48712414",
    "CreationDate": "2018-02-09T17:47:54.860",
    "Score": "9",
    "ViewCount": "11477",
    "Body": "<p>I'm trying to index a containerized Elasticsearch db using the Python client <a href='https://github.com/elastic/elasticsearch-py' rel='nofollow noreferrer'>https://github.com/elastic/elasticsearch-py</a> called from a script (running in a container too).</p> <p>By looking at existing pieces of code, it seems that <code>docker-compose</code> is a useful tool to use for my purpose. My dir structure is</p> <pre><code>docker-compose.yml indexer/ - Dockerfile - indexer.py - requirements.txt elasticsearch/ - Dockerfile </code></pre> <p>My <code>docker-compose.yml</code> reads</p> <pre class='lang-yaml prettyprint-override'><code>version: '3'  services:   elasticsearch:     build: elasticsearch/     ports:        - 9200:9200     networks:       - deploy_network     container_name: elasticsearch    indexer:     build: indexer/     depends_on:       - elasticsearch     networks:       - deploy_network     container_name: indexer    networks:   deploy_network:     driver: bridge </code></pre> <p><code>indexer.py</code> reads</p> <pre class='lang-py prettyprint-override'><code>from elasticsearch import Elasticsearch from elasticsearch.helpers import bulk      es = Elasticsearch(hosts=[{&quot;host&quot;:'elasticsearch'}]) # what should I put here?  actions = [     {     '_index' : 'test',     '_type' : 'content',     '_id' : str(item['id']),     '_source' : item,     } for item in [{'id': 1, 'foo': 'bar'}, {'id': 2, 'foo': 'spam'}] ]      # create index print(&quot;Indexing Elasticsearch db... (please hold on)&quot;) bulk(es, actions) print(&quot;...done indexing :-)&quot;) </code></pre> <p>The Dockerfile for the elasticsearch service is</p> <pre><code>FROM docker.elastic.co/elasticsearch/elasticsearch-oss:6.1.3 EXPOSE 9200 EXPOSE 9300 </code></pre> <p>and that for the indexer is</p> <pre><code>FROM python:3.6-slim WORKDIR /app ADD . /app RUN pip install -r requirements.txt ENTRYPOINT [ &quot;python&quot; ] CMD [ &quot;indexer.py&quot; ] </code></pre> <p>with <code>requirements.txt</code> containing only <code>elasticsearch</code> to be downloaded with pip.</p> <p>Running with <code>docker-compose run indexer</code> gives me the error message at <a href='https://pastebin.com/6U8maxGX' rel='nofollow noreferrer'>https://pastebin.com/6U8maxGX</a> (<code>ConnectionRefusedError: [Errno 111] Connection refused</code>). elasticsearch is up as far as I can see with <code>curl -XGET 'http://localhost:9200/' </code>or by running <code>docker ps -a</code>.</p> <p>How can I modify my <code>docker-compose.yml</code> or <code>indexer.py</code> to solve the problem?</p> <p>P.S. A (working) version (informed by the answers below) of the code can be found here, for completeness' sake: <a href='https://github.com/davidefiocco/dockerized-elasticsearch-indexer' rel='nofollow noreferrer'>https://github.com/davidefiocco/dockerized-elasticsearch-indexer</a>.</p> ",
    "OwnerUserId": "4240413",
    "LastEditorUserId": "4240413",
    "LastEditDate": "2021-10-07T07:29:15.167",
    "LastActivityDate": "2021-10-07T07:29:15.167",
    "Title": "How do I create a (dockerized) Elasticsearch index using a python script running in a docker container?",
    "Tags": "<python><docker><elasticsearch><docker-compose><elasticsearch-py>",
    "AnswerCount": "3",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 4.0"
  },
  {
    "Id": "48777109",
    "PostTypeId": "1",
    "AcceptedAnswerId": "48778576",
    "CreationDate": "2018-02-13T23:02:56.107",
    "Score": "9",
    "ViewCount": "2808",
    "Body": "<p>I have two projects and I need two differents docker environnement (containers). I have two <code>docker-compose.yml</code> files in two different projects. <code>foo</code> project and <code>bar</code> project.</p>  <p><code>foo/src/website/docker-compose.yml</code> #1 (<code>foo</code>)</p>  <pre class='lang-yaml prettyprint-override'><code>version: '3' services:   db:     env_file: .env     image: mariadb:10.0.23     container_name: foo-db     ports:       - '42333:3306'     restart: always   web:     image: project/foo     container_name: foo-web     env_file: .env     build: .     restart: always     command: bash -c 'rm -f tmp/pids/server.pid &amp;&amp; bundle exec rails server -p 3000 -b '0.0.0.0''     volumes:       - .:/webapps/foo     ports:       - '3000:3000'     depends_on:       - db </code></pre>  <p><code>bar/src/website/docker-compose.yml</code> #2 (<code>bar</code>)</p>  <pre class='lang-yaml prettyprint-override'><code>version: '3' services:   db:     image: mysql:5.5.50     container_name: bar-db     ports:       - '42333:3306'     env_file: .env     restart: always   web:     image: project/bar     container_name: bar-web     env_file: .env     build: .     restart: always     command: bash -c 'rm -f tmp/pids/server.pid &amp;&amp; bundle exec rails server -p 3000 -b '0.0.0.0''     volumes:       - .:/webapps/bar     ports:       - '3000:3000'     depends_on:       - db </code></pre>  <p>I do this command for my <code>foo</code> project <code>docker-compose build</code> and <code>docker-compose up</code>, everything works. In Kitematic I see my two containers with the good names (<code>foo-web</code>). </p>  <ol> <li>I do this command to stop my image <code>docker-compose stop</code>. </li> <li>I go to my second project (<code>bar</code>) and run <code>docker-compose build</code> and <code>docker-compose up</code>. everything works, but my container name in now replaced by <code>bar-web</code>. </li> <li>I stop my second image with <code>docker-compose stop</code> and I try to perform <code>docker-compose up</code> in my <code>foo</code> project folder again but it fails.</li> </ol>  <p><strong>How can I keep two different containers and easily switch from one to the other with <code>docker-compose stop</code> and <code>docker-compose up</code>?</strong></p>  <h2>Edit 1</h2>  <p>I found the issue, the main folder where my <code>docker-compose.yml</code> are located for my two projects have the same folder name. Can I fix this or I need to rename my folders?</p> ",
    "OwnerUserId": "979201",
    "LastEditorUserId": "1092815",
    "LastEditDate": "2018-02-22T20:24:53.017",
    "LastActivityDate": "2018-02-22T20:24:53.017",
    "Title": "docker-compose containers uses wrong container with multiple projects",
    "Tags": "<docker><docker-compose>",
    "AnswerCount": "3",
    "CommentCount": "0",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  },
  {
    "Id": "48873652",
    "PostTypeId": "1",
    "AcceptedAnswerId": "48873922",
    "CreationDate": "2018-02-19T20:25:13.440",
    "Score": "9",
    "ViewCount": "7178",
    "Body": "<p>In the Docker Compose documentation, <a href='https://docs.docker.com/compose/compose-file/#long-syntax-3' rel='noreferrer'>here</a>, you have the following example related to the <code>volumes</code> section of <code>docker-compose.yml</code> files:</p>  <pre><code>volumes:   # (1) Just specify a path and let the Engine create a volume   - /var/lib/mysql    # (2) Specify an absolute path mapping   - /opt/data:/var/lib/mysql    # (3) Path on the host, relative to the Compose file   - ./cache:/tmp/cache    # (4) User-relative path   - ~/configs:/etc/configs/:ro    # (5) Named volume   - datavolume:/var/lib/mysql </code></pre>  <p>Which syntaxes produce a <em>bind mount</em> and which produce a <em>docker volume</em>? At some place of the documentation, the two concepts are strictly differentiated but at this place they are mixed together... so it is not clear to me. </p> ",
    "OwnerUserId": "2095024",
    "LastActivityDate": "2018-11-21T14:13:09.890",
    "Title": "Docker Compose: Which syntax produces a bind mount, which produces a volume",
    "Tags": "<docker><syntax><docker-compose><volumes>",
    "AnswerCount": "2",
    "CommentCount": "1",
    "FavoriteCount": "0",
    "ContentLicense": "CC BY-SA 3.0"
  }
]