{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 entries in file ../data/results/config2/all_dependencies_all_gpt-3.5-turbo-0125.json.\n",
      "Index(['dependency_category', 'link_str', 'project', 'option_name',\n",
      "       'option_value', 'option_type', 'option_file', 'option_technology',\n",
      "       'dependent_option_name', 'dependent_option_value',\n",
      "       'dependent_option_type', 'dependent_option_file',\n",
      "       'dependent_option_technology', 'config_type', 'rating', 'final_rating',\n",
      "       'final_category', 'sub_category', 'explanation', 'response_rating',\n",
      "       'classification', 'plan', 'rationale', 'uncertainty', 'context_length',\n",
      "       'source_types'],\n",
      "      dtype='object')\n",
      "Skipped 0 entries in file ../data/results/config2/all_dependencies_all_gpt-4o-2024-05-13.json.\n",
      "Index(['dependency_category', 'link_str', 'project', 'option_name',\n",
      "       'option_value', 'option_type', 'option_file', 'option_technology',\n",
      "       'dependent_option_name', 'dependent_option_value',\n",
      "       'dependent_option_type', 'dependent_option_file',\n",
      "       'dependent_option_technology', 'config_type', 'rating', 'final_rating',\n",
      "       'final_category', 'sub_category', 'explanation', 'response_rating',\n",
      "       'classification', 'plan', 'rationale', 'uncertainty', 'context_length',\n",
      "       'source_types'],\n",
      "      dtype='object')\n",
      "Skipped 92 entries in file ../data/results/config2/all_dependencies_all_llama3:8b.json.\n",
      "Index(['dependency_category', 'link_str', 'project', 'option_name',\n",
      "       'option_value', 'option_type', 'option_file', 'option_technology',\n",
      "       'dependent_option_name', 'dependent_option_value',\n",
      "       'dependent_option_type', 'dependent_option_file',\n",
      "       'dependent_option_technology', 'config_type', 'rating', 'final_rating',\n",
      "       'final_category', 'sub_category', 'explanation', 'response_rating',\n",
      "       'classification', 'plan', 'rationale', 'uncertainty', 'context_length',\n",
      "       'source_types'],\n",
      "      dtype='object')\n",
      "Skipped 0 entries in file ../data/results/config2/all_dependencies_all_llama3:70b.json.\n",
      "Index(['dependency_category', 'link_str', 'project', 'option_name',\n",
      "       'option_value', 'option_type', 'option_file', 'option_technology',\n",
      "       'dependent_option_name', 'dependent_option_value',\n",
      "       'dependent_option_type', 'dependent_option_file',\n",
      "       'dependent_option_technology', 'config_type', 'rating', 'final_rating',\n",
      "       'final_category', 'sub_category', 'explanation', 'response_rating',\n",
      "       'classification', 'plan', 'rationale', 'uncertainty', 'context_length',\n",
      "       'source_types'],\n",
      "      dtype='object')\n",
      "Skipped 3 entries in file ../data/results/config2/all_dependencies_all_llama3.1:8b.json.\n",
      "Index(['dependency_category', 'link_str', 'project', 'option_name',\n",
      "       'option_value', 'option_type', 'option_file', 'option_technology',\n",
      "       'dependent_option_name', 'dependent_option_value',\n",
      "       'dependent_option_type', 'dependent_option_file',\n",
      "       'dependent_option_technology', 'config_type', 'rating', 'final_rating',\n",
      "       'final_category', 'sub_category', 'explanation', 'response_rating',\n",
      "       'classification', 'plan', 'rationale', 'uncertainty', 'context_length',\n",
      "       'source_types'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Dict\n",
    "import tiktoken\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def get_context_length(entry: Dict, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(entry[\"context_str\"]))\n",
    "    return num_tokens\n",
    "\n",
    "\n",
    "def get_source_types(entry: Dict) -> List[str]:\n",
    "    context = entry[\"context\"]\n",
    "    source_types = [x[\"index\"] for x in context]\n",
    "    return source_types\n",
    "\n",
    "\n",
    "def get_df_stats(model_name: str, config_str: str):\n",
    "\n",
    "    data_file = f\"../data/results/{config_str}/all_dependencies_all_{model_name}.json\"\n",
    "    baseline_file = \"../data/results/all_dependencies.csv\"\n",
    "\n",
    "    with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "        data = json.load(src)\n",
    "\n",
    "    df = pd.read_csv(baseline_file)\n",
    "\n",
    "    response_rating = []\n",
    "    classification = []\n",
    "    rationale = []\n",
    "    plan = []\n",
    "    uncertainty = []\n",
    "    context_length = []\n",
    "    source_types = []\n",
    "    skipped = 0\n",
    "    \n",
    "    for entry, (index, row) in zip(data, df.iterrows()):\n",
    "\n",
    "        assert entry[\"index\"] == index\n",
    "        \n",
    "        response_dict = None\n",
    "        isDependency = None\n",
    "\n",
    "        context_length.append(get_context_length(entry=entry))\n",
    "        source_types.append(get_source_types(entry=entry))\n",
    "\n",
    "        try:\n",
    "            if \"responses\" in entry:\n",
    "                response = entry[\"responses\"][0]\n",
    "            else:\n",
    "                response = entry[\"response\"]\n",
    "            response_dict = json.loads(response, strict=False)\n",
    "            isDependency = response_dict[\"isDependency\"]\n",
    "            plan_str = response_dict[\"plan\"]\n",
    "            rationale_str = response_dict[\"rationale\"]\n",
    "            uncertainty_str = response_dict[\"uncertainty\"]\n",
    "        except (json.JSONDecodeError, KeyError):\n",
    "            response_rating.append(\"None\")\n",
    "            classification.append(\"None\")\n",
    "            plan.append(\"None\")\n",
    "            rationale.append(\"None\")\n",
    "            uncertainty.append(\"None\")\n",
    "            skipped += 1\n",
    "            continue\n",
    "\n",
    "        rating = row[\"final_rating\"]\n",
    "        \n",
    "        if str(rating).lower() == \"borderline\":\n",
    "            if isDependency:\n",
    "                response_rating.append(str(isDependency))\n",
    "                classification.append(\"TP\")\n",
    "                plan.append(plan_str)\n",
    "                rationale.append(rationale_str)\n",
    "                uncertainty.append(uncertainty_str)\n",
    "            if not isDependency:\n",
    "                response_rating.append(str(isDependency))\n",
    "                classification.append(\"TN\")\n",
    "                plan.append(plan_str)\n",
    "                rationale.append(rationale_str)\n",
    "                uncertainty.append(uncertainty_str)\n",
    "\n",
    "        # FP: The LLM validates a dependency as correct, but the dependency is actually incorrect\n",
    "        if isDependency and str(rating).lower() == \"false\":\n",
    "            response_rating.append(str(isDependency))\n",
    "            classification.append(\"FP\")\n",
    "            plan.append(plan_str)\n",
    "            rationale.append(rationale_str)\n",
    "            uncertainty.append(uncertainty_str)\n",
    "\n",
    "\n",
    "        # FN: The LLM validates a dependency as incorrect, but the dependency is actually correct\n",
    "        if not isDependency and  str(rating).lower() == \"true\":\n",
    "            response_rating.append(str(isDependency))\n",
    "            classification.append(\"FN\")\n",
    "            plan.append(plan_str)\n",
    "            rationale.append(rationale_str)\n",
    "            uncertainty.append(uncertainty_str)\n",
    "\n",
    "        # TP: The LLM validates a dependency as correct and the dependency is correct\n",
    "        if isDependency and str(rating).lower() == \"true\":\n",
    "            response_rating.append(str(isDependency))\n",
    "            classification.append(\"TP\")\n",
    "            plan.append(plan_str)\n",
    "            rationale.append(rationale_str)\n",
    "            uncertainty.append(uncertainty_str)\n",
    "\n",
    "        # TN: The LLM validates a dependency as incorrect and the dependency is incorrect\n",
    "        if not isDependency and str(rating).lower() == \"false\":\n",
    "            response_rating.append(str(isDependency))\n",
    "            classification.append(\"TN\")\n",
    "            plan.append(plan_str)\n",
    "            rationale.append(rationale_str)\n",
    "            uncertainty.append(uncertainty_str)\n",
    "\n",
    "\n",
    "    print(f\"Skipped {skipped} entries in file {data_file}.\")\n",
    "    df[f\"response_rating\"] = response_rating\n",
    "    df[\"classification\"] = classification\n",
    "    df[\"plan\"] = plan\n",
    "    df[\"rationale\"] = rationale\n",
    "    df[\"uncertainty\"] = uncertainty\n",
    "    df[\"context_length\"] = context_length\n",
    "    df[\"source_types\"] = source_types\n",
    "\n",
    "    return df\n",
    "\n",
    "model_names = [\"gpt-3.5-turbo-0125\", \"gpt-4o-2024-05-13\", \"llama3:8b\", \"llama3:70b\", \"llama3.1:8b\"] # \"llama3.1:70b\"\n",
    "config_str = \"config2\"\n",
    "\n",
    "for name in model_names:\n",
    "    df = get_df_stats(model_name=name, config_str=config_str)\n",
    "    print(df.columns)\n",
    "    df.to_csv(f\"../data/analysis/{config_str}/{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_names = ['gpt-4o-2024-05-13', 'gpt-3.5-turbo-0125', 'llama3:70b', 'llama3:8b', 'llama3.1:8b'] # 'llama3.1:70b'\n",
    "\n",
    "df_base = pd.read_csv(\"../data/results/all_dependencies.csv\")\n",
    "\n",
    "for name in model_names:\n",
    "    file_name = f\"../data/analysis/{config_str}/{name}.csv\"\n",
    "    df_model = pd.read_csv(file_name)\n",
    "\n",
    "    classification = df_model[\"classification\"].to_list()\n",
    "\n",
    "    df_base[f\"{name}_classification\"] = classification\n",
    "\n",
    "\n",
    "df_base.to_csv(f\"../data/analysis/{config_str}/all.csv\", index=False)\n",
    "\n",
    "print(len(df_base))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      4\u001b[0m model_columns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-4o-2024-05-13_classification\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpt-3.5-turbo-0125_classification\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama3:70b_classification\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama3:8b_classification\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m failure_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel_names\u001b[49m:\n\u001b[1;32m     10\u001b[0m     file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../data/analysis/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m     df_model \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(file_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_names' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model_columns = ['gpt-4o-2024-05-13_classification', 'gpt-3.5-turbo-0125_classification', 'llama3:70b_classification', 'llama3:8b_classification']\n",
    "\n",
    "failure_ids = set()\n",
    "\n",
    "\n",
    "for name in model_names:\n",
    "    file_name = f\"../data/analysis/{config_str}/{name}.csv\"\n",
    "    df_model = pd.read_csv(file_name)\n",
    "\n",
    "    for index, row in df_model.iterrows():\n",
    "        if row[\"classification\"] == \"FP\" or row[\"classification\"] == \"FN\":\n",
    "            failure_ids.add(index)\n",
    "\n",
    "\n",
    "df_failures = df_base.iloc[list(failure_ids)]\n",
    "df_failures['FP_FN_count'] = df_failures[model_columns].apply(lambda row: row.isin(['FP', 'FN']).sum(), axis=1)\n",
    "\n",
    "print(len(df_failures))\n",
    "\n",
    "df_failures.to_csv(f\"../data/analysis/{config_str}/failures.csv\", index=False)\n",
    "\n",
    "\n",
    "categories = df_failures[\"final_category\"].to_list()\n",
    "sub_categories = df_failures[\"sub_category\"].to_list()\n",
    "\n",
    "category_counter = Counter(categories)\n",
    "sub_category_counter = Counter(sub_categories)\n",
    "\n",
    "print(category_counter)\n",
    "print(sub_category_counter)\n",
    "\n",
    "plt.figure(figsize=(25, 5)) \n",
    "plt.bar(category_counter.keys(), category_counter.values())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"../data/analysis/{config_str}/all.csv\")\n",
    "\n",
    "# List of model columns to check\n",
    "model_columns = ['gpt-4o-2024-05-13_classification', 'gpt-3.5-turbo-0125_classification', 'llama3:70b_classification', 'llama3:8b_classification'] # 'llama3.1:70b_classification'\n",
    "\n",
    "# Create a boolean mask where True indicates the presence of 'FP' or 'FN' in any of the specified model columns\n",
    "#mask = df[model_columns].apply(lambda x: x.isin(['FP', 'FN']), axis=1).any(axis=1)\n",
    "\n",
    "# Filter the dataframe using the mask\n",
    "#filtered_df_all = df[mask]\n",
    "\n",
    "df['FP_FN_count'] = df[model_columns].apply(lambda row: row.isin(['FP', 'FN']).sum(), axis=1)\n",
    "df['TP_TN_count'] = df[model_columns].apply(lambda row: row.isin(['TP', 'TN']).sum(), axis=1)\n",
    "\n",
    "#sorted_df_all =  filtered_df_all.sort_values(by='FP_FN_count', ascending=False)\n",
    "\n",
    "# Save the filtered dataframe if needed\n",
    "df.to_csv(f'../data/analysis/{config_str}/all.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "Failure counter:  Counter({1: 132, 0: 113, 2: 110, 3: 81, 4: 51, 5: 13})\n",
      "Success counter:  Counter({4: 130, 3: 118, 2: 100, 5: 82, 1: 57, 0: 13})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "df_all = pd.read_csv(f'../data/analysis/{config_str}/all.csv')\n",
    "\n",
    "failure_count = df_all[\"FP_FN_count\"].to_list()\n",
    "success_count = df_all[\"TP_TN_count\"].to_list()\n",
    "\n",
    "failure_counter = Counter(failure_count)\n",
    "success_counter = Counter(success_count)\n",
    "\n",
    "print(len(df_all))\n",
    "\n",
    "print(\"Failure counter: \", failure_counter)\n",
    "print(\"Success counter: \", success_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check if failure are identical across RAG variants**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt-4o-2024-05-13_classification\n",
      "gpt-4o-2024-05-13_classification\n",
      "TN    267\n",
      "TP    117\n",
      "FN     86\n",
      "FP     30\n",
      "Name: count, dtype: int64\n",
      "500\n",
      "gpt-3.5-turbo-0125_classification\n",
      "gpt-3.5-turbo-0125_classification\n",
      "TN    160\n",
      "TP    160\n",
      "FP    137\n",
      "FN     43\n",
      "Name: count, dtype: int64\n",
      "500\n",
      "llama3:70b_classification\n",
      "llama3:70b_classification\n",
      "TN    193\n",
      "TP    159\n",
      "FP    104\n",
      "FN     44\n",
      "Name: count, dtype: int64\n",
      "500\n",
      "llama3:8b_classification\n",
      "llama3:8b_classification\n",
      "FP    170\n",
      "TP    160\n",
      "TN     63\n",
      "FN     15\n",
      "Name: count, dtype: int64\n",
      "408\n",
      "llama3.1:8b_classification\n",
      "llama3.1:8b_classification\n",
      "FP    172\n",
      "TP    140\n",
      "TN    122\n",
      "FN     63\n",
      "Name: count, dtype: int64\n",
      "497\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(f\"../data/analysis/{config_str}/all.csv\")\n",
    "\n",
    "# List of model columns to check\n",
    "model_columns = ['gpt-4o-2024-05-13_classification', 'gpt-3.5-turbo-0125_classification', 'llama3:70b_classification', 'llama3:8b_classification', 'llama3.1:8b_classification'] # 'llama3.1:70b_classification'\n",
    "\n",
    "for column in model_columns:\n",
    "    rating_counts = df[column].value_counts()\n",
    "\n",
    "    print(column)\n",
    "    print(rating_counts)\n",
    "    print(sum(k for k in rating_counts.to_dict().values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'multi-maven-modules': 146,\n",
       "         'libraries': 115,\n",
       "         'boolean': 57,\n",
       "         'others': 48,\n",
       "         'version numbers': 44,\n",
       "         'generic names': 29,\n",
       "         'independent components': 20,\n",
       "         'datasource': 19,\n",
       "         'port': 16,\n",
       "         'integers': 6})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "baseline_file = \"../data/results/all_dependencies.csv\"\n",
    "\n",
    "df = pd.read_csv(baseline_file)\n",
    "\n",
    "categories = df[\"final_category\"].to_list()\n",
    "\n",
    "categories = [x.lower() for x in categories]\n",
    "\n",
    "category_counter = Counter(categories)\n",
    "\n",
    "category_counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  gpt-4o-2024-05-13\n",
      "            category_name  TP  TN FP  FN\n",
      "0         version numbers   8  11  8  17\n",
      "1                 boolean   -  56  1   -\n",
      "2     multi-maven-modules  74  25  5  42\n",
      "3                  others   8  36  3   1\n",
      "4               libraries  22  67  5  21\n",
      "5                    port   4   5  6   1\n",
      "6           generic names   -  27  2   -\n",
      "7              datasource   1  14  -   4\n",
      "8  independent components   -  20  -   -\n",
      "9                integers   -   6  -   -\n",
      "Model:  gpt-3.5-turbo-0125\n",
      "            category_name  TP  TN  FP  FN\n",
      "0         version numbers  22   4  15   3\n",
      "1                 boolean   -  54   3   -\n",
      "2     multi-maven-modules  85   8  22  31\n",
      "3                  others   7  23  16   2\n",
      "4               libraries  39  34  38   4\n",
      "5                    port   4   3   8   1\n",
      "6           generic names   -  21   8   -\n",
      "7              datasource   3   7   7   2\n",
      "8  independent components   -   3  17   -\n",
      "9                integers   -   3   3   -\n",
      "Model:  llama3:70b\n",
      "            category_name  TP  TN  FP  FN\n",
      "0         version numbers   8   1  18  17\n",
      "1                 boolean   -  57   -   -\n",
      "2     multi-maven-modules  98  12  18  18\n",
      "3                  others   7  28  11   2\n",
      "4               libraries  36  42  30   7\n",
      "5                    port   5   5   6   -\n",
      "6           generic names   -  22   7   -\n",
      "7              datasource   5   7   7   -\n",
      "8  independent components   -  14   6   -\n",
      "9                integers   -   5   1   -\n",
      "Model:  llama3:8b\n",
      "            category_name  TP  TN  FP  FN\n",
      "0         version numbers  16   1  17   5\n",
      "1                 boolean   -  27  18   -\n",
      "2     multi-maven-modules  88   6  18  10\n",
      "3                  others   7   5  24   -\n",
      "4               libraries  41   9  54   -\n",
      "5                    port   5   1   8   -\n",
      "6           generic names   -   6  12   -\n",
      "7              datasource   3   2   6   -\n",
      "8  independent components   -   6  10   -\n",
      "9                integers   -   -   3   -\n",
      "Model:  llama3.1:8b\n",
      "            category_name  TP  TN  FP  FN\n",
      "0         version numbers  13   6  13  12\n",
      "1                 boolean   -  42  14   -\n",
      "2     multi-maven-modules  82   8  22  34\n",
      "3                  others   7  15  22   2\n",
      "4               libraries  31  22  50  12\n",
      "5                    port   4   1  10   1\n",
      "6           generic names   -  12  17   -\n",
      "7              datasource   3   6   8   2\n",
      "8  independent components   -   6  14   -\n",
      "9                integers   -   4   2   -\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "\n",
    "def get_category_stats(category_names: List, model_name: str):\n",
    "\n",
    "    file_name = f\"../data/analysis/{config_str}/{model_name}.csv\"\n",
    "    df = pd.read_csv(file_name)\n",
    "\n",
    "    tp = []\n",
    "    fp = []\n",
    "    tn = []\n",
    "    fn = []\n",
    "\n",
    "    for category_name in category_names:\n",
    "\n",
    "        df_category = df[df['final_category'].str.lower() == str(category_name)]\n",
    "\n",
    "        #print(df_category[\"classification\"].unique())\n",
    "\n",
    "        rating_counts = df_category['classification'].value_counts().to_dict()\n",
    "\n",
    "        #print(type(rating_counts))\n",
    "        #print(df_category)\n",
    "        #print(rating_counts)\n",
    "\n",
    "        tp.append(rating_counts[\"TP\"] if \"TP\" in rating_counts else \"-\")\n",
    "        tn.append(rating_counts[\"TN\"] if \"TN\" in rating_counts else \"-\" )\n",
    "        fp.append(rating_counts[\"FP\"] if \"FP\" in rating_counts else \"-\")\n",
    "        fn.append(rating_counts[\"FN\"] if \"FN\" in rating_counts else \"-\")\n",
    "\n",
    "    \n",
    "    data = {\n",
    "        \"category_name\": category_names,\n",
    "        \"TP\": tp,\n",
    "        \"TN\": tn,\n",
    "        \"FP\": fp,\n",
    "        \"FN\": fn\n",
    "    }\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    print(df)\n",
    "\n",
    "    #return df\n",
    "\n",
    "\n",
    "model_names = ['gpt-4o-2024-05-13', 'gpt-3.5-turbo-0125', 'llama3:70b', 'llama3:8b', 'llama3.1:8b'] # 'llama3.1:70b'\n",
    "category_names = list(category_counter.keys())\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(\"Model: \", model_name)\n",
    "    get_category_stats(category_names=category_names, model_name=model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which technologies are involved in dependencies that are incorrectly validated?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  gpt-4o-2024-05-13\n",
      "Technologies Failures:  Counter({'maven': 99, 'docker-compose': 9, 'spring': 7, 'nodejs': 1})\n",
      "Model:  gpt-3.5-turbo-0125\n",
      "Technologies Failures:  Counter({'maven': 115, 'spring': 25, 'docker-compose': 19, 'docker': 12, 'nodejs': 8, 'tsconfig': 1})\n",
      "Model:  llama3:70b\n",
      "Technologies Failures:  Counter({'maven': 106, 'spring': 18, 'docker-compose': 13, 'nodejs': 8, 'docker': 3})\n",
      "Model:  llama3:8b\n",
      "Technologies Failures:  Counter({'maven': 114, 'spring': 32, 'docker-compose': 13, 'nodejs': 10, 'tsconfig': 8, 'docker': 8})\n",
      "Model:  llama3.1:8b\n",
      "Technologies Failures:  Counter({'maven': 156, 'spring': 34, 'docker-compose': 23, 'docker': 10, 'nodejs': 8, 'tsconfig': 4})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>maven</th>\n",
       "      <th>spring</th>\n",
       "      <th>docker-compose</th>\n",
       "      <th>nodejs</th>\n",
       "      <th>docker</th>\n",
       "      <th>tsconfig</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>99</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>115</td>\n",
       "      <td>25</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>106</td>\n",
       "      <td>18</td>\n",
       "      <td>13</td>\n",
       "      <td>8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>114</td>\n",
       "      <td>32</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3.1:8b</td>\n",
       "      <td>156</td>\n",
       "      <td>34</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name  maven  spring  docker-compose  nodejs  docker  tsconfig\n",
       "0   gpt-4o-2024-05-13     99       7               9       1     NaN       NaN\n",
       "1  gpt-3.5-turbo-0125    115      25              19       8    12.0       1.0\n",
       "2          llama3:70b    106      18              13       8     3.0       NaN\n",
       "3           llama3:8b    114      32              13      10     8.0       8.0\n",
       "4         llama3.1:8b    156      34              23       8    10.0       4.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "model_names = ['gpt-4o-2024-05-13', 'gpt-3.5-turbo-0125', 'llama3:70b', 'llama3:8b', 'llama3.1:8b'] # 'llama3.1:70b'\n",
    "\n",
    "data = []\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(\"Model: \", model_name)\n",
    "    file_name = f\"../data/analysis/{config_str}/{model_name}.csv\"\n",
    "    df_model = pd.read_csv(file_name)\n",
    "\n",
    "    df_failures = df_model[df_model[\"classification\"].isin([\"FP\", \"FN\"])]\n",
    "\n",
    "    technologies_failures = df_failures[\"option_technology\"].to_list() \n",
    "\n",
    "    counter = Counter(technologies_failures)\n",
    "\n",
    "    print(\"Technologies Failures: \", counter)\n",
    "\n",
    "\n",
    "    model_data = {\"model_name\": model_name}\n",
    "    model_data.update({k: v for k, v in counter.items()})\n",
    "    data.append(model_data)\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of Intra- and Cross-Technogy Failures**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  gpt-4o-2024-05-13\n",
      "Num intra-technology failures:  114\n",
      "Num cross-technology failures:  2\n",
      "Model:  gpt-3.5-turbo-0125\n",
      "Num intra-technology failures:  174\n",
      "Num cross-technology failures:  6\n",
      "Model:  llama3:70b\n",
      "Num intra-technology failures:  144\n",
      "Num cross-technology failures:  4\n",
      "Model:  llama3:8b\n",
      "Num intra-technology failures:  174\n",
      "Num cross-technology failures:  11\n",
      "Model:  llama3.1:8b\n",
      "Num intra-technology failures:  220\n",
      "Num cross-technology failures:  15\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_names = ['gpt-4o-2024-05-13', 'gpt-3.5-turbo-0125', 'llama3:70b', 'llama3:8b', 'llama3.1:8b'] # 'llama3.1:70b'\n",
    "\n",
    "\n",
    "for model_name in model_names:\n",
    "    intra = 0\n",
    "    cross = 0\n",
    "    print(\"Model: \", model_name)\n",
    "    file_name = f\"../data/analysis/{config_str}/{model_name}.csv\"\n",
    "    df_model = pd.read_csv(file_name)\n",
    "\n",
    "    df_failures = df_model[df_model[\"classification\"].isin([\"FP\", \"FN\"])]\n",
    "\n",
    "    technologies_a = df_failures[\"option_technology\"].to_list() \n",
    "    technologies_b = df_failures[\"dependent_option_technology\"].to_list() \n",
    "\n",
    "\n",
    "\n",
    "    for x, y in zip(technologies_a, technologies_b):\n",
    "        if x.lower() == y.lower():\n",
    "            intra += 1\n",
    "        else:\n",
    "            cross += 1\n",
    "    \n",
    "    print(\"Num intra-technology failures: \", intra)\n",
    "    print(\"Num cross-technology failures: \", cross)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Context length of correctly and incorrectly classified dependencies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  gpt-4o-2024-05-13\n",
      "Model:  gpt-3.5-turbo-0125\n",
      "Model:  llama3:70b\n",
      "Model:  llama3:8b\n",
      "Model:  llama3.1:8b\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>maven</th>\n",
       "      <th>spring</th>\n",
       "      <th>docker-compose</th>\n",
       "      <th>nodejs</th>\n",
       "      <th>docker</th>\n",
       "      <th>tsconfig</th>\n",
       "      <th>context_length_false</th>\n",
       "      <th>context_length_true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>99.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>115.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>106.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>114.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>llama3.1:8b</td>\n",
       "      <td>156.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt-4o-2024-05-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2301.68</td>\n",
       "      <td>2262.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt-3.5-turbo-0125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2275.27</td>\n",
       "      <td>2268.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>llama3:70b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2303.52</td>\n",
       "      <td>2255.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>llama3:8b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2257.90</td>\n",
       "      <td>2276.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>llama3.1:8b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2278.44</td>\n",
       "      <td>2264.32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name  maven  spring  docker-compose  nodejs  docker  \\\n",
       "0   gpt-4o-2024-05-13   99.0     7.0             9.0     1.0     NaN   \n",
       "1  gpt-3.5-turbo-0125  115.0    25.0            19.0     8.0    12.0   \n",
       "2          llama3:70b  106.0    18.0            13.0     8.0     3.0   \n",
       "3           llama3:8b  114.0    32.0            13.0    10.0     8.0   \n",
       "4         llama3.1:8b  156.0    34.0            23.0     8.0    10.0   \n",
       "5   gpt-4o-2024-05-13    NaN     NaN             NaN     NaN     NaN   \n",
       "6  gpt-3.5-turbo-0125    NaN     NaN             NaN     NaN     NaN   \n",
       "7          llama3:70b    NaN     NaN             NaN     NaN     NaN   \n",
       "8           llama3:8b    NaN     NaN             NaN     NaN     NaN   \n",
       "9         llama3.1:8b    NaN     NaN             NaN     NaN     NaN   \n",
       "\n",
       "   tsconfig  context_length_false  context_length_true  \n",
       "0       NaN                   NaN                  NaN  \n",
       "1       1.0                   NaN                  NaN  \n",
       "2       NaN                   NaN                  NaN  \n",
       "3       8.0                   NaN                  NaN  \n",
       "4       4.0                   NaN                  NaN  \n",
       "5       NaN               2301.68              2262.04  \n",
       "6       NaN               2275.27              2268.09  \n",
       "7       NaN               2303.52              2255.89  \n",
       "8       NaN               2257.90              2276.29  \n",
       "9       NaN               2278.44              2264.32  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "model_names = ['gpt-4o-2024-05-13', 'gpt-3.5-turbo-0125', 'llama3:70b', 'llama3:8b', 'llama3.1:8b'] # 'llama3.1:70b'\n",
    "config_str = \"config1\"\n",
    "\n",
    "\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(\"Model: \", model_name)\n",
    "    file_name = f\"../data/analysis/{config_str}/{model_name}.csv\"\n",
    "    \n",
    "    df_model = pd.read_csv(file_name)\n",
    "    df_false = df_model[df_model[\"classification\"].isin([\"FP\", \"FN\"])]\n",
    "    df_true = df_model[df_model[\"classification\"].isin([\"TP\", \"TN\"])]\n",
    "\n",
    "    context_length_false = df_false[\"context_length\"].to_list()\n",
    "    context_length_true = df_true[\"context_length\"].to_list()\n",
    "\n",
    "    context_length_false_avg = round(int(sum([x for x in context_length_false]))/len(context_length_false),2)\n",
    "    context_length_true_avg = round(int(sum([x for x in context_length_true]))/len(context_length_true),2)\n",
    "\n",
    "    data.append({\n",
    "        \"model_name\": model_name,\n",
    "        \"context_length_false\": context_length_false_avg,\n",
    "        \"context_length_true\": context_length_true_avg\n",
    "    })\n",
    "    \n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Distribution of source types**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config:  config4\n",
      "Model:  gpt-4o-2024-05-13\n",
      "Source Types Counts False: Counter({'web-search': 280, 'tech-docs': 44, 'so-posts': 14, 'github': 10})\n",
      "Source Types Distribution False: {'tech-docs': 0.12643678160919541, 'web-search': 0.8045977011494253, 'github': 0.028735632183908046, 'so-posts': 0.040229885057471264}\n",
      "Source Types Counts True: Counter({'web-search': 896, 'tech-docs': 124, 'so-posts': 114, 'github': 18})\n",
      "Source Types Distribution true: {'so-posts': 0.09895833333333333, 'web-search': 0.7777777777777778, 'tech-docs': 0.1076388888888889, 'github': 0.015625}\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "model_names = ['gpt-4o-2024-05-13', 'gpt-3.5-turbo-0125', 'llama3:70b', 'llama3:8b', 'llama3.1:8b'] # 'llama3.1:70b'\n",
    "config_str = \"config4\"\n",
    "\n",
    "\n",
    "for model_name in model_names:\n",
    "    print(\"Config: \", config_str)\n",
    "    print(\"Model: \", model_name)\n",
    "    file_name = f\"../data/analysis/{config_str}/{model_name}.csv\"\n",
    "    \n",
    "    df_model = pd.read_csv(file_name)\n",
    "    df_false = df_model[df_model[\"classification\"].isin([\"FP\", \"FN\"])]\n",
    "    df_true = df_model[df_model[\"classification\"].isin([\"TP\", \"TN\"])]\n",
    "\n",
    "    source_types_false = df_false[\"source_types\"].to_list()\n",
    "    source_types_true = df_true[\"source_types\"].to_list()\n",
    "   \n",
    "    # Convert each string representation of the list into an actual list\n",
    "    data_false = [ast.literal_eval(item) for item in source_types_false]\n",
    "    data_true = [ast.literal_eval(item) for item in source_types_true]\n",
    "\n",
    "    # Flatten the list of lists into a single list\n",
    "    flattened_list_false = [context for sublist in data_false for context in sublist]\n",
    "    flattened_list_true = [context for sublist in data_true for context in sublist]\n",
    "\n",
    "    # Count the occurrences of each context source\n",
    "    counter_false = Counter(flattened_list_false)\n",
    "    counter_true = Counter(flattened_list_true)\n",
    "\n",
    "    # Calculate the distribution\n",
    "    total_false = sum(counter_false.values())\n",
    "    distribution_false = {k: v / total_false for k, v in counter_false.items()}\n",
    "\n",
    "    total_true = sum(counter_true.values())\n",
    "    distribution_true = {k: v / total_true for k, v in counter_true.items()}\n",
    "\n",
    "\n",
    "    # Display the counts and distribution\n",
    "    print(\"Source Types Counts False:\", counter_false)\n",
    "    print(\"Source Types Distribution False:\", distribution_false)\n",
    "\n",
    "    print(\"Source Types Counts True:\", counter_true)\n",
    "    print(\"Source Types Distribution true:\", distribution_true)\n",
    "\n",
    "    break\n",
    "\n",
    "#df = pd.DataFrame(data)\n",
    "#df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
