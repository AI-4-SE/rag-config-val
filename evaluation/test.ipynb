{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "df = pd.read_csv(\"../data/results/all_dependencies_updated.csv\")\n",
    "\n",
    "df[\"final_rating\"]\n",
    "\n",
    "\n",
    "def transform_result_file(results_file: str):\n",
    "\n",
    "    parts = results_file.split(\"/\")    \n",
    "    config = parts[3]\n",
    "    llm_name = parts[-1].split(\"_\")[-1].split(\".json\")[0]\n",
    "\n",
    "\n",
    "    with open(results_file, \"r\", encoding=\"utf-8\") as src:\n",
    "        data = json.load(src)\n",
    "\n",
    "    for entry in data:\n",
    "        gt = df.iloc[entry[\"index\"]]\n",
    "\n",
    "        if \"responses\" in entry:\n",
    "            response = entry[\"responses\"][0]\n",
    "        else:\n",
    "            response = entry[\"response\"]\n",
    "        \n",
    "        try:\n",
    "           \n",
    "            response_dict = json.loads(response, strict=False)\n",
    "            entry[\"response_dict\"] = response_dict\n",
    "            entry[\"reasoning\"] = response_dict[\"rationale\"]\n",
    "            entry[\"uncertainty\"] = response_dict[\"uncertainty\"]\n",
    "    \n",
    "\n",
    "            if gt[\"final_rating\"] == response_dict[\"isDependency\"]:\n",
    "                if gt[\"final_rating\"]:\n",
    "                    entry[\"correct\"] = \"TP\"\n",
    "                else:\n",
    "                    entry[\"correct\"] = \"TN\"\n",
    "            else:\n",
    "                if gt[\"final_rating\"]:\n",
    "                    entry[\"correct\"] = \"FN\"\n",
    "                else:\n",
    "                    entry[\"correct\"] = \"FP\"\n",
    "\n",
    "        except:\n",
    "            entry[\"response_dict\"] = response\n",
    "            entry[\"reasoning\"] = None\n",
    "            entry[\"uncertainty\"] = None\n",
    "            entry[\"correct\"] = None\n",
    "\n",
    "        entry[\"final_category\"] = gt[\"final_category\"]\n",
    "        entry[\"sub_category\"] = gt[\"sub_category\"]\n",
    "        entry[\"llm\"] = llm_name\n",
    "        entry[\"config\"] = config\n",
    "\n",
    "\n",
    "    with open(results_file, \"w\", encoding=\"utf-8\") as dest:\n",
    "        json.dump(data, dest, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = \"../data/results/\"\n",
    "folder_paths = [results_path + x + \"/\" for x in os.listdir(results_path) if \".csv\" not in x]\n",
    "\n",
    "files = []\n",
    "\n",
    "for path in folder_paths:\n",
    "    for result_file in [path + x for x in os.listdir(path) if \".json\" in x]:\n",
    "        files.append(result_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/results/config4/all_dependencies_all_gpt-4o-2024-05-13.json\n",
      "../data/results/config4/all_dependencies_all_llama3:70b.json\n",
      "../data/results/config4/all_dependencies_all_gpt-3.5-turbo-0125.json\n",
      "../data/results/config4/all_dependencies_all_llama3:8b.json\n",
      "../data/results/without/all_dependencies_without_gpt-3.5-turbo-0125.json\n",
      "../data/results/without/all_dependencies_without_llama3:8b.json\n",
      "../data/results/without/all_dependencies_without_llama3:70b.json\n",
      "../data/results/without/all_dependencies_without_gpt-4o-2024-05-13.json\n",
      "../data/results/config2/all_dependencies_all_gpt-4o-2024-05-13.json\n",
      "../data/results/config2/all_dependencies_all_llama3:70b.json\n",
      "../data/results/config2/all_dependencies_all_gpt-3.5-turbo-0125.json\n",
      "../data/results/config2/all_dependencies_all_llama3:8b.json\n",
      "../data/results/config3/all_dependencies_all_gpt-4o-2024-05-13.json\n",
      "../data/results/config3/all_dependencies_all_llama3:70b.json\n",
      "../data/results/config3/all_dependencies_all_gpt-3.5-turbo-0125.json\n",
      "../data/results/config3/all_dependencies_all_llama3:8b.json\n",
      "../data/results/config1/all_dependencies_all_gpt-4o-2024-05-13.json\n",
      "../data/results/config1/all_dependencies_all_llama3:70b.json\n",
      "../data/results/config1/all_dependencies_all_gpt-3.5-turbo-0125.json\n",
      "../data/results/config1/all_dependencies_all_llama3:8b.json\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    print(file)\n",
    "    transform_result_file(results_file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    with open(file, \"r\", encoding=\"utf-8\") as src:\n",
    "        data = json.load(src)\n",
    "    \n",
    "    df = pd.concat([df, pd.DataFrame(data)], axis=0, ignore_index=True)\n",
    "\n",
    "columns = [\"llm\", \"config\", \"uncertainty\", \"correct\", \"reasoning\", \"context_str\", \"project\", \"option_name\", \"option_type\", \"option_value\",\"option_technology\", \n",
    "           \"option_file\", \"dependent_option_name\", \"dependent_option_type\", \"dependent_option_value\",\n",
    "           \"dependent_option_technology\", \"dependent_option_file\", \"final_category\", \"sub_category\"]\n",
    "\n",
    "json_df = pd.json_normalize(df[\"dependency\"])\n",
    "\n",
    "df = pd.concat([df.drop(\"dependency\", axis=1), json_df], axis=1)\n",
    "\n",
    "df = df[columns]\n",
    "df_2 = df\n",
    "df = df[df[\"correct\"].isin([\"FP\", \"FN\"])]\n",
    "\n",
    "df = df[df[\"config\"].isin([\"without\", \"config2\"])]\n",
    "\n",
    "df = df[df[\"llm\"].isin(['gpt-4o-2024-05-13', 'llama3:70b', 'llama3:8b', 'gpt-3.5-turbo-0125'])]\n",
    "\n",
    "df.to_csv(\"../data/analysis/failures.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1203"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1203.000000\n",
       "mean        7.711554\n",
       "std         1.095639\n",
       "min         2.000000\n",
       "25%         7.000000\n",
       "50%         8.000000\n",
       "75%         8.000000\n",
       "max        10.000000\n",
       "Name: uncertainty, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"uncertainty\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2678.000000\n",
       "mean        7.964899\n",
       "std         1.262176\n",
       "min         0.000000\n",
       "25%         8.000000\n",
       "50%         8.000000\n",
       "75%         9.000000\n",
       "max        10.000000\n",
       "Name: uncertainty, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "df_2 = df_2[df_2[\"correct\"].isin([\"TP\", \"TN\"])]\n",
    "df_2 = df_2[df_2[\"config\"].isin([\"without\", \"config2\"])]\n",
    "df_2 = df_2[df_2[\"llm\"].isin(['gpt-4o-2024-05-13', 'llama3:70b', 'llama3:8b', 'gpt-3.5-turbo-0125'])]\n",
    "\n",
    "df_2[\"uncertainty\"].describe()\n",
    "\n",
    "#ttest_ind(df[\"uncertainty\"], df_2[\"uncertainty\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203\n",
      "1203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([], dtype='int64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(\"../data/analysis/failures.csv\")\n",
    "\n",
    "#df = pd.read_csv(\"../data/results/all_dependencies.csv\")\n",
    "\n",
    "\n",
    "dup_columns = [\"option_value\", \"option_name\", \"option_file\", \"dependent_option_name\", \"dependent_option_value\", \"dependent_option_file\", \"llm\", \"config\"]\n",
    "\n",
    "duplicates = df[df.duplicated(subset=dup_columns)]\n",
    "\n",
    "#for index, row in duplicates.iterrows():\n",
    "#    print(row[\"link_str\"])\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "df = df.drop_duplicates(subset=dup_columns, keep=\"first\")\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "duplicates.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index([], dtype='int64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/results/all_dependencies_updated.csv\")\n",
    "\n",
    "\n",
    "dup_columns = [\"option_value\", \"option_name\", \"option_file\", \"dependent_option_name\", \"dependent_option_value\", \"dependent_option_file\"]\n",
    "\n",
    "duplicates = df[df.duplicated(subset=dup_columns)]\n",
    "\n",
    "for index, row in duplicates.iterrows():\n",
    "    print(row[\"link_str\"])\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "df = df.drop_duplicates(subset=dup_columns, keep=\"first\")\n",
    "\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "duplicates.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203\n",
      "1203\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/analysis/failures_annotated.csv\")\n",
    "\n",
    "print(len(df))\n",
    "\n",
    "dup_columns = [\"option_value\", \"option_name\", \"option_file\", \"dependent_option_name\", \"dependent_option_value\", \"dependent_option_file\", \"llm\", \"config\"]\n",
    "\n",
    "duplicates = df[df.duplicated(subset=dup_columns)]\n",
    "\n",
    "df = df.drop_duplicates(subset=dup_columns, keep=\"first\")\n",
    "\n",
    "print(len(df))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
