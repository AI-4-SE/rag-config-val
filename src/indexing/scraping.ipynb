{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "from typing import Dict\n",
    "from pyhtml2pdf import converter\n",
    "import requests\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scrape Documentations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technology_scraping_dict = {\n",
    "    \"docker-compose\": {\n",
    "        \"url\": \"https://docs.docker.com/compose/compose-file/\",\n",
    "        \"sub_urls\": True,\n",
    "        \"scraping\": {\n",
    "            \"html_class\": \"article\",\n",
    "            \"css_class\": \"class\",\n",
    "            \"css_class_name\": \"prose max-w-none dark:prose-invert\"\n",
    "        }\n",
    "    },\n",
    "    \"docker\": {\n",
    "        \"url\": \"https://docs.docker.com/reference/dockerfile/\",\n",
    "        \"sub_urls\": False,\n",
    "        \"scraping\": {\n",
    "            \"html_class\": \"article\",\n",
    "            \"css_class\": \"class\",\n",
    "            \"css_class_name\": \"prose max-w-none dark:prose-invert\"\n",
    "        }\n",
    "    },\n",
    "    \"spring-boot\": [\n",
    "        {\n",
    "            \"url\": \"https://docs.spring.io/spring-boot/appendix/application-properties/index.html\",\n",
    "                \"sub_urls\": False,\n",
    "                \"scraping\": {\n",
    "                    \"html_class\": \"article\",\n",
    "                    \"css_class\": \"class\",\n",
    "                    \"css_class_name\": \"doc\"\n",
    "                },\n",
    "        },\n",
    "        {\n",
    "            \"url\": \"https://docs.spring.io/spring-boot/docs/1.0.1.RELEASE/reference/html/howto-properties-and-configuration.html\",\n",
    "            \"sub_urls\": False,\n",
    "            \"scraping\": {\n",
    "                \"html_class\": \"div\",\n",
    "                \"css_class\": \"class\",\n",
    "                \"css_class_name\": \"chapter\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"maven\": [\n",
    "        {\n",
    "            \"url\": \"https://maven.apache.org/pom.html\",\n",
    "            \"sub_urls\": False,\n",
    "            \"scraping\": {\n",
    "                \"html_class\": \"main\",\n",
    "                \"css_class\": \"id\",\n",
    "                \"css_class_name\": \"bodyColumn\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"url\": \"https://maven.apache.org/ref/3.9.7/maven-model/maven.html\",\n",
    "            \"sub_urls\": False,\n",
    "            \"scraping\": {\n",
    "                \"html_class\": \"main\",\n",
    "                \"css_class\": \"id\",\n",
    "                \"css_class_name\": \"bodyColumn\"\n",
    "            }\n",
    "        },\n",
    "                {\n",
    "            \"url\": \"https://maven.apache.org/ref/3.9.7/maven-settings/settings.html\",\n",
    "            \"sub_urls\": False,\n",
    "            \"scraping\": {\n",
    "                \"html_class\": \"main\",\n",
    "                \"css_class\": \"id\",\n",
    "                \"css_class_name\": \"bodyColumn\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"url\": \"https://maven.apache.org/ref/3.9.7/maven-core/toolchains.html\",\n",
    "            \"sub_urls\": False,\n",
    "            \"scraping\": {\n",
    "                \"html_class\": \"main\",\n",
    "                \"css_class\": \"id\",\n",
    "                \"css_class_name\": \"bodyColumn\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"nodejs\": [\n",
    "        {\n",
    "            \"url\": \"https://nodejs.org/docs/latest/api/packages.html\",\n",
    "            \"sub_urls\": False,\n",
    "            \"scraping\": {\n",
    "                \"html_class\": \"div\",\n",
    "                \"css_class\": \"id\",\n",
    "                \"css_class_name\": \"apicontent\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"url\": \"https://docs.npmjs.com/cli/v10/configuring-npm/package-json\",\n",
    "            \"sub_urls\": False,\n",
    "            \"scraping\": {\n",
    "                \"html_class\": \"main\",\n",
    "                \"css_class\": \"class\",\n",
    "                \"css_class_name\": \"Box-sc-g0xbh4-0 jrNUvm\"\n",
    "            }\n",
    "        },\n",
    "    ],\n",
    "    \"tsconfig\": {\n",
    "        \"url\": \"https://www.typescriptlang.org/tsconfig/\",\n",
    "        \"sub_urls\": False,\n",
    "        \"scraping\": {\n",
    "            \"html_class\": \"main\",\n",
    "            \"css_class\": \"role\",\n",
    "            \"css_class_name\": \"main\"\n",
    "        }\n",
    "    },\n",
    "    \"mysql\": [\n",
    "        {\n",
    "            \"url\": \"https://dev.mysql.com/doc/refman/8.4/en/server-system-variables.html\",\n",
    "            \"sub_urls\": False,\n",
    "            \"scraping\": {\n",
    "                \"html_class\": \"div\",\n",
    "                \"css_class\": \"id\",\n",
    "                \"css_class_name\": \"docs-main-inner\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"url\": \"https://dev.mysql.com/doc/refman/8.4/en/innodb-parameters.html\",\n",
    "                \"sub_urls\": False,\n",
    "                \"scraping\": {\n",
    "                    \"html_class\": \"div\",\n",
    "                    \"css_class\": \"id\",\n",
    "                    \"css_class_name\": \"docs-main-inner\"\n",
    "                }\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin\n",
    "\n",
    "def scrape_sub_urls(url):\n",
    "    # Fetch the main page\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()  # Ensures we notice if something goes wrong\n",
    "\n",
    "    # Parse the HTML content\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Find all links within the page's <a> tags\n",
    "    links = soup.find_all('a', href=True)\n",
    "    # Normalize and filter URLs\n",
    "    sub_urls = set()\n",
    "    for link in links:\n",
    "        # Create a full URL if the link is relative\n",
    "        full_url = urljoin(url, link['href'])\n",
    "        if full_url.startswith(url):  # Optional: filter for specific domain\n",
    "            sub_urls.add(full_url)\n",
    "    return sub_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xhtml2pdf import pisa\n",
    "from io import BytesIO\n",
    "\n",
    "# HTML content\n",
    "html_content = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<body>\n",
    "    {}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def scrape(scraping_values: Dict, tech_dir_name: str):\n",
    "    main_url = scraping_values[\"url\"]\n",
    "\n",
    "    if scraping_values[\"sub_urls\"]:\n",
    "        sub_urls = scrape_sub_urls(main_url)\n",
    "\n",
    "        for url in sub_urls:\n",
    "            print(url)\n",
    "\n",
    "            name = url.split(\"/\")[-2]\n",
    "            output_file = tech_dir_name + f\"/{name}.pdf\"\n",
    "\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "            main_body = soup.find(scraping_values[\"scraping\"][\"html_class\"], {scraping_values[\"scraping\"][\"css_class\"]: scraping_values[\"scraping\"][\"css_class_name\"]})\n",
    "\n",
    "            pdf_output = BytesIO()\n",
    "            pisa.CreatePDF(html_content.format(main_body), dest=pdf_output, encoding='utf-8')\n",
    "\n",
    "            if not os.path.exists(output_file):\n",
    "                # Open a PDF file for writing in binary mode\n",
    "                with open(output_file, \"wb\") as pdf_file:\n",
    "                    # Write the PDF content to the file  \n",
    "                    pdf_file.write(pdf_output.getvalue())\n",
    "            else:\n",
    "                print(\"File already exists.\")\n",
    "    \n",
    "    else:\n",
    "        print(main_url)\n",
    "        name = \"_\".join(main_url.split(\"/\")[-2:])\n",
    "        output_file = tech_dir_name + f\"/{name}.pdf\"\n",
    "\n",
    "        response = requests.get(main_url)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        main_body = soup.find(scraping_values[\"scraping\"][\"html_class\"], {scraping_values[\"scraping\"][\"css_class\"]: scraping_values[\"scraping\"][\"css_class_name\"]})\n",
    "\n",
    "        pdf_output = BytesIO()\n",
    "        pisa.CreatePDF(html_content.format(main_body), dest=pdf_output, encoding='utf-8')\n",
    "\n",
    "        if not os.path.exists(output_file):\n",
    "            # Open a PDF file for writing in binary mode\n",
    "            with open(output_file, \"wb\") as pdf_file:\n",
    "                # Write the PDF content to the file  \n",
    "                pdf_file.write(pdf_output.getvalue())\n",
    "        else:\n",
    "            print(\"File already exists.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrape:  docker-compose\n",
      "Technology docker-compose already scraped.\n",
      "Scrape:  docker\n",
      "Technology docker already scraped.\n",
      "Scrape:  spring-boot\n",
      "Technology spring-boot already scraped.\n",
      "Scrape:  maven\n",
      "Technology maven already scraped.\n",
      "Scrape:  nodejs\n",
      "Technology nodejs already scraped.\n",
      "Scrape:  tsconfig\n",
      "Technology tsconfig already scraped.\n",
      "Scrape:  mysql\n",
      "https://dev.mysql.com/doc/refman/8.4/en/server-system-variables.html\n",
      "Name:  en_server-system-variables.html\n",
      "https://dev.mysql.com/doc/refman/8.4/en/innodb-parameters.html\n",
      "Name:  en_innodb-parameters.html\n"
     ]
    }
   ],
   "source": [
    "for technology, scraping_values in technology_scraping_dict.items():\n",
    "    print(\"Scrape: \", technology)\n",
    "\n",
    "    tech_dir_name = f\"../../data/tech_docs/{technology}\"\n",
    "\n",
    "    os.makedirs(tech_dir_name, exist_ok=True)\n",
    "\n",
    "    if len(os.listdir(tech_dir_name)) > 0:\n",
    "        print(f\"Technology {technology} already scraped.\")\n",
    "        continue\n",
    "\n",
    "    if isinstance(scraping_values, list):\n",
    "        for x in scraping_values:\n",
    "            scrape(scraping_values=x, tech_dir_name=tech_dir_name)\n",
    "\n",
    "    else:\n",
    "        scrape(scraping_values=scraping_values, tech_dir_name=tech_dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scrape Stack Overflow Posts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('docker', 'docker-compose'),\n",
       " ('docker', 'maven'),\n",
       " ('docker', 'spring'),\n",
       " ('docker-compose', 'maven'),\n",
       " ('docker-compose', 'spring'),\n",
       " ('maven', 'spring')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "technologies = [\"docker\", \"docker-compose\", \"maven\", \"spring\"]\n",
    "\n",
    "combinations = list(itertools.combinations(technologies, r=2))\n",
    "\n",
    "combinations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scrape Blog Posts**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
