{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"../data/evaluation/config5/all_dependencies_all.json\"\n",
    "output_file = \"../data/evaluation/config5/all_dependencies_all_updated.json\"\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "\n",
    "for entry in data:\n",
    "    context = entry[\"context\"][:3]\n",
    "    context_str = \"\\n\\n\".join([x[\"content\"] for x in context])\n",
    "    \n",
    "    entry[\"context\"] = context\n",
    "    entry[\"context_str\"] = context_str\n",
    "\n",
    "with open(output_file, \"a\", encoding=\"utf-8\") as dest:\n",
    "    json.dump(data, dest, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "dict_keys(['content', 'score', 'index', 'id'])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"../data/evaluation/config5/all_dependencies_all.json\"\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "    print(len(data))\n",
    "\n",
    "    print(data[0][\"context\"][0].keys())\n",
    "\n",
    "    for x in data:\n",
    "        context = x[\"context\"]\n",
    "        if len(context) == 0:\n",
    "            print(x[\"index\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ssimon/github/cval/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file:  ../data/evaluation/without/all_dependencies_without_gpt-4o-2024-05-13.json\n",
      "With RAG:  False\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07/16/24 20:41:05] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialize CfgNet prompt settings.                              <a href=\"file:///home/ssimon/github/cval/src/prompt_settings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">prompt_settings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/github/cval/src/prompt_settings.py#192\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">192</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07/16/24 20:41:05]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialize CfgNet prompt settings.                              \u001b]8;id=548139;file:///home/ssimon/github/cval/src/prompt_settings.py\u001b\\\u001b[2mprompt_settings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=320272;file:///home/ssimon/github/cval/src/prompt_settings.py#192\u001b\\\u001b[2m192\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> GPT <span style=\"font-weight: bold\">(</span>gpt-4o-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">05</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">)</span> generator initialized.                         <a href=\"file:///home/ssimon/github/cval/src/generator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">generator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/github/cval/src/generator.py#47\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">47</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPT \u001b[1m(\u001b[0mgpt-4o-\u001b[1;36m2024\u001b[0m-\u001b[1;36m05\u001b[0m-\u001b[1;36m13\u001b[0m\u001b[1m)\u001b[0m generator initialized.                         \u001b]8;id=841179;file:///home/ssimon/github/cval/src/generator.py\u001b\\\u001b[2mgenerator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=359751;file:///home/ssimon/github/cval/src/generator.py#47\u001b\\\u001b[2m47\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07/16/24 20:41:14] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/github/cval/env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/github/cval/env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07/16/24 20:41:14]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=586720;file:///home/ssimon/github/cval/env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=50929;file:///home/ssimon/github/cval/env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:  35%|███▌      | 175/500 [00:08<00:16, 19.62it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07/16/24 20:41:19] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/github/cval/env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/github/cval/env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07/16/24 20:41:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=645900;file:///home/ssimon/github/cval/env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=317523;file:///home/ssimon/github/cval/env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:  54%|█████▎    | 268/500 [00:14<00:12, 18.94it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[07/16/24 20:41:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/github/cval/env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/github/cval/env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[07/16/24 20:41:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=570083;file:///home/ssimon/github/cval/env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=795579;file:///home/ssimon/github/cval/env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries: 100%|██████████| 500/500 [00:21<00:00, 23.19it/s]\n"
     ]
    }
   ],
   "source": [
    "from prompt_settings import PrompSettingsFactory\n",
    "from typing import Dict, List\n",
    "from generator import GeneratorFactory, GeneratorEngine\n",
    "from dotenv import load_dotenv\n",
    "from util import load_config\n",
    "from tqdm import tqdm\n",
    "import backoff\n",
    "import json\n",
    "\n",
    "\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=10)\n",
    "def generate(generator: GeneratorEngine, messages: List) -> str:\n",
    "    response = generator.generate(messages=messages)\n",
    "\n",
    "    if not response:\n",
    "        raise Exception(\"Response is empty.\")\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def run_generation(config: Dict, target_index: List[int]) -> None:\n",
    "    \n",
    "    print(\"Data file: \", config[\"data_file\"])\n",
    "    print(\"With RAG: \", config[\"with_rag\"])\n",
    "    \n",
    "\n",
    "    with open(config[\"data_file\"], \"r\", encoding=\"utf-8\") as src:\n",
    "        data = json.load(src)\n",
    "\n",
    "    prompt_settings = PrompSettingsFactory.get_prompt_settings(tool_name=config[\"tool_name\"])\n",
    "\n",
    "    generator = GeneratorFactory().get_generator(\n",
    "        model_name=config[\"model_name\"], \n",
    "        temperature=config[\"temperature\"]\n",
    "    )\n",
    "\n",
    "    for entry in tqdm(data, total=len(data), desc=\"Processing entries\"):\n",
    "        \n",
    "        if not entry[\"index\"] in target_index:\n",
    "            continue\n",
    "\n",
    "\n",
    "        if config[\"with_rag\"]:\n",
    "            query_str = prompt_settings.query_prompt.format(\n",
    "                context_str=entry[\"context_str\"], \n",
    "                task_str=entry[\"task_str\"],\n",
    "                format_str=prompt_settings.get_format_prompt()\n",
    "            )\n",
    "        else:\n",
    "            query_str =f\"{entry['task_str']}\\n\\n{prompt_settings.get_format_prompt()}\"\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": entry[\"system_str\"]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query_str\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = generate(\n",
    "            generator=generator,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        #entry[\"responses\"] = [response]\n",
    "        entry[\"response\"] = response\n",
    "        \n",
    "    output_file = config[\"data_file\"]\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as dest:\n",
    "        json.dump(data, dest, indent=2)\n",
    "            \n",
    "\n",
    "config_file = \"../generation_config.toml\"\n",
    "env_file = \"../.env\"\n",
    "\n",
    "load_dotenv(dotenv_path=env_file)\n",
    "\n",
    "# load config\n",
    "config = load_config(config_file=config_file)\n",
    "run_generation(config=config, target_index=[174, 267, 285])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
