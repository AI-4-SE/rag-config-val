{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/evaluation/all_dependencies.csv\")\n",
    "\n",
    "df_sample = df.sample(n=100)\n",
    "\n",
    "df_sample.to_csv(\"../data/evaluation/test_dependencies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"../data/evaluation/config5/all_dependencies_all.json\"\n",
    "output_file = \"../data/evaluation/config5/all_dependencies_all_updated.json\"\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "\n",
    "for entry in data:\n",
    "    context = entry[\"context\"][:3]\n",
    "    context_str = \"\\n\\n\".join([x[\"content\"] for x in context])\n",
    "    \n",
    "    entry[\"context\"] = context\n",
    "    entry[\"context_str\"] = context_str\n",
    "\n",
    "with open(output_file, \"a\", encoding=\"utf-8\") as dest:\n",
    "    json.dump(data, dest, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get index of dependencies for which no context could be retrieved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"../data/evaluation/config5/all_dependencies_all.json\"\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "    print(len(data))\n",
    "\n",
    "    print(data[0][\"context\"][0].keys())\n",
    "\n",
    "    for x in data:\n",
    "        context = x[\"context\"]\n",
    "        if len(context) == 0:\n",
    "            print(x[\"index\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get index of dependencies for which the response format cannot be load as json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "dict_keys(['content', 'score', 'index', 'id'])\n",
      "JSONDecodeError Index:  31\n",
      "JSONDecodeError Index:  39\n",
      "JSONDecodeError Index:  58\n",
      "JSONDecodeError Index:  94\n",
      "JSONDecodeError Index:  108\n",
      "JSONDecodeError Index:  210\n",
      "JSONDecodeError Index:  301\n",
      "JSONDecodeError Index:  321\n",
      "JSONDecodeError Index:  327\n",
      "JSONDecodeError Index:  338\n",
      "JSONDecodeError Index:  422\n",
      "JSONDecodeError Index:  432\n",
      "JSONDecodeError Index:  447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[31, 39, 58, 94, 108, 210, 301, 321, 327, 338, 422, 432, 447]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"../data/evaluation/without/all_dependencies_without_llama3:8b.json\"\n",
    "\n",
    "target_indices = []\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "    print(len(data))\n",
    "\n",
    "    print(data[0][\"context\"][0].keys())\n",
    "\n",
    "    for entry in data:\n",
    "        response = entry[\"response\"]\n",
    "        \n",
    "        try:\n",
    "            response_dict = json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            target_indices.append(entry[\"index\"])\n",
    "            print(\"JSONDecodeError Index: \", entry[\"index\"])\n",
    "            try:\n",
    "                isDependency = response_dict[\"isDependency\"]\n",
    "            except KeyError as error:\n",
    "                print(\"IsDependency missing: \", entry[\"index\"])\n",
    "\n",
    "        except KeyError:\n",
    "            target_indices.append(entry[\"index\"])\n",
    "            print(\"KeyError Index: \", entry[\"index\"])\n",
    "\n",
    "        \n",
    "target_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run generation pipeline for specific indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_settings import PrompSettingsFactory\n",
    "from typing import Dict, List\n",
    "from generator import GeneratorFactory, GeneratorEngine\n",
    "from dotenv import load_dotenv\n",
    "from util import load_config\n",
    "from tqdm import tqdm\n",
    "import backoff\n",
    "import json\n",
    "\n",
    "\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=10)\n",
    "def generate(generator: GeneratorEngine, messages: List) -> str:\n",
    "    response = generator.generate(messages=messages)\n",
    "\n",
    "    if not response:\n",
    "        raise Exception(\"Response is empty.\")\n",
    "    \n",
    "    try:\n",
    "        json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        raise Exception(\"Response cannot be loaded as JSON.\")\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def run_generation(config: Dict, target_index: List[int]) -> None:\n",
    "    \n",
    "    print(\"Data file: \", config[\"data_file\"])\n",
    "    print(\"With RAG: \", config[\"with_rag\"])\n",
    "    \n",
    "\n",
    "    with open(config[\"data_file\"], \"r\", encoding=\"utf-8\") as src:\n",
    "        data = json.load(src)\n",
    "\n",
    "    prompt_settings = PrompSettingsFactory.get_prompt_settings(tool_name=config[\"tool_name\"])\n",
    "\n",
    "    generator = GeneratorFactory().get_generator(\n",
    "        model_name=config[\"model_name\"], \n",
    "        temperature=config[\"temperature\"]\n",
    "    )\n",
    "\n",
    "    for entry in tqdm(data, total=len(data), desc=\"Processing entries\"):\n",
    "        \n",
    "        if not entry[\"index\"] in target_index:\n",
    "            continue\n",
    "\n",
    "\n",
    "        if config[\"with_rag\"]:\n",
    "            query_str = prompt_settings.query_prompt.format(\n",
    "                context_str=entry[\"context_str\"], \n",
    "                task_str=entry[\"task_str\"],\n",
    "                format_str=prompt_settings.get_format_prompt()\n",
    "            )\n",
    "        else:\n",
    "            query_str =f\"{entry['task_str']}\\n\\n{prompt_settings.get_format_prompt()}\"\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": entry[\"system_str\"]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query_str\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = generate(\n",
    "            generator=generator,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        #entry[\"responses\"] = [response]\n",
    "        entry[\"response\"] = response\n",
    "        \n",
    "    output_file = config[\"data_file\"]\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as dest:\n",
    "        json.dump(data, dest, indent=2)\n",
    "            \n",
    "\n",
    "config_file = \"../generation_config.toml\"\n",
    "env_file = \"../.env\"\n",
    "\n",
    "load_dotenv(dotenv_path=env_file)\n",
    "\n",
    "# load config\n",
    "config = load_config(config_file=config_file)\n",
    "run_generation(config=config, target_index=[31, 39, 58, 94, 108, 210, 301, 321, 327, 338, 422, 432, 447])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "133\n",
      "181\n",
      "192\n",
      "238\n",
      "264\n",
      "268\n",
      "282\n",
      "285\n",
      "486\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "model_names = [\"gpt-4o-2024-05-13\", \"gpt-3.5-turbo-0125\", \"llama3:8b\", \"llama3:70b\"]\n",
    "\n",
    "updated_file = \"../data/results/config4/all_dependencies_all_updated.json\"\n",
    "data_file = \"../data/results/config4/all_dependencies_all_llama3:70b.json\"\n",
    "\n",
    "\n",
    "with open(updated_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    updated_data = json.load(src)\n",
    "\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "\n",
    "\n",
    "for entry in updated_data:\n",
    "    index = entry[\"index\"]\n",
    "    print(index)\n",
    "    data[index] = entry\n",
    "\n",
    "\n",
    "with open(data_file, \"w\", encoding=\"utf-8\") as dest:\n",
    "    json.dump(data, dest, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
