{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/evaluation/all_dependencies.csv\")\n",
    "\n",
    "df_sample = df.sample(n=100)\n",
    "\n",
    "df_sample.to_csv(\"../data/evaluation/test_dependencies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"../data/evaluation/config5/all_dependencies_all.json\"\n",
    "output_file = \"../data/evaluation/config5/all_dependencies_all_updated.json\"\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "\n",
    "for entry in data:\n",
    "    context = entry[\"context\"][:3]\n",
    "    context_str = \"\\n\\n\".join([x[\"content\"] for x in context])\n",
    "    \n",
    "    entry[\"context\"] = context\n",
    "    entry[\"context_str\"] = context_str\n",
    "\n",
    "with open(output_file, \"a\", encoding=\"utf-8\") as dest:\n",
    "    json.dump(data, dest, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get index of dependencies for which no context could be retrieved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"../data/evaluation/config5/all_dependencies_all.json\"\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "    print(len(data))\n",
    "\n",
    "    print(data[0][\"context\"][0].keys())\n",
    "\n",
    "    for x in data:\n",
    "        context = x[\"context\"]\n",
    "        if len(context) == 0:\n",
    "            print(x[\"index\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get index of dependencies for which the response format cannot be load as json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "dict_keys(['content', 'score', 'index', 'id'])\n",
      "JSONDecodeError Index:  31\n",
      "JSONDecodeError Index:  39\n",
      "JSONDecodeError Index:  58\n",
      "JSONDecodeError Index:  94\n",
      "JSONDecodeError Index:  108\n",
      "JSONDecodeError Index:  210\n",
      "JSONDecodeError Index:  301\n",
      "JSONDecodeError Index:  321\n",
      "JSONDecodeError Index:  327\n",
      "JSONDecodeError Index:  338\n",
      "JSONDecodeError Index:  422\n",
      "JSONDecodeError Index:  432\n",
      "JSONDecodeError Index:  447\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[31, 39, 58, 94, 108, 210, 301, 321, 327, 338, 422, 432, 447]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"../data/evaluation/without/all_dependencies_without_llama3:8b.json\"\n",
    "\n",
    "target_indices = []\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "    print(len(data))\n",
    "\n",
    "    print(data[0][\"context\"][0].keys())\n",
    "\n",
    "    for entry in data:\n",
    "        response = entry[\"response\"]\n",
    "        \n",
    "        try:\n",
    "            response_dict = json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            target_indices.append(entry[\"index\"])\n",
    "            print(\"JSONDecodeError Index: \", entry[\"index\"])\n",
    "            try:\n",
    "                isDependency = response_dict[\"isDependency\"]\n",
    "            except KeyError as error:\n",
    "                print(\"IsDependency missing: \", entry[\"index\"])\n",
    "\n",
    "        except KeyError:\n",
    "            target_indices.append(entry[\"index\"])\n",
    "            print(\"KeyError Index: \", entry[\"index\"])\n",
    "\n",
    "        \n",
    "target_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run generation pipeline for specific indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file:  ../data/results/config1/all_dependencies_all_gpt-3.5-turbo-0125.json\n",
      "With RAG:  True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/02/24 19:06:18] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Initialize CfgNet prompt settings.                              <a href=\"file:///home/ssimon/projects/cval/src/prompt_settings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">prompt_settings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/projects/cval/src/prompt_settings.py#192\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">192</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/02/24 19:06:18]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Initialize CfgNet prompt settings.                              \u001b]8;id=74639;file:///home/ssimon/projects/cval/src/prompt_settings.py\u001b\\\u001b[2mprompt_settings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=646236;file:///home/ssimon/projects/cval/src/prompt_settings.py#192\u001b\\\u001b[2m192\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> GPT <span style=\"font-weight: bold\">(</span>gpt-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.5</span>-turbo-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0125</span><span style=\"font-weight: bold\">)</span> generator initialized.                        <a href=\"file:///home/ssimon/projects/cval/src/generator.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">generator.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/projects/cval/src/generator.py#88\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">88</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m GPT \u001b[1m(\u001b[0mgpt-\u001b[1;36m3.5\u001b[0m-turbo-\u001b[1;36m0125\u001b[0m\u001b[1m)\u001b[0m generator initialized.                        \u001b]8;id=93133;file:///home/ssimon/projects/cval/src/generator.py\u001b\\\u001b[2mgenerator.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=532207;file:///home/ssimon/projects/cval/src/generator.py#88\u001b\\\u001b[2m88\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:   0%|          | 0/500 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/02/24 19:06:21] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/02/24 19:06:21]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=167481;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=356178;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:  25%|██▌       | 126/500 [00:03<00:09, 40.10it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/02/24 19:06:24] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/02/24 19:06:24]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=105997;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=109930;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:  27%|██▋       | 134/500 [00:05<00:19, 19.12it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/02/24 19:06:27] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/02/24 19:06:27]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=100337;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=749466;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:  36%|███▋      | 182/500 [00:09<00:18, 16.97it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/02/24 19:06:30] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/02/24 19:06:30]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=216718;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=257714;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:  39%|███▊      | 193/500 [00:12<00:25, 11.89it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/02/24 19:06:33] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/02/24 19:06:33]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=37059;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=25451;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:  48%|████▊     | 239/500 [00:15<00:20, 12.79it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/02/24 19:06:36] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/02/24 19:06:36]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=637499;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=524671;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:  53%|█████▎    | 265/500 [00:18<00:20, 11.53it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/02/24 19:06:39] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/02/24 19:06:39]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=379334;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=551506;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:  54%|█████▍    | 269/500 [00:21<00:27,  8.34it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/02/24 19:06:41] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/02/24 19:06:41]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=34809;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=220876;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:  57%|█████▋    | 283/500 [00:23<00:26,  8.21it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/02/24 19:06:43] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/02/24 19:06:43]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=775098;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=492345;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries:  57%|█████▋    | 286/500 [00:25<00:36,  5.87it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[09/02/24 19:06:46] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> HTTP Request: <span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">POST</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff; text-decoration: underline\">https://api.openai.com/v1/chat/completions</span>          <a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">_client.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1026</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #008000; text-decoration-color: #008000\">\"HTTP/1.1 200 OK\"</span>                                                      <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[09/02/24 19:06:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m HTTP Request: \u001b[1;33mPOST\u001b[0m \u001b[4;94mhttps://api.openai.com/v1/chat/completions\u001b[0m          \u001b]8;id=605980;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py\u001b\\\u001b[2m_client.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=369693;file:///home/ssimon/projects/cval/cval_env/lib/python3.10/site-packages/httpx/_client.py#1026\u001b\\\u001b[2m1026\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[32m\"HTTP/1.1 200 OK\"\u001b[0m                                                      \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing entries: 100%|██████████| 500/500 [00:28<00:00, 17.40it/s]\n"
     ]
    }
   ],
   "source": [
    "from prompt_settings import PrompSettingsFactory\n",
    "from typing import Dict, List\n",
    "from generator import GeneratorFactory, GeneratorEngine\n",
    "from dotenv import load_dotenv\n",
    "from util import load_config\n",
    "from tqdm import tqdm\n",
    "import backoff\n",
    "import json\n",
    "\n",
    "\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=10)\n",
    "def generate(generator: GeneratorEngine, messages: List) -> str:\n",
    "    response = generator.generate(messages=messages)\n",
    "\n",
    "    if not response:\n",
    "        raise Exception(\"Response is empty.\")\n",
    "    \n",
    "    try:\n",
    "        json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        raise Exception(\"Response cannot be loaded as JSON.\")\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def run_generation(config: Dict, target_index: List[int]) -> None:\n",
    "    \n",
    "    print(\"Data file: \", config[\"data_file\"])\n",
    "    print(\"With RAG: \", config[\"with_rag\"])\n",
    "    \n",
    "\n",
    "    with open(config[\"data_file\"], \"r\", encoding=\"utf-8\") as src:\n",
    "        data = json.load(src)\n",
    "\n",
    "    prompt_settings = PrompSettingsFactory.get_prompt_settings(tool_name=config[\"tool_name\"])\n",
    "\n",
    "    generator = GeneratorFactory().get_generator(\n",
    "        model_name=config[\"model_name\"], \n",
    "        temperature=config[\"temperature\"]\n",
    "    )\n",
    "\n",
    "    for entry in tqdm(data, total=len(data), desc=\"Processing entries\"):\n",
    "        \n",
    "        if not entry[\"index\"] in target_index:\n",
    "            continue\n",
    "\n",
    "        print(\"Process index: \", entry[\"index\"])\n",
    "\n",
    "        if config[\"with_rag\"]:\n",
    "            query_str = prompt_settings.query_prompt.format(\n",
    "                context_str=entry[\"context_str\"], \n",
    "                task_str=entry[\"task_str\"],\n",
    "                format_str=prompt_settings.get_format_prompt()\n",
    "            )\n",
    "        else:\n",
    "            query_str =f\"{entry['task_str']}\\n\\n{prompt_settings.get_format_prompt()}\"\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": entry[\"system_str\"]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query_str\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = generate(\n",
    "            generator=generator,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        #entry[\"responses\"] = [response]\n",
    "        entry[\"response\"] = response\n",
    "        \n",
    "    output_file = config[\"data_file\"]\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as dest:\n",
    "        json.dump(data, dest, indent=2)\n",
    "            \n",
    "\n",
    "config_file = \"../generation_config.toml\"\n",
    "env_file = \"../.env\"\n",
    "\n",
    "load_dotenv(dotenv_path=env_file)\n",
    "\n",
    "# load config\n",
    "config = load_config(config_file=config_file)\n",
    "run_generation(config=config, target_index=[125, 133, 181, 192, 238, 264, 268, 282, 285, 486])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125\n",
      "133\n",
      "181\n",
      "192\n",
      "238\n",
      "264\n",
      "268\n",
      "282\n",
      "285\n",
      "486\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "model_names = [\"gpt-4o-2024-05-13\", \"gpt-3.5-turbo-0125\", \"llama3:8b\", \"llama3:70b\"]\n",
    "\n",
    "updated_file = \"../data/results/config4/all_dependencies_all_updated.json\"\n",
    "data_file = \"../data/results/config4/all_dependencies_all_llama3:70b.json\"\n",
    "\n",
    "\n",
    "with open(updated_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    updated_data = json.load(src)\n",
    "\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "\n",
    "\n",
    "for entry in updated_data:\n",
    "    index = entry[\"index\"]\n",
    "    print(index)\n",
    "    data[index] = entry\n",
    "\n",
    "\n",
    "with open(data_file, \"w\", encoding=\"utf-8\") as dest:\n",
    "    json.dump(data, dest, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
