{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/evaluation/all_dependencies.csv\")\n",
    "\n",
    "df_sample = df.sample(n=100)\n",
    "\n",
    "df_sample.to_csv(\"../data/evaluation/test_dependencies.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"../data/evaluation/config5/all_dependencies_all.json\"\n",
    "output_file = \"../data/evaluation/config5/all_dependencies_all_updated.json\"\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "\n",
    "for entry in data:\n",
    "    context = entry[\"context\"][:3]\n",
    "    context_str = \"\\n\\n\".join([x[\"content\"] for x in context])\n",
    "    \n",
    "    entry[\"context\"] = context\n",
    "    entry[\"context_str\"] = context_str\n",
    "\n",
    "with open(output_file, \"a\", encoding=\"utf-8\") as dest:\n",
    "    json.dump(data, dest, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get index of dependencies for which no context could be retrieved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"../data/evaluation/config5/all_dependencies_all.json\"\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "    print(len(data))\n",
    "\n",
    "    print(data[0][\"context\"][0].keys())\n",
    "\n",
    "    for x in data:\n",
    "        context = x[\"context\"]\n",
    "        if len(context) == 0:\n",
    "            print(x[\"index\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get index of dependencies for which the response format cannot be load as json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_file = \"../data/evaluation/without/all_dependencies_without_llama3:8b.json\"\n",
    "\n",
    "target_indices = []\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "    print(len(data))\n",
    "\n",
    "    print(data[0][\"context\"][0].keys())\n",
    "\n",
    "    for entry in data:\n",
    "        response = entry[\"response\"]\n",
    "        \n",
    "        try:\n",
    "            response_dict = json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            target_indices.append(entry[\"index\"])\n",
    "            print(\"JSONDecodeError Index: \", entry[\"index\"])\n",
    "            try:\n",
    "                isDependency = response_dict[\"isDependency\"]\n",
    "            except KeyError as error:\n",
    "                print(\"IsDependency missing: \", entry[\"index\"])\n",
    "\n",
    "        except KeyError:\n",
    "            target_indices.append(entry[\"index\"])\n",
    "            print(\"KeyError Index: \", entry[\"index\"])\n",
    "\n",
    "        \n",
    "target_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Run generation pipeline for specific indices**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prompt_settings import PrompSettingsFactory\n",
    "from typing import Dict, List\n",
    "from generator import GeneratorFactory, GeneratorEngine\n",
    "from dotenv import load_dotenv\n",
    "from util import load_config\n",
    "from tqdm import tqdm\n",
    "import backoff\n",
    "import json\n",
    "\n",
    "\n",
    "@backoff.on_exception(backoff.expo, Exception, max_tries=10)\n",
    "def generate(generator: GeneratorEngine, messages: List) -> str:\n",
    "    response = generator.generate(messages=messages)\n",
    "\n",
    "    if not response:\n",
    "        raise Exception(\"Response is empty.\")\n",
    "    \n",
    "    try:\n",
    "        json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        raise Exception(\"Response cannot be loaded as JSON.\")\n",
    "\n",
    "    return response\n",
    "\n",
    "\n",
    "def run_generation(config: Dict, target_index: List[int]) -> None:\n",
    "    \n",
    "    print(\"Data file: \", config[\"data_file\"])\n",
    "    print(\"With RAG: \", config[\"with_rag\"])\n",
    "    \n",
    "\n",
    "    with open(config[\"data_file\"], \"r\", encoding=\"utf-8\") as src:\n",
    "        data = json.load(src)\n",
    "\n",
    "    prompt_settings = PrompSettingsFactory.get_prompt_settings(tool_name=config[\"tool_name\"])\n",
    "\n",
    "    generator = GeneratorFactory().get_generator(\n",
    "        model_name=config[\"model_name\"], \n",
    "        temperature=config[\"temperature\"]\n",
    "    )\n",
    "\n",
    "    for entry in tqdm(data, total=len(data), desc=\"Processing entries\"):\n",
    "        \n",
    "        if not entry[\"index\"] in target_index:\n",
    "            continue\n",
    "\n",
    "        print(\"Process index: \", entry[\"index\"])\n",
    "\n",
    "        if config[\"with_rag\"]:\n",
    "            query_str = prompt_settings.query_prompt.format(\n",
    "                context_str=entry[\"context_str\"], \n",
    "                task_str=entry[\"task_str\"],\n",
    "                format_str=prompt_settings.get_format_prompt()\n",
    "            )\n",
    "        else:\n",
    "            query_str =f\"{entry['task_str']}\\n\\n{prompt_settings.get_format_prompt()}\"\n",
    "\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\", \n",
    "                \"content\": entry[\"system_str\"]\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query_str\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = generate(\n",
    "            generator=generator,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        #entry[\"responses\"] = [response]\n",
    "        entry[\"response\"] = response\n",
    "        \n",
    "    output_file = config[\"data_file\"]\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as dest:\n",
    "        json.dump(data, dest, indent=2)\n",
    "            \n",
    "\n",
    "config_file = \"../generation_config.toml\"\n",
    "env_file = \"../.env\"\n",
    "\n",
    "load_dotenv(dotenv_path=env_file)\n",
    "\n",
    "# load config\n",
    "config = load_config(config_file=config_file)\n",
    "run_generation(config=config, target_index=[125, 133, 181, 192, 238, 264, 268, 282, 285, 486])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "model_names = [\"gpt-4o-2024-05-13\", \"gpt-3.5-turbo-0125\", \"llama3:8b\", \"llama3:70b\"]\n",
    "\n",
    "updated_file = \"../data/results/config4/all_dependencies_all_updated.json\"\n",
    "data_file = \"../data/results/config4/all_dependencies_all_llama3:70b.json\"\n",
    "\n",
    "\n",
    "with open(updated_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    updated_data = json.load(src)\n",
    "\n",
    "\n",
    "with open(data_file, \"r\", encoding=\"utf-8\") as src:\n",
    "    data = json.load(src)\n",
    "\n",
    "\n",
    "\n",
    "for entry in updated_data:\n",
    "    index = entry[\"index\"]\n",
    "    print(index)\n",
    "    data[index] = entry\n",
    "\n",
    "\n",
    "with open(data_file, \"w\", encoding=\"utf-8\") as dest:\n",
    "    json.dump(data, dest, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Respond in a JSON format as shown below:\\n{\\n\\t“plan”: string, // Write down a step-by-step plan on how to solve the task given the information above.\\n\\t“rationale”: string, // Provide a concise explanation of whether and why the configuration options depend on each other due to value-equality.\\n\\t“isDependency”: boolean // True if a dependency exists, or False otherwise.\\n}'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prompt_settings import AdvancedCfgNetPromptSettings\n",
    "from data import Dependency\n",
    "from util import get_projet_description\n",
    "\n",
    "dependency = Dependency(\n",
    "    project=\"piggymetrics\",\n",
    "    option_name=\"server.port\",\n",
    "    option_value=\"8000\",\n",
    "    option_type=\"PORT\",\n",
    "    option_file=\"application.properties\",\n",
    "    option_technology=\"spring\",\n",
    "    dependent_option_name=\"EXPOSE\",\n",
    "    dependent_option_value=\"8000\",\n",
    "    dependent_option_type=\"PORT\",\n",
    "    dependent_option_file=\"Dockerfile\",\n",
    "    dependent_option_technology=\"Docker\"\n",
    ")\n",
    "\n",
    "dependency1 = Dependency(\n",
    "    project=\"piggymetrics\",\n",
    "    option_name=\"project.modelVersion\",\n",
    "    option_value=\"modelVersion:4.0.0\",\n",
    "    option_type=\"VERSION_NUMBER\",\n",
    "    option_file=\"pom.xml\",\n",
    "    option_technology=\"maven\",\n",
    "    dependent_option_name=\"project.modelVersion\",\n",
    "    dependent_option_value=\"modelVersion:4.0.0\",\n",
    "    dependent_option_type=\"VERSION_NUMBER\",\n",
    "    dependent_option_file=\"config/pom.xml\",\n",
    "    dependent_option_technology=\"maven\"\n",
    ")\n",
    "\n",
    "project_str = get_projet_description(dependency.project)\n",
    "\n",
    "system_str = AdvancedCfgNetPromptSettings.get_system_str(\n",
    "    dependency=dependency,\n",
    "    project_str=project_str\n",
    ")\n",
    "\n",
    "\n",
    "context_str=\"Context\",\n",
    "shot_str=\"Shots\" \n",
    "task_str = AdvancedCfgNetPromptSettings.get_task_str(dependency=dependency)\n",
    "format_str = AdvancedCfgNetPromptSettings.get_format_prompt()\n",
    "\n",
    "user_prompt = AdvancedCfgNetPromptSettings.advanced_query_prompt.format(\n",
    "    context_str=context_str,\n",
    "    shot_str=shot_str,\n",
    "    task_str=task_str,\n",
    "    format_str=format_str\n",
    ")\n",
    "\n",
    "format_str\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import load_shots, get_most_similar_shot, get_most_similar_shots\n",
    "\n",
    "shots = load_shots()\n",
    "\n",
    "relevant_shot = get_most_similar_shot(shots=shots, dependency=dependency)\n",
    "\n",
    "relevant_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Carefully evaluate whether configuration option project.modelVersion of type VERSION_NUMBER with value modelVersion:4.0.0 in litemall-all/pom.xml of technology maven depends on configuration option project.modelVersion of type VERSION_NUMBER with value modelVersion:4.0.0 in litemall-admin-api/pom.xml of technology maven or vice versa.\\n\\n{\\n    \"rationale\": \"The \\'project.modelVersion\\' in a Maven project typically specifies the version of the POM model being used. Maven currently only supports the model version 4.0.0 and this is required all modules to ensure compatibility. Therefore, the project.modelVersion must be consistent across all modules, creatiing a dependency based on value-equality.\",\\n    \"isDependency\": true\\n}',\n",
       " 'Carefully evaluate whether configuration option project.modelVersion of type VERSION_NUMBER with value modelVersion:4.0.0 in mall-security/pom.xml of technology maven depends on configuration option project.modelVersion of type VERSION_NUMBER with value modelVersion:4.0.0 in mall-search/pom.xml of technology maven or vice versa.\\n\\n {\\n    \"rationale\": \"The \\'project.modelVersion\\' in a Maven project defines the version of the POM model being used. Maven exclusively supports model version 4.0.0, which must be used across all modules to maintain compatibility. As a result, the project.modelVersion needs to be the same across all modules, establishing a dependency based on value equality.\",\\n    \"isDependency\": true\\n}')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_shots = get_most_similar_shots(shots=shots, dependency=dependency1)\n",
    "\n",
    "relevant_shots"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
