{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "document_types = {\n",
    "    \"DOCUMENTATIONS\": {\n",
    "        \"index_name\": \"tech-docs\"\n",
    "    },\n",
    "    \"BLOG_POSTS\": {\n",
    "        \"index_name\": \"blog-posts\",\n",
    "        \"data_dir\": \"../../data/blog_posts\"\n",
    "    },\n",
    "    \"STACK_OVERFLOW_POSTS\": {\n",
    "        \"index_name\": \"so-posts\",\n",
    "        \"data_dir\": \"../../data/so_posts\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "\n",
    "tech_docs = {\n",
    "    \"maven\": [\n",
    "        \"https://maven.apache.org/pom.html\",\n",
    "        \"https://maven.apache.org/ref/3.9.7/maven-model/maven.html\",\n",
    "        \"https://maven.apache.org/ref/3.9.7/maven-settings/settings.html\",\n",
    "        \"https://maven.apache.org/ref/3.9.7/maven-core/toolchains.html\",\n",
    "        \"https://maven.apache.org/guides/getting-started/index.html\",\n",
    "    ],\n",
    "    \"spring-boot\": [\n",
    "        \"https://docs.spring.io/spring-boot/appendix/application-properties/index.html\",\n",
    "        \"https://docs.spring.io/spring-boot/docs/1.0.1.RELEASE/reference/html/howto-properties-and-configuration.html\",\n",
    "        \"https://docs.spring.io/spring-boot/reference/features/external-config.html\",\n",
    "        \"https://docs.spring.io/spring-boot/reference/features/profiles.html\",\n",
    "    ],\n",
    "    \"docker-compose\": [\n",
    "        \"https://docs.docker.com/compose/compose-file/\",\n",
    "        \"https://docs.docker.com/compose/compose-application-model/\",\n",
    "        \"https://docs.docker.com/compose/intro/features-uses/\",\n",
    "        \"https://docs.docker.com/compose/gettingstarted/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/04-version-and-name/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/05-services/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/06-networks/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/07-volumes/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/08-configs/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/09-secrets/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/10-fragments/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/11-extension/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/12-interpolation/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/13-merge/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/14-include/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/15-profiles/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/build/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/deploy/\",\n",
    "        \"https://docs.docker.com/compose/compose-file/develop/\"\n",
    "\n",
    "    ],\n",
    "    \"docker\": [\n",
    "        \"https://docs.docker.com/reference/dockerfile/\",\n",
    "        \"https://docs.docker.com/build/building/packaging/\",\n",
    "        \"https://docs.docker.com/build/building/multi-stage/\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_up_text(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Remove unwanted characters and patterns in text input.\n",
    "\n",
    "    :param content: Text input.\n",
    "    \n",
    "    :return: Cleaned version of original text input.\n",
    "    \"\"\"\n",
    "\n",
    "    # Fix hyphenated words broken by newline\n",
    "    content = re.sub(r'(\\w+)-\\n(\\w+)', r'\\1\\2', content)\n",
    "\n",
    "    # Remove specific unwanted patterns and characters\n",
    "    unwanted_patterns = [\n",
    "        \"\\\\n\", \"  —\", \"——————————\", \"—————————\", \"—————\",\n",
    "        r'\\\\u[\\dA-Fa-f]{4}', r'\\uf075', r'\\uf0b7'\n",
    "    ]\n",
    "    for pattern in unwanted_patterns:\n",
    "        content = re.sub(pattern, \"\", content)\n",
    "\n",
    "    # Fix improperly spaced hyphenated words and normalize whitespace\n",
    "    content = re.sub(r'(\\w)\\s*-\\s*(\\w)', r'\\1-\\2', content)\n",
    "    content = re.sub(r'\\s+', ' ', content)\n",
    "\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing DOCUMENTATIONS\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserted vectors: 100%|██████████| 470/470 [00:11<00:00, 40.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing BLOG_POSTS\n",
      "docker-compose_docker\n",
      "maven_docker\n",
      "maven_docker-compose\n",
      "spring-boot_docker\n",
      "spring-boot_docker-compose\n",
      "spring-boot_maven\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserted vectors: 100%|██████████| 117/117 [00:03<00:00, 32.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing STACK_OVERFLOW_POSTS\n",
      "docker-compose_maven\n",
      "docker-compose_spring-boot\n",
      "docker_docker-compose\n",
      "docker_maven\n",
      "docker_spring-boot\n",
      "spring-boot_maven\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserted vectors: 100%|██████████| 873/873 [00:20<00:00, 41.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core.extractors import TitleExtractor, SummaryExtractor\n",
    "from llama_index.core import SimpleDirectoryReader, Settings\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from llama_index.readers.web import SimpleWebPageReader\n",
    "from llama_index.core.schema import MetadataMode\n",
    "import glob\n",
    "\n",
    "\n",
    "config = dotenv_values(\"../../.env\")\n",
    "pc = Pinecone(api_key=config[\"PINECONE_API_KEY\"])\n",
    "indexes = pc.list_indexes().names()\n",
    "\n",
    "embed_model = OpenAIEmbedding(api_key=config[\"OPENAI_KEY\"])\n",
    "llm = OpenAI(model=\"gpt-4o\", api_key=config[\"OPENAI_KEY\"])\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# add data\n",
    "for document_type, values in document_types.items():\n",
    "    if values[\"index_name\"] not in indexes:\n",
    "        pc.create_index(\n",
    "            name=values[\"index_name\"],\n",
    "            dimension=1536,\n",
    "            metric=\"dotproduct\",\n",
    "            spec=ServerlessSpec(\n",
    "                cloud=\"aws\",\n",
    "                region=\"us-east-1\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "    print(\"Indexing\", document_type)\n",
    "    pinecone_index = pc.Index(values[\"index_name\"])\n",
    "    \n",
    "    # Initialize VectorStore\n",
    "    vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n",
    "\n",
    "    cleaned_documents = []\n",
    "\n",
    "    # Use SimpleWebPageReader for Tech-Docs\n",
    "    if values[\"index_name\"] == \"tech-docs\":\n",
    "        for key, urls in tech_docs.items():\n",
    "            documents = SimpleWebPageReader(html_to_text=True).load_data(urls)\n",
    "            for d in documents:\n",
    "                d.metadata[\"technology\"] = key\n",
    "                d.metadata[\"file_name\"] = d.doc_id\n",
    "                cleaned_documents.append(d)\n",
    "    else:\n",
    "        for dir in glob.glob(values[\"data_dir\"] + \"/**\"):\n",
    "            technology_name = dir.split(\"/\")[-1]\n",
    "            print(technology_name)\n",
    "\n",
    "\n",
    "            documents = SimpleDirectoryReader(dir).load_data()\n",
    "\n",
    "            # clean up documents and add technology name to metadata\n",
    "            for d in documents: \n",
    "                cleaned_text = clean_up_text(d.text)\n",
    "                d.text = cleaned_text\n",
    "                d.metadata[\"technology\"] = technology_name\n",
    "                cleaned_documents.append(d)\n",
    "\n",
    "\n",
    "    transformations = [\n",
    "        SentenceSplitter(chunk_size=1024, chunk_overlap=20),\n",
    "        embed_model,\n",
    "    ]\n",
    "\n",
    "    # define the ingestion pipeline\n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=transformations,\n",
    "        vector_store=vector_store\n",
    "    )\n",
    "\n",
    "    # run the ingestion pipeline\n",
    "    pipeline.run(documents=cleaned_documents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
